[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experiments",
    "section": "",
    "text": "Preface\nThis book contains all experiment protocols for my research on appointment scheduling.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Surrogate models for schedule evaluation",
    "section": "",
    "text": "Objective\nObjective: Testing the performance of an XGBoost model trained for predicting objective values and ranking pairwise schedules.\nBackground: To find optimal solutions for appointment scheduling problems one approach is to create local search neighborhoods and evaluate the schedules in that set. A better search method either (1) - creates smaller search neighborhoods or (2) - evaluates faster.\nOne approach for speeding up evaluation is to create surrogate models, or metamodels. These are simplified representations of complex systems that are often created using machine learning techniques. When evaluating a complex system is computationally expensive, it’s more efficient to use a method that quickly identifies a subset of solutions with a high likelihood of containing the optimal or near-optimal solution. By focusing computational resources on refining the search within this promising subset, rather than across the entire solution space, we can significantly reduce the overall computational burden (Ho et al. 2000).\nWe will test two approaches:",
    "crumbs": [
      "Surrogate models for schedule evaluation"
    ]
  },
  {
    "objectID": "intro.html#objective",
    "href": "intro.html#objective",
    "title": "Surrogate models for schedule evaluation",
    "section": "",
    "text": "Cardinal model - Directly assessing the objective values from a given sample schedule using an XGBoost regressor.\nOrdinal model - Predicting the preferred schedule from a pair of sampled schedules using an XGBoost classifier.\n\n\n\n\n\n\n\n\n\nModel\nCardinal (Regressor)\nOrdinal (Classifier)\n\n\n\n\nEvaluation (approx.)\n\\(f: S \\rightarrow Objective, \\\\ f(S) \\in \\mathbb{R}^{18}\\)\n\\(g: (S_0,S_1) \\rightarrow \\text{\\{0, if } S_0 \\text{ is better; otherwise 1\\}}, \\\\ g(S_0, S_1) \\in \\mathbb{R}^{2 \\times 18}\\)\n\n\nComparison (schedules \\(S_0, S_1\\))\n\\(f(S_0)\\) vs. \\(f(S_1)\\)\n\\(g(S_0, S_1)\\)\n\n\nParameter Tuning\nOptuna\nOptuna\n\n\nTraining Data\n40k rows\n20k rows\n\n\n\n\nResults\n\n\n\n\nHo, Y-C, C G Cassandras, C-H Chen, and L Dai. 2000. “Ordinal Optimisation and Simulation.” Journal of the Operational Research Society 51 (4): 490–500. https://doi.org/10.1057/palgrave.jors.2600906.",
    "crumbs": [
      "Surrogate models for schedule evaluation"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html",
    "href": "xgboost-pairwise-ranking.html",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "",
    "text": "1.1 Objective\nObjective: Testing the performance of an XGBoost model trained for ranking pairwise schedules.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#background",
    "href": "xgboost-pairwise-ranking.html#background",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "1.2 Background",
    "text": "1.2 Background\nIn this experiment we develop a Machine Learning model using XGBoost that can evaluate two neighboring schedules and rank them according to preference. This ranking model can be applied to quickly guide the search process towards a ‘good enough’ solution.\nThe choice of using an ordinal model instead of a cardinal model is based on the consideration that it is significantly easier to determine whether alternative A is superior to B than to quantify the exact difference between A and B. This makes intuitive sense when considering the scenario of holding two identical-looking packages and deciding which one is heavier, as opposed to estimating the precise weight difference between them. (Ho et al. 2000).",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#hypothesis",
    "href": "xgboost-pairwise-ranking.html#hypothesis",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "1.3 Hypothesis",
    "text": "1.3 Hypothesis\nAn XGBoost ranking model achieves superior computational efficiency compared to evaluating each element of a pair individually, leading to faster overall performance in ranking tasks.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#methodology",
    "href": "xgboost-pairwise-ranking.html#methodology",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "1.4 Methodology",
    "text": "1.4 Methodology\n\n1.4.1 Tools and Materials\nWe use packages from Scikit-learn to prepare training data and evaluate the model and the XGBClassifier interface from the XGBoost library.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.base import clone\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\nimport random\n\n\n\n1.4.2 Experimental Design\nTo compare an XGBoost Machine Learning model with a simple evaluation of each individual element of the pair, we will use a pairwise ranking approach. The objective is to rank two neighboring schedules according to preference.\n\nfrom functions import get_v_star\nN = 12 # Number of patients\nT = 18 # Number of intervals\nd = 5 # Length of each interval\ns = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1] # Service times distribution\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.8 # Weight for the waiting time in objective function\nnum_schedules = 20000 # Number of schedules to sample\nv_star = get_v_star(T)\n\nWe will create a random set of pairs of neighboring schedules with \\(N = 12\\) patients and \\(T = 18\\) intervals of length \\(d = 5\\).\nA neighbor of a schedule x is considered a schedule x’ where single patients have been shifted one interval to the left. Eg: ([2,1,1,2], [1,2,0,3]) are neighbors and ([2,1,1,2], [2,1,3,0]) are not, because [1,2,0,3] - [2,1,1,2] = [-1, 1, -1, 1] and [2,1,3,0] - [2,1,1,2] = [0, 0, 2, -2].\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.2\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. The model will be trained to predict which of the two neighboring schedules has the lowest objective value. The prediction time will be recorded. Then the same schedules will be evaluated by computing the objective value and then ranked.\n\n\n1.4.3 Variables\n\nIndependent Variables: A list of tuples with pairs of neighboring schedules.\nDependent Variables: A list with rankings for each tuple of pairwise schedules. Eg: If the rank for ([2,1,1], [1,1,2]) equals 0 this means that the schedule with index 0 ([2,1,1]) has the lowest objective value.\n\n\n\n1.4.4 Data Collection\nThe data set will be generated using simulation in which random samples will be drawn from the population of all possible schedules. For each sample a random neighboring schedule will be created.\n\n\n1.4.5 Sample Size and Selection\nSample Size: The total population size equals \\({{N + T -1}\\choose{N}} \\approx\\) 52.0 mln. For this experiment we will be using a relatively small sample of 20000 pairs of schedules.\nSample Selection: The samples will be drawn from a lexicographic order of possible schedules in order to accurately reflect the combinatorial nature of the problem and to ensure unbiased sampling from the entire combinatorial space.\n\n\n1.4.6 Experimental Procedure\nThe experiment involves multiple steps, beginning with data preparation and concluding with model evaluation.The diagram below illustrates the sequence of steps.\n\n\n\n\n\ngraph TD\n    A[\"From population\"] --&gt;|\"Sample\"| B[\"Random subset\"]\n    B --&gt; |Create neighbors| C[\"Features: Schedule pairs\"]\n    C --&gt; |Calculate objectives| D[\"Objective values\"]\n    D --&gt; |Rank objectives| E[\"Labels: Rankings\"]\n    E --&gt; |\"Split dataset\"| F[\"Training set\"]\n    E --&gt; |\"Split dataset\"| G[\"Test set\"]\n    F --&gt; |\"Train\"| H[\"Model\"]\n    H[\"Model\"] --&gt; |\"Apply\"| G[\"Test set\"]\n    G[\"Test set\"] --&gt; |\"Evaluate\"| I[\"Performance\"]\n\n\n\n\n\n\nStep 1: Randomly select a subset of schedules.\n\nfrom functions import random_combination_with_replacement\n\nstart = time.time()\nschedules = random_combination_with_replacement(T, N, num_schedules)\nprint(f\"Sampled: {len(schedules)} schedules\\n\")\nh = random.choices(range(len(schedules)), k=7)\nprint(f\"Sampled schedules: {h}\")\nfor i in h:\n    print(f\"Schedule: {schedules[i]}\")\nend = time.time()\ndata_prep_time = end - start\n\nprint(f\"\\nProcessing time: {data_prep_time} seconds\\n\")\n\nTotal number of combinations: 51,895,935\nSampled: 20000 schedules\n\nSampled schedules: [3143, 16624, 16871, 2155, 2873, 3097, 6994]\nSchedule: [7, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [6, 1, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [5, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\nSchedule: [5, 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [4, 2, 1, 2, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\nSchedule: [7, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\nProcessing time: 0.2260730266571045 seconds\n\n\n\nStep 2: Create pairs of neighboring schedules.\n\nfrom functions import create_neighbors_list\n\nstart = time.time()\nneighbors_list = [create_neighbors_list(schedule, v_star) for schedule in schedules] # This can be done in parellel to improve speed\nend = time.time()\nfor i in h:\n    original_schedule = neighbors_list[i][0]\n    neighbor_schedule = neighbors_list[i][1]\n    difference = [x - y for x, y in zip(neighbors_list[i][0], neighbors_list[i][1])]\n    print(f\"Neighbors\\n{original_schedule}\\n{neighbor_schedule}\\n{difference}\")\ntraining_set_feat_time = end - start\nprint(f\"\\nProcessing time: {training_set_feat_time} seconds\\n\")\n\nNeighbors\n[7, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[7, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nNeighbors\n[6, 1, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[7, 1, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[-1, 0, 1, 0, 0, 0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nNeighbors\n[5, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n[5, 0, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n[0, 1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\nNeighbors\n[5, 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[4, 1, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n[1, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\nNeighbors\n[4, 2, 1, 2, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[5, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[-1, 1, -1, 1, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nNeighbors\n[3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n[3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, -1, 1, 0, 0, 0, -1]\nNeighbors\n[7, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n[7, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n[0, -1, 0, 1, -1, 0, 0, 1, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0]\n\nProcessing time: 1.674152135848999 seconds\n\n\n\nStep 3: For each schedule in each pair calculate the objective. For each pair save the index of the schedule that has the lowest objective value.\n\nfrom functions import calculate_objective\n\nobjectives_schedule_1 = [w * calculate_objective(neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(neighbor[0], s, d, q)[1] for neighbor in neighbors_list]\nstart = time.time()\nobjectives_schedule_2 = [w * calculate_objective(neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(neighbor[1], s, d, q)[1] for neighbor in neighbors_list]\nend = time.time()\ntraining_set_lab_time = end - start\nobjectives = [[obj, objectives_schedule_2[i]] for i, obj in enumerate(objectives_schedule_1)]\nrankings = np.argmin(objectives, axis=1).tolist()\nfor i in range(5):\n    print(f\"Objectives: {objectives[i]}, Ranking: {rankings[i]}\")\n\nprint(f\"\\nProcessing time: {training_set_lab_time} seconds\\n\")\n\n# Saving neighbors_list and objectives to a pickle file\nfile_path = 'datasets/neighbors_and_objectives.pkl'\nwith open(file_path, 'wb') as f:\n    pickle.dump({'neighbors_list': neighbors_list, 'objectives': objectives, 'rankings': rankings}, f)\n    print(f\"Data saved successfully to '{file_path}'\")\n\nObjectives: [40.7132903786003, 44.29093770976293], Ranking: 0\nObjectives: [53.109972522414175, 43.64776101084806], Ranking: 1\nObjectives: [53.4264119642738, 46.525074507348194], Ranking: 1\nObjectives: [47.571610887503645, 47.571610887503645], Ranking: 0\nObjectives: [49.47536904144756, 40.17117767200208], Ranking: 1\n\nProcessing time: 17.09611225128174 seconds\n\nData saved successfully to 'datasets/neighbors_and_objectives.pkl'\n\n\nStep 4: Create training and test sets.\n\n# Prepare the dataset\nX = []\nfor neighbors in neighbors_list:\n    X.append(neighbors[0] + neighbors[1])\n\nX = np.array(X)\ny = np.array(rankings)\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nStep 5: Train the XGBoost model.\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B[Initialize StratifiedKFold]\n    B --&gt; C[Initialize XGBClassifier]\n    C --&gt; D[Set results as empty list]\n    D --&gt; E[Loop through each split of cv split]\n    E --&gt; F[Get train and test indices]\n    F --&gt; G[Split X and y into X_train, X_test, y_train, y_test]\n    G --&gt; H[Clone the classifier]\n    H --&gt; I[Call fit_and_score function]\n    I --&gt; J[Fit the estimator]\n    J --&gt; K[Score on training set]\n    J --&gt; L[Score on test set]\n    K --&gt; M[Return estimator, train_score, test_score]\n    L --&gt; M\n    M --&gt; N[Append the results]\n    N --&gt; E\n    E --&gt; O[Loop ends]\n    O --&gt; P[Print results]\n    P --&gt; Q[End]\n\n\n\n\n\n\n\nclass CustomCallback(TrainingCallback):\n    def __init__(self, period=10):\n        self.period = period\n\n    def after_iteration(self, model, epoch, evals_log):\n        if (epoch + 1) % self.period == 0:\n            print(f\"Epoch {epoch}, Evaluation log: {evals_log['validation_0']['logloss'][epoch]}\")\n        return False\n    \ndef fit_and_score(estimator, X_train, X_test, y_train, y_test):\n    \"\"\"Fit the estimator on the train set and score it on both sets\"\"\"\n    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0\n    )\n\n    train_score = estimator.score(X_train, y_train)\n    test_score = estimator.score(X_test, y_test)\n\n    return estimator, train_score, test_score\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)\n\n# Initialize the XGBClassifier without early stopping here\n# Load the best trial parameters from a JSON file.\nwith open(\"model_params.json\", \"r\") as f:\n    model_params = json.load(f)\n    \n# Initialize the EarlyStopping callback with validation dataset\nearly_stop = xgb.callback.EarlyStopping(\n    rounds=10, metric_name='logloss', data_name='validation_0', save_best=True\n)\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n    early_stopping_rounds=9,\n    #callbacks=[CustomCallback(period=50), early_stop],\n    callbacks=[CustomCallback(period=50)],\n)\nprint(\"Params: \")\nfor key, value in model_params.items():\n    print(f\" {key}: {value}\")\n\nstart = time.time()\nresults = []\n\nfor train_idx, test_idx in cv.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    est, train_score, test_score = fit_and_score(\n        clone(clf), X_train, X_test, y_train, y_test\n    )\n    results.append((est, train_score, test_score))\nend = time.time()\ntraining_time = end - start\nprint(f\"\\nTraining time: {training_time} seconds\\n\")\n\nParams: \n max_depth: 6\n min_child_weight: 1\n gamma: 0.1\n subsample: 0.8\n colsample_bytree: 0.8\n learning_rate: 0.1\n n_estimators: 100\nEpoch 49, Evaluation log: 0.05455219040368683\nEpoch 99, Evaluation log: 0.04216296073211015\nEpoch 49, Evaluation log: 0.05368845318281092\nEpoch 99, Evaluation log: 0.04094662195513956\nEpoch 49, Evaluation log: 0.04904532701848075\nEpoch 99, Evaluation log: 0.03687723997185094\nEpoch 49, Evaluation log: 0.05073861599853263\nEpoch 99, Evaluation log: 0.0393132749446886\nEpoch 49, Evaluation log: 0.04947142685431754\nEpoch 99, Evaluation log: 0.03850802336719062\n\nTraining time: 0.9882938861846924 seconds\n\n\n\nStep 6: To evaluate the performance of the XGBoost ranking model, we will use Stratified K-Fold Cross-Validation with 5 splits, ensuring each fold maintains the same class distribution as the original dataset. Using StratifiedKFold(n_splits=5, shuffle=True, random_state=94), the dataset will be divided into five folds. In each iteration, the model will be trained on four folds and evaluated on the remaining fold. A custom callback, CustomCallback(period=10), will print the evaluation log every 10 epochs.\nThe fit_and_score function will fit the model and score it on both the training and test sets, storing the results for each fold. This provides insight into the model’s performance across different subsets of the data, helps in understanding how well the model generalizes to unseen data and identifies potential overfitting or underfitting issues. The overall processing time for the cross-validation will also be recorded.\n\n# Print results\nfor i, (est, train_score, test_score) in enumerate(results):\n    print(f\"Fold {i+1} - Train Score (Accuracy): {train_score:.4f}, Test Score (Accuracy): {test_score:.4f}\")\n\nFold 1 - Train Score (Accuracy): 0.9925, Test Score (Accuracy): 0.9862\nFold 2 - Train Score (Accuracy): 0.9922, Test Score (Accuracy): 0.9872\nFold 3 - Train Score (Accuracy): 0.9920, Test Score (Accuracy): 0.9890\nFold 4 - Train Score (Accuracy): 0.9924, Test Score (Accuracy): 0.9878\nFold 5 - Train Score (Accuracy): 0.9922, Test Score (Accuracy): 0.9882\n\n\nTraining the model on the entire dataset provides a final model that has learned from all available data. Recording the training time helps in understanding the computational efficiency and scalability of the model with the given hyperparameters.\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\\n\")\n\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\nTraining accuracy: 99.23%\n\n\nTraining time: 0.1360487937927246 seconds\n\n\n\n\n\n1.4.7 Validation\nGenerating test schedules and calculating their objectives and rankings allows us to create a new dataset for evaluating the model’s performance on unseen data.\n\nnum_test_schedules = 1000\n\ntest_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_neighbors = [create_neighbors_list(test_schedule, v_star) for test_schedule in test_schedules] # This can be done in parellel to improve speed\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\ntest_objectives_schedule_1 = [w * calculate_objective(test_neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[0], s, d, q)[1] for test_neighbor in test_neighbors]\n# Start time measeurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_2 = [w * calculate_objective(test_neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[1], s, d, q)[1] for test_neighbor in test_neighbors]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\nend = time.time()\nevaluation_time = end - start\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\nprint(f\"\\nEvaluation time: {evaluation_time} seconds\\n\")\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nTotal number of combinations: 51,895,935\nSampled: 1000 schedules\n\n\nEvaluation time: 0.898392915725708 seconds\n\nNeighbors: ([6, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [6, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [34.10370626270946, 36.3890775770396], Ranking: 0\n\nNeighbors: ([6, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [6, 0, 2, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]),\nObjectives: [42.168055975490745, 33.26579003483442], Ranking: 1\n\nNeighbors: ([4, 4, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 5, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [43.17359852761168, 47.900340916589684], Ranking: 0\n\nNeighbors: ([5, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 4, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [55.90431273631407, 63.446546787123296], Ranking: 0\n\nNeighbors: ([7, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [7, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]),\nObjectives: [53.4264119642738, 45.89097380607223], Ranking: 1\n\nNeighbors: ([4, 1, 5, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [5, 1, 4, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [34.31133011310308, 39.00838306816456], Ranking: 0\n\n\n\nMaking predictions on new data and comparing them to the actual rankings provides an evaluation of the model’s performance in practical applications. Recording the prediction time helps in understanding the model’s efficiency during inference.\n\ninput_X = test_neighbors\nX_new = []\nfor test_neighbor in input_X:\n    X_new.append(test_neighbor[0] + test_neighbor[1])\n    \n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.004464864730834961 seconds\n\ntest_rankings = [0 1 0 0 1 0], \ny_pred = [0 1 0 0 1 0], \ny_pred_proba = \n[[0.97218204 0.02781794]\n [0.00402802 0.995972  ]\n [0.99254835 0.00745166]\n [0.99486387 0.00513611]\n [0.07889068 0.9211093 ]\n [0.99056184 0.00943818]]\n\n\nCalculating the ambiguousness of the predicted probabilities helps in understanding the model’s confidence in its predictions. High ambiguousness indicates uncertain predictions, while low ambiguousness indicates confident predictions.\nAmbiguousness is calculated using the formula for entropy:\n\\[\nH(X) = - \\sum_{i} p(x_i) \\log_b p(x_i)\n\\]\nWhere in our case:\n\n\\(H(X)\\) is the ambiguousness of the random variable \\(X\\) - the set of probability scores for the predicted rankings,\n\\(p(x_i)\\) is probability score \\(x_i\\),\n\\(\\log_b\\) is the logarithm with base \\(b\\) (here \\(\\log_2\\) as we have two predicted values),\nThe sum is taken over all possible outcomes of \\(X\\).\n\nCalculating cumulative error rate and cumulative accuracy helps in understanding how the model’s performance evolves over the dataset.\nVisualizing the relationship between ambiguousness and error provides insights into how uncertainty in the model’s predictions correlates with its accuracy. This can help in identifying patterns and understanding the conditions under which the model performs well or poorly.\n\nfrom functions import calculate_ambiguousness\n\nerrors = np.abs(y_pred - np.array(test_rankings))\n\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9)))\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()\n\n                                                \n\n\n\n\n1.4.8 Hyperparameter Optimization\nIn the initial model the choice of hyperparameters was based on default values, examples from demo’s or trial and error. To improve the model’s performance, we applied a hyperparameter optimization technique to find the best set of hyperparameters. We used a grid search with cross-validation to find the optimal hyperparameters for the XGBoost model. The grid search was performed over a predefined set of hyperparameters, and the best hyperparameters were selected based on the model’s performance on the validation set. The best hyperparameters were then used to train the final model.\n\nfrom functions import compare_json\n\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n    \ndifferences = compare_json(model_params, best_trial_params)\n\nparams_tbl = pd.DataFrame(differences)\nparams_tbl.rename(index={'json1_value': 'base parameters', 'json2_value': 'optimized parameters'}, inplace=True)\nprint(params_tbl)\n\n                      max_depth     gamma  subsample  colsample_bytree  \\\nbase parameters               6  0.100000   0.800000          0.800000   \noptimized parameters          5  0.304548   0.781029          0.922528   \n\n                      learning_rate  n_estimators  \nbase parameters            0.100000           100  \noptimized parameters       0.239488           490  \n\n\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\n# Load the best trial parameters from a JSON file.\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=best_trial_params[\"max_depth\"],\n    min_child_weight=best_trial_params[\"min_child_weight\"],\n    gamma=best_trial_params[\"gamma\"],\n    subsample=best_trial_params[\"subsample\"],\n    colsample_bytree=best_trial_params[\"colsample_bytree\"],\n    learning_rate=best_trial_params[\"learning_rate\"],\n    n_estimators=best_trial_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\")\n\n\nTraining time: 0.36020803451538086 seconds\n\nTraining accuracy: 99.97%\n\n\n\n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.004562854766845703 seconds\n\ntest_rankings = [0 1 0 0 1 0], \ny_pred = [0 1 0 0 1 0], \ny_pred_proba = \n[[9.5283890e-01 4.7161117e-02]\n [1.6450882e-05 9.9998355e-01]\n [9.9937177e-01 6.2821433e-04]\n [9.9999166e-01 8.3718114e-06]\n [8.5286498e-03 9.9147135e-01]\n [9.9326497e-01 6.7350427e-03]]\n\n\n\nerrors = np.abs(y_pred - np.array(test_rankings))\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors, \"Schedules\": test_neighbors, \"Objectives\": test_objectives}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n\n\n\n\n\n\n\nAmbiguousness\nError\nSchedules\nObjectives\nCumulative error rate\nCumulative accuracy\n\n\n\n\n757\n3.321928e-09\n0\n([5, 0, 2, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n[29.27167190264852, 22.08056364258747]\n0.0\n1.0\n\n\n85\n3.321928e-09\n0\n([5, 3, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0,...\n[36.82335597592348, 22.700339918266497]\n0.0\n1.0\n\n\n181\n2.913796e-06\n0\n([7, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,...\n[39.958752516119404, 27.90929658917552]\n0.0\n1.0\n\n\n768\n2.913796e-06\n0\n([6, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,...\n[47.25699782218697, 32.81150132439508]\n0.0\n1.0\n\n\n353\n2.913796e-06\n0\n([4, 4, 1, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0,...\n[36.869197819247226, 26.235646300158415]\n0.0\n1.0\n\n\n\n\n\n\n\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9),\n                    customdata=df[[\"Schedules\", \"Objectives\"]],\n                    hovertemplate=\n                        \"Ambiguousness: %{x} &lt;br&gt;\" +\n                        \"Error: %{y} &lt;br&gt;\" +\n                        \"Schedules: %{customdata[0][0]} / %{customdata[0][1]} &lt;br&gt;\" +\n                        \"Objectives: %{customdata[1]} &lt;br&gt;\"\n                    ))\n                  \nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#results",
    "href": "xgboost-pairwise-ranking.html#results",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "1.5 Results",
    "text": "1.5 Results\nWe wanted to test whether an XGBoost classification model could be used to assess and rank the quality of pairs of schedules. For performance benchmarking we use the conventional calculation method utilizing Lindley recursions.\nWe trained the XGBoost ranking model with a limited set of features (schedules) and labels (objectives). The total number of possible schedules is approximately 52.0 million. For training and validation, we sampled 20000 schedules. Generating the feature and label set took a total of 18.9963 seconds, with the calculation of objective values accounting for 17.0961 seconds.\nThe model demonstrates strong and consistent performance with high accuracies both for training as well as testing, good generalization and stability. Total training time for the final model was 0.3602 seconds. The evaluation of 1000 test schedules took 0.0046 seconds for the the XGBoost model and 0.8984 for the conventional method, which is an improvement of 196X.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#discussion",
    "href": "xgboost-pairwise-ranking.html#discussion",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "1.6 Discussion",
    "text": "1.6 Discussion\n\ntraining_time = round(modeling_time, 4)\nconventional_time = round(evaluation_time, 4)\nxgboost_time = round(prediction_time, 4)\n\n# Define time values for plotting\ntime_values = np.linspace(0, training_time+0.1, 1000)  # 0 to 2 seconds\n\n# Calculate evaluations for method 1\nmethod1_evaluations = np.where(time_values &gt;= training_time, (time_values - training_time) / xgboost_time * 1000, 0)\n\n# Calculate evaluations for method 2\nmethod2_evaluations = time_values / conventional_time * 1000\n\n# Create line chart\nfig = go.Figure()\n\n# Add method 1 trace\nfig.add_trace(go.Scatter(x=time_values, y=method1_evaluations, mode='lines', name='Ranking model'))\n\n# Add method 2 trace\nfig.add_trace(go.Scatter(x=time_values, y=method2_evaluations, mode='lines', name='Conventional method'))\n\n# Update layout\nfig.update_layout(\n    title=\"Speed comparison between XGBoost ranking model and conventional method\",\n    xaxis_title=\"Time (seconds)\",\n    yaxis_title=\"Number of Evaluations\",\n    legend_title=\"Methods\",\n    template=\"plotly_white\"\n)\n\nfig.show()",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#timeline",
    "href": "xgboost-pairwise-ranking.html#timeline",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "1.7 Timeline",
    "text": "1.7 Timeline\n*This experiment was started on 25-07-2024. The completion date was 28-08-2024.**",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#references",
    "href": "xgboost-pairwise-ranking.html#references",
    "title": "1  XGBoost classification model for pairwise ranking",
    "section": "1.8 References",
    "text": "1.8 References\n\n\n\n\nHo, Y-C, C G Cassandras, C-H Chen, and L Dai. 2000. “Ordinal Optimisation and Simulation.” Journal of the Operational Research Society 51 (4): 490–500. https://doi.org/10.1057/palgrave.jors.2600906.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html",
    "href": "xgboost-objective-calc.html",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "",
    "text": "2.1 Objective\nCompare the performance (speed and accuracy) of a surrogate model (XGBoost regressor) with a conventional calculation for appointment scheduling objective function and against a ranking model.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#background",
    "href": "xgboost-objective-calc.html#background",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "2.2 Background",
    "text": "2.2 Background\nIn this experiment we’ll develop a Machine Learning model using XGBoost for evaluating a single schedule and let it compete with the conventional method as well as with the ranking model.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#hypothesis",
    "href": "xgboost-objective-calc.html#hypothesis",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "2.3 Hypothesis",
    "text": "2.3 Hypothesis\nWe expect a ranking model to be superior in speed compared to a XGBoost regressor model. The XGBoost regressor model will outperform the conventional model in speed.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#methodology",
    "href": "xgboost-objective-calc.html#methodology",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "2.4 Methodology",
    "text": "2.4 Methodology\n\n2.4.1 Tools and Materials\nWe use packages from Scikit-learn to prepare training data and evaluate the model and the XGBRegressor interface from the XGBoost library.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\nfrom sklearn.base import clone\nfrom sklearn.metrics import mean_squared_log_error\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\n\n\n\n2.4.2 Experimental Design\n\nfrom functions import get_v_star\nN = 12 # Number of patients\nT = 18 # Number of intervals\nd = 5 # Length of each interval\ns = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1] # Service times distribution\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.8 # Weight for the waiting time in objective function\nnum_schedules = 20000 # Number of schedules to sample\nv_star = get_v_star(T)\n\nWe will create a random set of pairs of neighboring schedules with \\(N = 12\\) patients and \\(\\ T = 18\\) intervals of length \\(d = 5\\).\nA neighbor of a schedule x is considered a schedule x’ where single patients have been shifted one interval to the left. Eg: ([2,1,1,2], [1,2,0,3]) are neighbors and ([2,1,1,2], [2,1,3,0]) are not, because [1,2,0,3] - [2,1,1,2] = [-1, 1, -1, 1] and [2,1,3,0] - [2,1,1,2] = [0, 0, 2, -2].\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.2\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. First all the paired schedules will be evaluated by computing the objective value. Then an XGBoost regressor model for predicting objective values will be trained and evaluated.\nThe model will be validated using a new sample of paired schedules the model has never seen (not in the training or the evaluation phase). All the objective values will be computed and the computation time will be recorded. Using the regressor model the objectives will be predicted and the prediciotn time will be measured. The predicted values will be compared to the actual values and the accuracy of the model will be assessed.\nIn order to be able to compare the objective regressor to the ranking model in the other experiment we will also predict the rankings of the paired schedules and compare them to the actual rankings. An opaqueness measure will be calculated for each prediction to assess the confidence of the model and relate it to accuracy.\n\n\n2.4.3 Variables\n\nIndependent Variables: A list of tuples with pairs of neighboring schedules.\nDependent Variables:\n\nA list of tuples with the objective values for each pair of neighboring schedules.\nLists with rankings for each tuple of pairwise schedules. Eg: If the rank for ([2,1,1], [1,1,2]) equals 0 this means that the schedule with index 0 ([2,1,1]) has the lowest objective value.\n\n\n\n\n2.4.4 Data Collection\nThe data set will be generated using simulation in which random samples will be drawn from the population of all possible schedules. For each sample a random neighboring schedule will be created.\n\n\n2.4.5 Sample Size and Selection\nSample Size: The total population size equals \\({{N + T -1}\\choose{N}} \\approx\\) 52.0 mln. For this experiment we will be using a relatively small sample of 20000 schedules.\nSample Selection: The samples will be drawn from a lexicographic order of possible schedules in order to accurately reflect the combinatorial nature of the problem and to ensure unbiased sampling from the entire combinatorial space.\n\n\n2.4.6 Data Collection\nThe data sample has been generated in an earlier experiment using simulation in which random samples were drawn from the population of all possible schedules.\n\n# Load the data from the pickle file\nwith open('neighbors_and_objectives.pkl', 'rb') as f:\n    data = pickle.load(f)\n\n# Extract the variables from the loaded data\nneighbors_list = data['neighbors_list']\nobjectives_list = data['objectives']\nrankings_list = data['rankings']\n\nprint(\"Data loaded successfully.\\n\")\nfor neigbors in neighbors_list[:2]: print(neigbors, \"\\n\")\nfor objectives in objectives_list[:2]: print(objectives, \"\\n\")\nfor rankings in rankings_list[:2]: print(rankings, \"\\n\")\n\nData loaded successfully.\n\n([3, 4, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 4, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n\n([5, 3, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [5, 3, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) \n\n[33.92084835176509, 40.85746812024389] \n\n[38.76980916837894, 39.52497576696366] \n\n0 \n\n0 \n\n\n\nThe experiment involves multiple steps, beginning with data preparation and concluding with model evaluation.The diagram below illustrates the sequence of steps.\n\n\n\n\n\ngraph TD\n    A[\"From population\"] --&gt;|\"Sample\"| B[\"Random subset\"]\n    B --&gt; |Create neighbors| C[\"Features: Schedule pairs\"]\n    C --&gt; |Calculate objectives| D[\"Labels: Objective values\"]\n    D --&gt; |Flatten lists| E[\"Features and labels\"]\n    E --&gt; |\"Split\"| F[\"Training set\"]\n    E --&gt; |\"Split\"| G[\"Test set\"]\n    F --&gt; |\"Train\"| H[\"Model\"]\n    H[\"Model\"] --&gt; |\"Apply\"| G[\"Test set\"]\n    G[\"Test set\"] --&gt; |\"Evaluate\"| I[\"Performance\"]\n\n\n\n\n\n\n\nPrepare the data for training the XGBoost regressor model.\n\n\n# Transform the schedule and objective data into lists of NumPy arrays\nX = [item for tup in neighbors_list for item in tup]\ny = [item for tup in objectives_list for item in tup]\nprint(f\"Flattened neighbors list: {X[:3]}\")\nprint(f\"Flattened objectives list: {y[:3]}\")\nprint(f\"Number of schedules: {len(X)}\")\n\nFlattened neighbors list: [[3, 4, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 4, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 3, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]]\nFlattened objectives list: [33.92084835176509, 40.85746812024389, 38.76980916837894]\nNumber of schedules: 40000\n\n\n\nRun hyperparameter optimization for the XGBoost regressor model and record the time taken to find the optimal hyperparameters.\n\n\n# #=========================================================================\n# # XGBoost regression: \n# # Parameters: \n# # n_estimators  \"Number of gradient boosted trees. Equivalent to number \n# #                of boosting rounds.\"\n# # learning_rate \"Boosting learning rate (also known as “eta”)\"\n# # max_depth     \"Maximum depth of a tree. Increasing this value will make \n# #                the model more complex and more likely to overfit.\" \n# #=========================================================================\n# regressor=xgb.XGBRegressor(eval_metric='rmsle')\n# \n# #=========================================================================\n# # exhaustively search for the optimal hyperparameters\n# #=========================================================================\n# from sklearn.model_selection import GridSearchCV\n# # set up our search grid\n# param_grid = {\"max_depth\":    [4, 5, 7],\n#               \"n_estimators\": [500, 700, 900],\n#               \"learning_rate\": [0.05, 0.1, 0.15]}\n# \n# # try out every combination of the above values\n# start = time.time()\n# search = GridSearchCV(regressor, param_grid, cv=5, verbose=3, n_jobs=-1).fit(X_train, y_train)\n# end = time.time()\n# hyper_search_time = end - start\n# print(f'Hyperparameter optimization time: {hyper_search_time}')\n# \n# print(\"The best hyperparameters are \",search.best_params_)\n\n\nTrain XGBoost regressor model to predict objective values from given schedules and measure training time.\n\n\nclass CustomCallback(TrainingCallback):\n    def __init__(self, period=10):\n        self.period = period\n\n    def after_iteration(self, model, epoch, evals_log):\n        if (epoch + 1) % self.period == 0:\n            print(f\"Epoch {epoch}, Evaluation log: {evals_log['validation_0']['rmse'][epoch]}\")\n        return False\n\ndef fit_and_score(estimator, X_train, X_test, y_train, y_test):\n    \"\"\"Fit the estimator on the train set and score it on both sets\"\"\"\n    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0)\n    \n    train_score = estimator.score(X_train, y_train)\n    test_score = estimator.score(X_test, y_test)\n\n    return estimator, train_score, test_score\n\n# Ensure that X and y are numpy arrays (convert if needed)\nX = np.array(X)  # Replace this with actual data\ny = np.array(y)  # Replace this with actual data\n\n# Check the shapes of X and y to ensure compatibility\nprint(f\"X shape: {X.shape}, y shape: {y.shape}\")\n\n# Use KFold instead of StratifiedKFold, as stratification is not necessary for regression\ncv = KFold(n_splits=5, shuffle=True, random_state=94)\n\n# Load the best trial parameters from a JSON file\nwith open(\"best_regressor_trial_params.json\", \"r\") as f:\n    model_params = json.load(f)\n\n# Initialize the XGBRegressor with the loaded parameters\nregressor = xgb.XGBRegressor(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n    callbacks=[CustomCallback(period=50)],\n)\n\nprint(\"Params: \")\nfor key, value in model_params.items():\n    print(f\" {key}: {value}\")\n\nstart = time.time()\nresults = []\n\nfor train_idx, test_idx in cv.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    \n    est, train_score, test_score = fit_and_score(\n        clone(regressor), X_train, X_test, y_train, y_test\n    )\n    results.append((est, train_score, test_score))\nend = time.time()\ntraining_time = end - start\nprint(f\"\\nTraining time: {training_time} seconds\\n\")\n\nX shape: (40000, 18), y shape: (40000,)\nParams: \n max_depth: 7\n min_child_weight: 8\n gamma: 0.014781560271184178\n subsample: 0.939540319301831\n colsample_bytree: 0.981185586324404\n learning_rate: 0.19710059853968986\n n_estimators: 339\nEpoch 49, Evaluation log: 0.7842675890542508\nEpoch 99, Evaluation log: 0.5841304745168888\nEpoch 149, Evaluation log: 0.5205105576054171\nEpoch 199, Evaluation log: 0.49100139293300615\nEpoch 249, Evaluation log: 0.4725865535197702\nEpoch 299, Evaluation log: 0.46768840443511245\nEpoch 49, Evaluation log: 0.8459649633654832\nEpoch 99, Evaluation log: 0.6707248343759513\nEpoch 149, Evaluation log: 0.612484916667559\nEpoch 199, Evaluation log: 0.5938950511994303\nEpoch 249, Evaluation log: 0.5831474784528811\nEpoch 299, Evaluation log: 0.5696855171251721\nEpoch 49, Evaluation log: 0.8168490844451659\nEpoch 99, Evaluation log: 0.620164837967189\nEpoch 149, Evaluation log: 0.5494073276576844\nEpoch 199, Evaluation log: 0.5259532836037151\nEpoch 249, Evaluation log: 0.5005621293366569\nEpoch 299, Evaluation log: 0.48866907252237435\nEpoch 49, Evaluation log: 0.8179180833280669\nEpoch 99, Evaluation log: 0.6199463741784181\nEpoch 149, Evaluation log: 0.5610159807146109\nEpoch 199, Evaluation log: 0.5346341440253888\nEpoch 249, Evaluation log: 0.5206202507814842\nEpoch 299, Evaluation log: 0.5038149767723248\nEpoch 49, Evaluation log: 0.8459593913794298\nEpoch 99, Evaluation log: 0.6399426459119163\nEpoch 149, Evaluation log: 0.5836571877365068\nEpoch 199, Evaluation log: 0.5576078958053741\nEpoch 249, Evaluation log: 0.5435028981273413\nEpoch 299, Evaluation log: 0.5367994961487046\n\nTraining time: 3.8138859272003174 seconds\n\n\n\n\n# Print results\nfor i, (est, train_score, test_score) in enumerate(results):\n    print(f\"Fold {i+1} - Train Score (R²): {train_score:.4f}, Test Score (R²): {test_score:.4f}\")\n\nFold 1 - Train Score (R²): 0.9988, Test Score (R²): 0.9982\nFold 2 - Train Score (R²): 0.9989, Test Score (R²): 0.9971\nFold 3 - Train Score (R²): 0.9988, Test Score (R²): 0.9980\nFold 4 - Train Score (R²): 0.9988, Test Score (R²): 0.9978\nFold 5 - Train Score (R²): 0.9987, Test Score (R²): 0.9975\n\n\n\n# regressor=xgb.XGBRegressor(learning_rate = search.best_params_[\"learning_rate\"],\n#                        n_estimators  = search.best_params_[\"n_estimators\"],\n#                        max_depth     = search.best_params_[\"max_depth\"],\n#                        eval_metric='rmsle')\n# \n# start = time.time()\n# regressor.fit(X_train, y_train)\n# end = time.time()\n# training_time = end - start\n# print(f\"\\nTraining time: {training_time} seconds\\n\")\n\n\nUse the trained model to predict the objective values for the test set and calculate the Mean Absolute Percentage Error (MAPE) between the predicted and true values.\n\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the XGBRegressor with the loaded parameters\nregressor = xgb.XGBRegressor(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n)\n\nregressor.fit(X_train, y_train)\nregressor.save_model('models/regressor.json')\npredictions = regressor.predict(X_test)\n\n# Calculate Mean Absolute Percentage Error (MAPE)\ndef mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\nmape = mean_absolute_percentage_error(y_test, predictions)\nprint(f'MAPE: {mape:.2f}%')\n\nMAPE: 0.75%\n\n\n\n# Create the scatter plot\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=y_test, \n    y=predictions, \n    mode='markers',\n    marker=dict(color='blue'),\n    name='Predictions vs. true values'\n))\nfig.add_trace(go.Scatter(\n    x=[0, max(max(y_test), max(predictions))],\n    y=[0, max(max(y_test), max(predictions))],\n    mode='lines',\n    line=dict(color='tomato', dash='dash'),\n    name='Base line',\n))\n\n# Add axis labels and a title\nfig.update_layout(\n    title='Predictions vs. true values',\n    xaxis_title='True values',\n    yaxis_title='Predictions',\n    showlegend=True\n)\n\n# Show the plot\nfig.show()\n\n                                                \n\n\n\n\n2.4.7 Validation\n\nCreate validation set with pairs of neighboring schedules and calculate their objectives. Measure calculation time.\n\n\nfrom functions import random_combination_with_replacement, create_neighbors_list, calculate_objective\n\nnum_test_schedules = 1000\n\ntest_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_neighbors = [create_neighbors_list(test_schedule, v_star) for test_schedule in test_schedules] # This can be done in parellel to improve speed\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\n# Start time measeurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_1 = [w * calculate_objective(test_neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[0], s, d, q)[1] for test_neighbor in test_neighbors]\nend = time.time()\nevaluation_time = end - start\nprint(f\"Evaluation time: {evaluation_time} seconds,\\nNumber of evaluated schedules: {len(test_schedules)}\\n\")\ntest_objectives_schedule_2 = [w * calculate_objective(test_neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[1], s, d, q)[1] for test_neighbor in test_neighbors]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nTotal number of combinations: 51,895,935\nSampled: 1000 schedules\n\nEvaluation time: 0.8680870532989502 seconds,\nNumber of evaluated schedules: 1000\n\nNeighbors: ([6, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [6, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]),\nObjectives: [45.52353226715654, 39.28968414105995], Ranking: 1\n\nNeighbors: ([6, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0], [6, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\nObjectives: [35.515142981242484, 40.420143342402774], Ranking: 0\n\nNeighbors: ([4, 4, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 3, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [40.75650171481233, 29.93577017017845], Ranking: 1\n\nNeighbors: ([5, 4, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 4, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [50.97612604849105, 59.37432141247381], Ranking: 0\n\nNeighbors: ([7, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [6, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [46.56245265301212, 33.6342448518005], Ranking: 1\n\nNeighbors: ([8, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [7, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [57.1136398876704, 43.64936609033637], Ranking: 1\n\n\n\n\nPredict for each schedule in the validation set the objectives using the regressor model. Measure prediction time.\n\n\ndef predict_objective(neighbors):\n    neighbors_array = [np.array(neighbor) for neighbor in neighbors] # Convert schedules to a NumPy array\n    neighbors_array = np.vstack(neighbors_array)\n    predictions = regressor.predict(neighbors_array)\n    return predictions\n\n# Start time measurement for the prediction\nstart = time.time()\npredictions = regressor.predict(test_schedules)\nend = time.time()\nprediction_time = end - start\nprint(f\"Prediction time: {prediction_time},\\nNumber of predicted schedules: {len(predictions)}\\n\")\n\n# Calculate the rankings based on the predicted objectives\npredictions = [predict_objective(neighbors) for neighbors in test_neighbors]\npred_rankings = [np.argmin(objectives) for objectives in predictions]\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nPredictions: {predictions[i]}, Ranking: {pred_rankings[i]}\\n\")\n\nPrediction time: 0.0039348602294921875,\nNumber of predicted schedules: 1000\n\nNeighbors: ([6, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [6, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]),\nPredictions: [45.412872 38.887188], Ranking: 1\n\nNeighbors: ([6, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0], [6, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\nPredictions: [35.4165  40.10864], Ranking: 0\n\nNeighbors: ([4, 4, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 3, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nPredictions: [40.62893  29.863707], Ranking: 1\n\nNeighbors: ([5, 4, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 4, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nPredictions: [50.934414 59.48574 ], Ranking: 0\n\nNeighbors: ([7, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [6, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]),\nPredictions: [46.498203 34.146675], Ranking: 1\n\nNeighbors: ([8, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [7, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nPredictions: [57.351826 43.583366], Ranking: 1\n\n\n\n\nCalculate opaqueness and accuracy comparing true and predicted rankings.\n\nOpaqueness is calculated using the formula for entropy:\n\\[\nH(X) = - \\sum_{i} p(x_i) \\log_b p(x_i)\n\\]\nWhere in our case:\n\n\\(H(X)\\) is the opaqueness of the random variable \\(X\\) - the set of predicted normalized objective values for each of the paired schedules,\n\\(p(x_i)\\) is the normalized outcome \\(x_i\\),\n\\(\\log_b\\) is the logarithm with base \\(b\\) (here \\(\\log_2\\) as we have two predicted values),\nThe sum is taken over all possible outcomes of \\(X\\).\n\n\nfrom functions import calculate_opaqueness\n\nerrors = np.abs(np.array(test_rankings) - pred_rankings)\naccuracy = 1 - errors.mean()\nprint(f\"Accuracy = {accuracy}\")\n\n# Calculate the opaqueness of each prediction\nnormalised_predictions = [prediction / np.sum(prediction) for prediction in predictions]\nopaqueness = [calculate_opaqueness(vector) for vector in normalised_predictions]\n\nAccuracy = 0.954\n\n\n\npredicted_values_left = [prediction[0] for prediction in predictions]\n\n\ndf = pd.DataFrame({\"Opaqueness\": opaqueness, \"Error\": errors, \"Predictions\": predictions}).sort_values(by=\"Opaqueness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\nprint(df.head())\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Opaqueness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9),\n                    text=[f'{prediction}' for prediction in df[\"Predictions\"]],))\nfig.add_trace(go.Scatter(x=df[\"Opaqueness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Opaqueness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Opaqueness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()\nfig.write_html(\"images/objective-results.html\")\n\n     Opaqueness  Error             Predictions  Cumulative error rate  \\\n639    0.941917      0  [31.386139, 17.584324]                    0.0   \n967    0.956972      0   [34.25956, 20.863909]                    0.0   \n398    0.963658      0  [26.794538, 17.004993]                    0.0   \n940    0.963955      0  [16.938108, 26.638329]                    0.0   \n79     0.965459      0  [30.839458, 19.802292]                    0.0   \n\n     Cumulative accuracy  \n639                  1.0  \n967                  1.0  \n398                  1.0  \n940                  1.0  \n79                   1.0",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#results",
    "href": "xgboost-objective-calc.html#results",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "2.5 Results",
    "text": "2.5 Results\nWe wanted to test whether an XGBoost regressor model could be used to assess the objective values schedules. For performance benchmarking we use the conventional calculation method utilizing Lindley recursions.\nWe trained the XGBoost regressor model with a limited set of features (schedules) and labels (objectives). The total number of possible schedules is approximately 52.0 million. For training and validation, we sampled 20000 schedules.\nThe model demonstrates strong and consistent performance with high prediction ability both for training as well as testing, good generalization and stability. Total training time for the final model was 3.8139 seconds. The evaluation of 1000 test schedules took 0.0039 seconds for the the XGBoost model and 0.8681 for the conventional method, which is an improvement of 220X.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#discussion",
    "href": "xgboost-objective-calc.html#discussion",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "2.6 Discussion",
    "text": "2.6 Discussion\n\ntraining_time = round(training_time, 4)\nconventional_time = round(evaluation_time, 4)\nxgboost_time = round(prediction_time, 4)\n\n# Define time values for plotting\ntime_values = np.linspace(0, training_time+0.1, 1000)  # 0 to 2 seconds\n\n# Calculate evaluations for method 1\nmethod1_evaluations = np.where(time_values &gt;= training_time, (time_values - training_time) / xgboost_time * 1000, 0)\n\n# Calculate evaluations for method 2\nmethod2_evaluations = time_values / conventional_time * 1000\n\n# Create line chart\nfig = go.Figure()\n\n# Add method 1 trace\nfig.add_trace(go.Scatter(x=time_values, y=method1_evaluations, mode='lines', name='Regressor model'))\n\n# Add method 2 trace\nfig.add_trace(go.Scatter(x=time_values, y=method2_evaluations, mode='lines', name='Conventional method'))\n\n# Update layout\nfig.update_layout(\n    title=\"Speed comparison between XGBoost regressor model and conventional method\",\n    xaxis_title=\"Time (seconds)\",\n    yaxis_title=\"Number of Evaluations\",\n    legend_title=\"Methods\",\n    template=\"plotly_white\"\n)\n\nfig.show()\nfig.write_html(\"images/objectives-speed.html\")",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#timeline",
    "href": "xgboost-objective-calc.html#timeline",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "2.7 Timeline",
    "text": "2.7 Timeline\nThis experiment was started on 30-08-2024. The expected completion date is 09-09-2024.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#references",
    "href": "xgboost-objective-calc.html#references",
    "title": "2  XGBoost regression model for objective calculation",
    "section": "2.8 References",
    "text": "2.8 References\nCite all sources that informed your experiment, including research papers, datasets, and tools. This section ensures that your work is properly grounded in existing research and that others can trace the origins of your methods and data.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html",
    "href": "local-search-regressor.html",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "",
    "text": "3.1 Objective\nTest the working and performance of a previously trained XGBoost Regressor model in a local search application.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html#background",
    "href": "local-search-regressor.html#background",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "3.2 Background",
    "text": "3.2 Background\nIn previous experiments, we trained an XGBoost Regressor model to predict the objective values of neighboring schedules. In this experiment, we will use the trained models to perform a local search to find the best schedule.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html#hypothesis",
    "href": "local-search-regressor.html#hypothesis",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "3.3 Hypothesis",
    "text": "3.3 Hypothesis\nThe XGBoost Regressor model will be able to efficiently guide the local search algorithm to find a schedule with a lower objective value than the initial schedule.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html#methodology",
    "href": "local-search-regressor.html#methodology",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "3.4 Methodology",
    "text": "3.4 Methodology\n\n3.4.1 Tools and Materials\n\nimport numpy as np\nfrom itertools import chain, combinations\nimport sys\nfrom math import comb  # Available in Python 3.8 and later\nimport xgboost as xgb\nfrom functions import calculate_objective\nimport pickle\n\n\n\n3.4.2 Experimental Design\nWe will use the trained XGBoost Regressor model to guide a local search algorithm to find the best schedule. The local search algorithm will start with an initial schedule and iteratively explore the neighborhood of the current schedule to find a better one. As an initial schedule, we will use the schedule with the lowest objective value from the training dataset that was used to train the XGBoost Regressor model.\n\n\n3.4.3 Variables\n\nIndependent Variables:\n\nThe trained XGBoost Regressor model.\n\nDependent Variables:\n\nSpeed, accuracy, and convergence of the local search algorithm.\n\n\n\n\n3.4.4 Data Collection\nWe will use the training dataset to initialize the local search algorithm.\n\n\n3.4.5 Sample Size and Selection\n\nN = 12 # Number of patients\nT = 18 # Number of intervals\nd = 5 # Length of each interval\ns = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1] # Service times distribution\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.8 # Weight for the waiting time in objective function\nnum_schedules = 20000 # Number of schedules to sample\n\n\n\n3.4.6 Experimental Procedure\n\n\n\n\n\n\nFigure 3.1: Local search algorithm",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html#results",
    "href": "local-search-regressor.html#results",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "3.5 Results",
    "text": "3.5 Results\n\n3.5.1 Load the initial best schedule.\nStart with the best solution found so far \\(\\{x^*, C(x^*)\\}\\) from the training set.\n\n# Load the best solution from the training dataset\nwith open('neighbors_and_objectives.pkl', 'rb') as f:\n    data = pickle.load(f)\n    \nprint(f\"The data has following keys: {[key for key in data.keys()]}\")\n\n# Step 1: Flatten the objectives into a 1D array\nflattened_data = [value for sublist in data['objectives'] for value in sublist]\n\n# Step 2: Find the index of the minimum value\nmin_index = np.argmin(flattened_data)\n\n# Step 3: Convert that index back to the original 2D structure\nrow_index = min_index // 2  # Assuming each inner list has 2 values\ncol_index = min_index % 2\n\nprint(f\"The minimum objective value is at index [{row_index}][{col_index}].\\nThis is schedule: {data['neighbors_list'][row_index][col_index]} with objective value {data['objectives'][row_index][col_index]}.\")\n\n# Set the initial schedule to the best solution from the training dataset\ninitial_schedule = data['neighbors_list'][row_index][col_index]\nN = sum(initial_schedule)\nT = len(initial_schedule)\n\nThe data has following keys: ['neighbors_list', 'objectives', 'rankings']\nThe minimum objective value is at index [1197][1].\nThis is schedule: [3, 1, 2, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] with objective value 11.154798314469787.\n\n\n\n\n3.5.2 Generate the neighborhood of \\(x^*\\).\n\n3.5.2.1 Set T\nSet \\(T\\) to the length of the vector \\(x^*\\).\n\nT = len(initial_schedule)\n\n\n\n3.5.2.2 Define \\(V^*\\).\nDefine the vectors \\(V^*\\) as follows:\n$$\n\\left\\{\n\\begin{array}{c}\n\\vec{v_1}, \\\\\n\\vec{v_2}, \\\\\n\\vec{v_3}, \\\\\n\\vdots \\\\\n\\vec{v_{T-1}}, \\\\\n\\vec{v_T} \\\\\n\\end{array}\n\\right\\} = \n\\left\\{\n\\begin{array}{c}\n(-1, 0,...., 0, 1), \\\\\n(1, -1, 0,...., 0), \\\\\n(0, 1, -1,...., 0), \\\\\n\\vdots \\\\\n(0,...., 1, -1, 0), \\\\\n(0,...., 0, 1, -1) \\\\\n\\end{array}\n\\right\\}\n$$\n\ndef get_v_star(t):\n    # Create an initial vector 'u' of zeros with length 't'\n    u = np.zeros(t, dtype=int)\n    # Set the first element of vector 'u' to -1\n    u[0] = -1\n    # Set the last element of vector 'u' to 1\n    u[-1] = 1\n    # Initialize the list 'v_star' with the initial vector 'u'\n    v_star = [u]\n    # Loop over the length of 'u' minus one times\n    for i in range(len(u) - 1):\n        # Append the last element of 'u' to the front of 'u'\n        u = np.append(u[-1], u)\n        # Remove the last element of 'u' to maintain the same length\n        u = np.delete(u, -1)\n        # Append the updated vector 'u' to the list 'v_star'\n        v_star.append(u)\n    # Convert the list of vectors 'v_star' into a NumPy array and return it\n    return(np.array(v_star))\n\n# Example of function call:\n# This will create a 4x4 matrix where each row is a cyclically shifted version of the first row\nget_v_star(4)\n\narray([[-1,  0,  0,  1],\n       [ 1, -1,  0,  0],\n       [ 0,  1, -1,  0],\n       [ 0,  0,  1, -1]])\n\n\n\n\n3.5.2.3 Define \\(U_t\\).\nDefine \\(U_t\\) as the set of all possible subsets of \\(V^*\\) such that each subset contains exactly \\(t\\) elements, i.e.,\n\\[\nU_t = \\{ S \\subsetneq V^* \\mid |S| = t \\}, \\quad t \\in \\{1, 2, \\dots, T\\}.\n\\]\n\ndef powerset(iterable, size=1):\n    \"powerset([1,2,3], 2) --&gt; (1,2) (1,3) (2,3)\"\n    return [[i for i in item] for item in combinations(iterable, size)]\n  \nx = initial_schedule\n\n# Generate a matrix 'v_star' using the 'get_v_star' function\nv_star = get_v_star(T)\n\n# Generate all possible non-empty subsets (powerset) of the set {0, 1, 2, ..., t-1}\n# 'ids' will be a list of tuples, where each tuple is a subset of indices\nsize = 2\nids = powerset(range(T), size)\nlen(ids)\nids[:T]\n\n[[0, 1],\n [0, 2],\n [0, 3],\n [0, 4],\n [0, 5],\n [0, 6],\n [0, 7],\n [0, 8],\n [0, 9],\n [0, 10],\n [0, 11],\n [0, 12],\n [0, 13],\n [0, 14],\n [0, 15],\n [0, 16],\n [0, 17],\n [1, 2]]\n\n\n\n\n3.5.2.4 Define the neighborhood of \\(x\\)\nDefine the neighborhood of \\(x\\) as all vectors of the form \\(x + u_{tk}\\) with \\(\\forall\\, u_{tk} \\in U_t\\).\n\nv_star = get_v_star(T)\n\ndef get_neighborhood(x, v_star, ids, verbose=False):\n    x = np.array(x)\n    p = 50\n    if verbose:\n        print(f\"Printing every {p}th result\")\n    # Initialize the list 'neighborhood' to store the vectors in the neighborhood of 'x'\n    neighborhood = []\n    # Loop over all possible non-empty subsets of indices\n    for i in range(len(ids)):\n        # Initialize the vector 'neighbor' to store the sum of vectors in 'v_star' corresponding to the indices in 'ids[i]'\n        neighbor = np.zeros(len(x), dtype=int)\n        # Loop over all indices in 'ids[i]'\n        for j in range(len(ids[i])):\n            if verbose:\n                print(f\"v_star{[ids[i][j]]}: {v_star[ids[i][j]]}\")\n            # Add the vector in 'v_star' corresponding to the index 'ids[i][j]' to 'neighbor'\n            neighbor += v_star[ids[i][j]]\n        # Append the vector 'x' plus 'neighbor' to the list 'neighborhood'\n        x_n = x + neighbor\n        if i%p==0:\n            if verbose:\n                print(f\"x, x', delta:\\n{x},\\n{x_n},\\n{neighbor}\\n----------------- \")\n        neighborhood.append(x_n)\n    \n    # Convert the list 'neighborhood' into a NumPy array\n    neighborhood = np.array(neighborhood)\n    if verbose:\n        print(f\"Size of raw neighborhood: {len(neighborhood)}\")\n    # Create a mask for rows with negative values\n    mask = ~np.any(neighborhood &lt; 0, axis=1)\n    # Filter out rows with negative values using the mask\n    if verbose:\n        print(f\"filtered out: {len(neighborhood)-mask.sum()} schedules with negative values.\")\n    filtered_neighborhood = neighborhood[mask]\n    if verbose:\n        print(f\"Size of filtered neighborhood: {len(filtered_neighborhood)}\")\n    return filtered_neighborhood\n\n# Example of function call:\n# This will generate the neighborhood of the vector 'x' using the vectors in 'v_star' and the indices in 'ids'\ntest_nh = get_neighborhood(x, v_star, ids)\nprint(f\"All neighborhoods with {size} patients switched:\\n x = {np.array(x)}: \\n {test_nh}\")\n\nAll neighborhoods with 2 patients switched:\n x = [3 1 2 1 1 2 0 1 0 0 0 0 0 0 0 0 0 1]: \n [[3 0 2 1 1 2 0 1 0 0 0 0 0 0 0 0 0 2]\n [2 2 1 1 1 2 0 1 0 0 0 0 0 0 0 0 0 2]\n [2 1 3 0 1 2 0 1 0 0 0 0 0 0 0 0 0 2]\n [2 1 2 2 0 2 0 1 0 0 0 0 0 0 0 0 0 2]\n [2 1 2 1 2 1 0 1 0 0 0 0 0 0 0 0 0 2]\n [2 1 2 1 1 2 1 0 0 0 0 0 0 0 0 0 0 2]\n [2 1 2 1 1 2 0 1 0 0 0 0 0 0 0 0 1 1]\n [4 1 1 1 1 2 0 1 0 0 0 0 0 0 0 0 0 1]\n [4 0 3 0 1 2 0 1 0 0 0 0 0 0 0 0 0 1]\n [4 0 2 2 0 2 0 1 0 0 0 0 0 0 0 0 0 1]\n [4 0 2 1 2 1 0 1 0 0 0 0 0 0 0 0 0 1]\n [4 0 2 1 1 2 1 0 0 0 0 0 0 0 0 0 0 1]\n [4 0 2 1 1 2 0 1 0 0 0 0 0 0 0 0 1 0]\n [3 2 2 0 1 2 0 1 0 0 0 0 0 0 0 0 0 1]\n [3 2 1 2 0 2 0 1 0 0 0 0 0 0 0 0 0 1]\n [3 2 1 1 2 1 0 1 0 0 0 0 0 0 0 0 0 1]\n [3 2 1 1 1 2 1 0 0 0 0 0 0 0 0 0 0 1]\n [3 2 1 1 1 2 0 1 0 0 0 0 0 0 0 0 1 0]\n [3 1 3 1 0 2 0 1 0 0 0 0 0 0 0 0 0 1]\n [3 1 3 0 2 1 0 1 0 0 0 0 0 0 0 0 0 1]\n [3 1 3 0 1 2 1 0 0 0 0 0 0 0 0 0 0 1]\n [3 1 3 0 1 2 0 1 0 0 0 0 0 0 0 0 1 0]\n [3 1 2 2 1 1 0 1 0 0 0 0 0 0 0 0 0 1]\n [3 1 2 2 0 2 1 0 0 0 0 0 0 0 0 0 0 1]\n [3 1 2 2 0 2 0 1 0 0 0 0 0 0 0 0 1 0]\n [3 1 2 1 2 1 1 0 0 0 0 0 0 0 0 0 0 1]\n [3 1 2 1 2 1 0 1 0 0 0 0 0 0 0 0 1 0]\n [3 1 2 1 1 3 0 0 0 0 0 0 0 0 0 0 0 1]\n [3 1 2 1 1 2 1 0 0 0 0 0 0 0 0 0 1 0]\n [3 1 2 1 1 2 0 1 0 0 0 0 0 0 0 1 0 0]]\n\n\n\n\n\n3.5.3 Local search algorithm\n1. Generate the neighborhood of $x^*$.\n2. For each vector $y$ in the neighborhood of $x^*$:\n  a.  Predict $C(y)$.\n  b.  If $C(y) &lt; C(x^*)$, set $x^* = y$ and go to 1\n\n3. Return $x^*$.\n\ndef local_search_predicted(x, v_star, regressor, size=2):\n    # Initialize the best solution found so far 'x_star' to the input vector 'x'\n    x_star = np.array(x).flatten()  # Keep as 1D array\n\n    # Initialize the best cost found so far 'C_star' to the cost of the input vector 'x'\n    x_star_dmatrix = xgb.DMatrix(x_star.reshape(1, -1))\n    c_star = regressor.predict(x_star_dmatrix)[0]\n\n    # Set the value of 'T' to the length of the input vector 'x'\n    T = len(x_star)\n\n    # Loop over all possible values of 't'\n    for t in range(1, size):\n        print(f'Running local search {t}')\n\n        # Generate the neighborhood of the current best solution 'x_star' with 't' patients switched\n        ids = powerset(range(T), t)\n        neighborhood = get_neighborhood(x_star, v_star, ids)\n        print(f\"Switching {t} patient(s). Size of neighborhood: {len(ids)}\")\n        \n        for neighbor in neighborhood:\n            neighbor_dmatrix = xgb.DMatrix(neighbor.reshape(1, -1))\n            cost = regressor.predict(neighbor_dmatrix)\n            if cost &lt; c_star:\n                x_star = neighbor\n                c_star = cost\n                result = [int(x) for x in x_star] # Convert x_star to list of integers\n                objectives = calculate_objective(result, s, d, q)\n                objective_value = w * objectives[0] + (1 - w) * objectives[1]\n                print(f\"Found better solution: {x_star}, pred_cost: {c_star}, real_cost: {objective_value}\")\n\n    # Return the best solution found 'x_star' as 1D array\n    return x_star, c_star, objective_value\n\n\ndef local_search(x, v_star, size=2):\n    # Initialize the best solution found so far 'x_star' to the input vector 'x'\n    x_star = np.array(x).flatten()  # Keep as 1D array\n\n    # Calculate initial objectives and cost\n    objectives_star = calculate_objective(x_star, s, d, q)\n    c_star = w * objectives_star[0] + (1 - w) * objectives_star[1]\n\n    # Set the value of 'T' to the length of the input vector 'x'\n    T = len(x_star)\n\n    # Loop over all possible values of 't'\n    for t in range(1, size):\n        print(f'Running local search {t}')\n\n        # Generate the neighborhood of the current best solution 'x_star' with 't' patients switched\n        ids = powerset(range(T), t)\n        neighborhood = get_neighborhood(x_star, v_star, ids)\n        print(f\"Switching {t} patient(s). Size of neighborhood: {len(ids)}\")\n\n        for neighbor in neighborhood:\n            # Calculate objectives for the neighbor\n            objectives = calculate_objective(neighbor, s, d, q)\n            cost = w * objectives[0] + (1 - w) * objectives[1]\n\n            # Compare scalar costs\n            if cost &lt; c_star:\n                x_star = neighbor\n                c_star = cost\n                print(f\"Found better solution: {x_star}, cost: {c_star}\")\n\n    # Return the best solution found 'x_star' and its cost\n    return x_star, c_star\n\n\n\n3.5.4 Run the local search algorithm\n\n# Example of using the local search algorithm with a regressor model\n# Load regressor model\nregressor = xgb.Booster()\nregressor.load_model(\"models/regressor.json\")\n\ntest = local_search_predicted(initial_schedule, v_star, regressor, T)\nprint(test)\nprint(f\"Best solution found: {test[0]}, with predicted cost: {test[1]} and real cost: {test[2]}\")\n\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 18\nFound better solution: [2 1 2 1 1 2 0 1 0 0 0 0 0 0 0 0 0 2], pred_cost: [7.7052813], real_cost: 7.660096612108859\nRunning local search 2\nSwitching 2 patient(s). Size of neighborhood: 153\nFound better solution: [1 2 1 1 1 2 0 1 0 0 0 0 0 0 0 0 0 3], pred_cost: [6.8521957], real_cost: 8.912169065349131\nFound better solution: [1 1 2 1 1 2 0 1 0 0 0 0 0 0 0 0 1 2], pred_cost: [4.8244953], real_cost: 5.446127674818565\nRunning local search 3\nSwitching 3 patient(s). Size of neighborhood: 816\nFound better solution: [1 1 1 1 1 2 0 1 0 0 0 0 0 0 0 0 1 3], pred_cost: [4.219187], real_cost: 6.811261644800006\nFound better solution: [1 0 2 1 1 2 0 1 0 0 0 0 0 0 0 0 2 2], pred_cost: [4.178016], real_cost: 7.903520716226568\nFound better solution: [0 2 1 1 1 2 0 1 0 0 0 0 0 0 0 1 0 3], pred_cost: [4.011073], real_cost: 8.912169065349127\nFound better solution: [0 2 1 1 1 2 0 1 0 0 0 0 0 0 0 0 2 2], pred_cost: [3.7777016], real_cost: 7.894940461957126\nFound better solution: [0 1 2 1 1 2 0 1 0 0 0 0 0 0 0 1 1 2], pred_cost: [3.339848], real_cost: 5.446127674818565\nRunning local search 4\nSwitching 4 patient(s). Size of neighborhood: 3060\nFound better solution: [0 1 1 1 1 2 0 1 0 0 0 0 0 0 1 0 1 3], pred_cost: [2.5395162], real_cost: 6.811261644800006\nFound better solution: [0 1 1 1 1 2 0 1 0 0 0 0 0 0 0 1 2 2], pred_cost: [1.1575596], real_cost: 5.794033041408006\nRunning local search 5\nSwitching 5 patient(s). Size of neighborhood: 8568\nRunning local search 6\nSwitching 6 patient(s). Size of neighborhood: 18564\nFound better solution: [0 1 0 1 1 2 0 1 0 0 0 0 0 0 1 1 2 2], pred_cost: [1.062134], real_cost: 5.794033041408006\nRunning local search 7\nSwitching 7 patient(s). Size of neighborhood: 31824\nFound better solution: [0 1 0 2 1 1 0 1 0 1 0 0 0 0 0 1 2 2], pred_cost: [0.4633214], real_cost: 6.260557201408006\nFound better solution: [0 1 0 1 2 1 1 0 0 1 0 0 0 0 0 1 2 2], pred_cost: [0.3822482], real_cost: 6.260557201408006\nFound better solution: [0 1 0 1 1 2 1 0 0 1 0 0 0 0 0 1 3 1], pred_cost: [0.17397752], real_cost: 8.312152662016008\nFound better solution: [0 1 0 1 1 2 0 1 0 1 0 0 0 0 0 2 2 1], pred_cost: [0.04072012], real_cost: 6.281370480803847\nRunning local search 8\nSwitching 8 patient(s). Size of neighborhood: 43758\nFound better solution: [0 1 0 1 1 2 0 2 0 1 0 0 0 0 0 1 2 1], pred_cost: [-0.18848653], real_cost: 5.268951040000005\nRunning local search 9\nSwitching 9 patient(s). Size of neighborhood: 48620\nRunning local search 10\nSwitching 10 patient(s). Size of neighborhood: 43758\nRunning local search 11\nSwitching 11 patient(s). Size of neighborhood: 31824\nRunning local search 12\nSwitching 12 patient(s). Size of neighborhood: 18564\nRunning local search 13\nSwitching 13 patient(s). Size of neighborhood: 8568\nFound better solution: [0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 2 1], pred_cost: [-0.18908274], real_cost: 2.030551040000001\nRunning local search 14\nSwitching 14 patient(s). Size of neighborhood: 3060\nRunning local search 15\nSwitching 15 patient(s). Size of neighborhood: 816\nFound better solution: [0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 2 1], pred_cost: [-0.5040771], real_cost: 2.030551040000001\nRunning local search 16\nSwitching 16 patient(s). Size of neighborhood: 153\nRunning local search 17\nSwitching 17 patient(s). Size of neighborhood: 18\n(array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 1]), array([-0.5040771], dtype=float32), 2.030551040000001)\nBest solution found: [0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 2 1], with predicted cost: [-0.5040771] and real cost: 2.030551040000001\n\n\n\n# Computing optimun solution with real cost\nprint(f\"Initial schedule: {test[0]}\")\ntest_x = local_search(test[0], v_star, T)\ntest_x_pred = np.array(test_x[0]).flatten()  # Keep as 1D array\ntest_x_pred_dmatrix = xgb.DMatrix(test_x_pred.reshape(1, -1))\ntest_c_star_pred = regressor.predict(test_x_pred_dmatrix)[0]\nprint(f\"Best solution found: {test_x [0]}, with true cost: {test_x [1]}, and predicted cost: {test_c_star_pred}\")\n\nInitial schedule: [0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 2 1]\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 18\nRunning local search 2\nSwitching 2 patient(s). Size of neighborhood: 153\nFound better solution: [0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1], cost: 0.0\nRunning local search 3\nSwitching 3 patient(s). Size of neighborhood: 816\nRunning local search 4\nSwitching 4 patient(s). Size of neighborhood: 3060\nRunning local search 5\nSwitching 5 patient(s). Size of neighborhood: 8568\nRunning local search 6\nSwitching 6 patient(s). Size of neighborhood: 18564\nRunning local search 7\nSwitching 7 patient(s). Size of neighborhood: 31824\nRunning local search 8\nSwitching 8 patient(s). Size of neighborhood: 43758\nRunning local search 9\nSwitching 9 patient(s). Size of neighborhood: 48620\nRunning local search 10\nSwitching 10 patient(s). Size of neighborhood: 43758\nRunning local search 11\nSwitching 11 patient(s). Size of neighborhood: 31824\nRunning local search 12\nSwitching 12 patient(s). Size of neighborhood: 18564\nRunning local search 13\nSwitching 13 patient(s). Size of neighborhood: 8568\nRunning local search 14\nSwitching 14 patient(s). Size of neighborhood: 3060\nRunning local search 15\nSwitching 15 patient(s). Size of neighborhood: 816\nRunning local search 16\nSwitching 16 patient(s). Size of neighborhood: 153\nRunning local search 17\nSwitching 17 patient(s). Size of neighborhood: 18\nBest solution found: [0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1], with true cost: 0.0, and predicted cost: 0.18796852231025696",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html#discussion",
    "href": "local-search-regressor.html#discussion",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "3.6 Discussion",
    "text": "3.6 Discussion\nAnalyze your results in this section. Discuss whether your hypothesis was supported, what the results mean, and the implications for future work. Address any anomalies or unexpected findings, and consider the broader impact of your results.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html#timeline",
    "href": "local-search-regressor.html#timeline",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "3.7 Timeline",
    "text": "3.7 Timeline\nDocument the duration and key dates of the experiment. This helps in project management and reproducibility.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor.html#references",
    "href": "local-search-regressor.html#references",
    "title": "3  Local search with trained XGBoost regressor model",
    "section": "3.8 References",
    "text": "3.8 References\nCite all sources that informed your experiment, including research papers, datasets, and tools. This section ensures that your work is properly grounded in existing research and that others can trace the origins of your methods and data.s",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html",
    "href": "xgboost-pairwise-ranking-large.html",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "",
    "text": "4.1 Objective\nObjective: Testing the performance of an XGBoost model trained for ranking pairwise schedules.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#background",
    "href": "xgboost-pairwise-ranking-large.html#background",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "4.2 Background",
    "text": "4.2 Background\nIn this experiment we develop a Machine Learning model using XGBoost that can evaluate two neighboring schedules and rank them according to preference. This ranking model can be applied to quickly guide the search process towards a ‘good enough’ solution.\nThe choice of using an ordinal model instead of a cardinal model is based on the consideration that it is significantly easier to determine whether alternative A is superior to B than to quantify the exact difference between A and B. This makes intuitive sense when considering the scenario of holding two identical-looking packages and deciding which one is heavier, as opposed to estimating the precise weight difference between them. (Ho et al. 2000).",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#hypothesis",
    "href": "xgboost-pairwise-ranking-large.html#hypothesis",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "4.3 Hypothesis",
    "text": "4.3 Hypothesis\nAn XGBoost ranking model achieves superior computational efficiency compared to evaluating each element of a pair individually, leading to faster overall performance in ranking tasks.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#methodology",
    "href": "xgboost-pairwise-ranking-large.html#methodology",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "4.4 Methodology",
    "text": "4.4 Methodology\n\n4.4.1 Tools and Materials\nWe use packages from Scikit-learn to prepare training data and evaluate the model and the XGBClassifier interface from the XGBoost library.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.base import clone\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\nimport random\nfrom scipy.optimize import minimize\nfrom itertools import combinations\n\n\n\n4.4.2 Experimental Design\nTo compare an XGBoost Machine Learning model with a simple evaluation of each individual element of the pair, we will use a pairwise ranking approach. The objective is to rank two neighboring schedules according to preference.\n\nfrom functions import compute_convolutions\n\nN = 22 # Number of patients\nT = 20 # Number of intervals\nd = 5 # Length of each interval\nmax_s = 20 # Maximum service time\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.1 # Weight for the waiting time in objective function\nl = 10\nnum_schedules = 100000 # Number of schedules to sample\n\n# Create service time distribution\ndef generate_weighted_list(max_s, l, i):\n    # Initialize an array of T+1 values, starting with zero\n    values = np.zeros(T + 1)\n    \n    # Objective function: Sum of squared differences between current weighted average and the desired l\n    def objective(x):\n        weighted_avg = np.dot(np.arange(1, T + 1), x) / np.sum(x)\n        return (weighted_avg - l) ** 2\n\n    # Constraint: The sum of the values from index 1 to T must be 1\n    constraints = ({\n        'type': 'eq',\n        'fun': lambda x: np.sum(x) - 1\n    })\n    \n    # Bounds: Each value should be between 0 and 1\n    bounds = [(0, 1)] * T\n\n    # Initial guess: Random distribution that sums to 1\n    initial_guess = np.random.dirichlet(np.ones(T))\n\n    # Optimization: Minimize the objective function subject to the sum and bounds constraints\n    result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n\n    # Set the values in the array (index 0 remains 0)\n    values[1:] = result.x\n\n    # Now we need to reorder the values as per the new requirement\n    first_part = np.sort(values[1:i+1])  # Sort the first 'i' values in ascending order\n    second_part = np.sort(values[i+1:])[::-1]  # Sort the remaining 'T-i' values in descending order\n    \n    # Combine the sorted parts back together\n    values[1:i+1] = first_part\n    values[i+1:] = second_part\n    \n    return values\n\ni = 5  # First 5 highest values in ascending order, rest in descending order\ns = generate_weighted_list(max_s, l, i)\nprint(s)\nprint(\"Sum:\", np.sum(s[1:]))  # This should be 1\nprint(\"Weighted service time:\", np.dot(np.arange(1, T + 1), s[1:]))  # This should be close to l\n\nconvolutions = compute_convolutions(s, N, q)\nfile_path_parameters = f\"datasets/parameters_{N}_{T}_{l}.pkl\"\nwith open(file_path_parameters, 'wb') as f:\n    pickle.dump({\n      'N': N,\n      'T': T,\n      'd': d,\n      'max_s': max_s,\n      'q': q,\n      'w': w,\n      'l': l,\n      'num_schedules': num_schedules,\n      'convolutions': convolutions\n      }, f)\n    print(f\"Data saved successfully to '{file_path_parameters}'\")\n\n[0.         0.0147001  0.02342236 0.03945559 0.16700115 0.16938116\n 0.13856396 0.09033693 0.08763717 0.05221984 0.05048468 0.02903124\n 0.02530015 0.02156219 0.02075647 0.01921377 0.0155514  0.01385018\n 0.00904409 0.00790201 0.00458555]\nSum: 1.0000000000006346\nWeighted service time: 7.205456443733393\nData saved successfully to 'datasets/parameters_22_20_10.pkl'\n\n\nWe will create a random set of pairs of neighboring schedules with \\(N = 22\\) patients and \\(T = 20\\) intervals of length \\(d = 5\\).\nA neighbor of a schedule x is considered a schedule x’ where single patients have been shifted one interval to the left. Eg: ([2,1,1,2], [1,2,0,3]) are neighbors and ([2,1,1,2], [2,1,3,0]) are not, because [1,2,0,3] - [2,1,1,2] = [-1, 1, -1, 1] and [2,1,3,0] - [2,1,1,2] = [0, 0, 2, -2].\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.2\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. The model will be trained to predict which of the two neighboring schedules has the lowest objective value. The prediction time will be recorded. Then the same schedules will be evaluated by computing the objective value and then ranked.\n\n\n4.4.3 Variables\n\nIndependent Variables: A list of tuples with pairs of neighboring schedules.\nDependent Variables: A list with rankings for each tuple of pairwise schedules. Eg: If the rank for ([2,1,1], [1,1,2]) equals 0 this means that the schedule with index 0 ([2,1,1]) has the lowest objective value.\n\n\n\n4.4.4 Data Collection\nThe data set will be generated using simulation in which random samples will be drawn from the population of all possible schedules. For each sample a random neighboring schedule will be created.\n\n\n4.4.5 Sample Size and Selection\nSample Size: The total population size equals \\({{N + T -1}\\choose{N}} \\approx\\) 244663.0 mln. For this experiment we will be using a relatively small sample of 100000 pairs of schedules.\nSample Selection: The samples will be drawn from a lexicographic order of possible schedules in order to accurately reflect the combinatorial nature of the problem and to ensure unbiased sampling from the entire combinatorial space.\n\n\n4.4.6 Experimental Procedure\nThe experiment involves multiple steps, beginning with data preparation and concluding with model evaluation.The diagram below illustrates the sequence of steps.\n\n\n\n\n\ngraph TD\n    A[\"From population\"] --&gt;|\"Sample\"| B[\"Random subset\"]\n    B --&gt; |Create neighbors| C[\"Features: Schedule pairs\"]\n    C --&gt; |Calculate objectives| D[\"Objective values\"]\n    D --&gt; |Rank objectives| E[\"Labels: Rankings\"]\n    E --&gt; |\"Split dataset\"| F[\"Training set\"]\n    E --&gt; |\"Split dataset\"| G[\"Test set\"]\n    F --&gt; |\"Train\"| H[\"Model\"]\n    H[\"Model\"] --&gt; |\"Apply\"| G[\"Test set\"]\n    G[\"Test set\"] --&gt; |\"Evaluate\"| I[\"Performance\"]\n\n\n\n\n\n\nStep 1: Randomly select a subset of schedules.\n\nfrom functions import create_random_schedules #random_combination_with_replacement\n\nstart = time.time()\n# schedules = random_combination_with_replacement(T, N, num_schedules)\nschedules = create_random_schedules(T, N, num_schedules)\nprint(f\"Sampled: {len(schedules):,} schedules\\n\")\nh = random.choices(range(len(schedules)), k=7)\nprint(f\"Sampled schedules: {h}\")\nfor i in h:\n    print(f\"Schedule: {schedules[i]}\")\nend = time.time()\ndata_prep_time = end - start\n\nprint(f\"\\nProcessing time: {data_prep_time} seconds\\n\")\n\nSampled: 100,000 schedules\n\nSampled schedules: [47745, 49171, 88152, 42829, 2704, 94038, 64904]\nSchedule: [1, 3, 2, 1, 0, 0, 2, 0, 0, 0, 3, 0, 3, 0, 0, 2, 2, 1, 2, 0]\nSchedule: [2, 2, 2, 0, 1, 0, 2, 0, 0, 1, 1, 3, 2, 1, 1, 0, 2, 1, 0, 1]\nSchedule: [0, 0, 0, 0, 1, 1, 3, 0, 0, 1, 1, 3, 0, 3, 1, 2, 1, 2, 0, 3]\nSchedule: [1, 2, 0, 0, 0, 3, 2, 2, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 3]\nSchedule: [0, 0, 0, 1, 1, 2, 3, 0, 0, 0, 1, 0, 4, 1, 2, 1, 2, 2, 2, 0]\nSchedule: [1, 1, 2, 1, 1, 0, 1, 0, 2, 2, 1, 0, 4, 0, 1, 1, 0, 2, 1, 1]\nSchedule: [4, 0, 0, 1, 2, 0, 2, 0, 3, 1, 4, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n\nProcessing time: 0.7331840991973877 seconds\n\n\n\nStep 2: Create pairs of neighboring schedules.\n\ndef create_neighbors_list(s: list[int], v_star: np.ndarray) -&gt; (list[int], list[int]):\n    \"\"\"\n    Create a set of pairs of schedules that are from the same neighborhood.\n    \n    Parameters:\n      s (list[int]): A list of integers with |s| = T and sum N.\n      v_star (np.ndarray): Precomputed vectors V* of length T.\n      \n    Returns:\n      tuple(list[int], list[int]): A pair of schedules.\n    \"\"\"\n    T = len(s)\n\n    # Precompute binomial coefficients (weights for random.choices)\n    binom_coeff = [math.comb(T, i) for i in range(1, T)]\n\n    # Choose a random value of i with the corresponding probability\n    i = random.choices(range(1, T), weights=binom_coeff)[0]\n\n    # Instead of generating the full list of combinations, sample one directly\n    j = random.sample(range(T), i)\n    \n    s_p = s.copy()\n    for k in j:\n        s_temp = np.array(s_p) + v_star[k]\n        s_temp = s_temp.astype(int)\n        if np.all(s_temp &gt;= 0):\n            s_p = s_temp.astype(int).tolist()\n        \n    return s, s_p\n    \ndef get_v_star(T):\n    # Create an initial vector 'u' of zeros with length 'T'\n    u = np.zeros(T)\n    u[0] = -1\n    u[-1] = 1\n    v_star = [u.copy()]\n\n    # Generate shifted versions of 'u'\n    for i in range(T - 1):\n        u = np.roll(u, 1)\n        v_star.append(u.copy())\n\n    return np.array(v_star)\n\nstart = time.time()\nv_star = get_v_star(T)\nneighbors_list = [create_neighbors_list(schedule, v_star) for schedule in schedules] # This can be done in parellel to improve speed\nend = time.time()\nfor i in h:\n    original_schedule = neighbors_list[i][0]\n    neighbor_schedule = neighbors_list[i][1]\n    difference = [int(x - y) for x, y in zip(neighbors_list[i][0], neighbors_list[i][1])]\n    print(f\"Neighbors\\n{original_schedule}\\n{neighbor_schedule}\\n{difference}\")\ntraining_set_feat_time = end - start\nprint(f\"\\nProcessing time: {training_set_feat_time} seconds\\n\")\n\nNeighbors\n[1, 3, 2, 1, 0, 0, 2, 0, 0, 0, 3, 0, 3, 0, 0, 2, 2, 1, 2, 0]\n[1, 2, 2, 1, 0, 0, 2, 0, 0, 0, 3, 0, 3, 0, 1, 1, 3, 0, 3, 0]\n[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, 1, -1, 0]\nNeighbors\n[2, 2, 2, 0, 1, 0, 2, 0, 0, 1, 1, 3, 2, 1, 1, 0, 2, 1, 0, 1]\n[1, 2, 2, 0, 1, 0, 2, 0, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 0, 2]\n[1, 0, 0, 0, 0, 0, 0, 0, -1, 1, -1, 1, 0, 0, 0, 0, 0, 0, 0, -1]\nNeighbors\n[0, 0, 0, 0, 1, 1, 3, 0, 0, 1, 1, 3, 0, 3, 1, 2, 1, 2, 0, 3]\n[0, 0, 0, 0, 1, 2, 2, 0, 1, 1, 0, 3, 0, 4, 1, 1, 1, 2, 0, 3]\n[0, 0, 0, 0, 0, -1, 1, 0, -1, 0, 1, 0, 0, -1, 0, 1, 0, 0, 0, 0]\nNeighbors\n[1, 2, 0, 0, 0, 3, 2, 2, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 3]\n[2, 1, 0, 0, 0, 4, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 0, 1, 1, 3]\n[-1, 1, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, 0]\nNeighbors\n[0, 0, 0, 1, 1, 2, 3, 0, 0, 0, 1, 0, 4, 1, 2, 1, 2, 2, 2, 0]\n[0, 0, 0, 2, 0, 2, 3, 0, 0, 0, 2, 0, 4, 0, 3, 0, 2, 3, 1, 0]\n[0, 0, 0, -1, 1, 0, 0, 0, 0, 0, -1, 0, 0, 1, -1, 1, 0, -1, 1, 0]\nNeighbors\n[1, 1, 2, 1, 1, 0, 1, 0, 2, 2, 1, 0, 4, 0, 1, 1, 0, 2, 1, 1]\n[0, 1, 2, 2, 0, 0, 1, 1, 1, 2, 1, 1, 3, 0, 2, 0, 0, 2, 2, 1]\n[1, 0, 0, -1, 1, 0, 0, -1, 1, 0, 0, -1, 1, 0, -1, 1, 0, 0, -1, 0]\nNeighbors\n[4, 0, 0, 1, 2, 0, 2, 0, 3, 1, 4, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n[3, 0, 1, 1, 2, 0, 1, 0, 4, 1, 3, 0, 2, 0, 1, 1, 1, 0, 0, 1]\n[1, 0, -1, 0, 0, 0, 1, 0, -1, 0, 1, 0, -1, 1, 0, -1, 0, 1, 0, -1]\n\nProcessing time: 10.87825894355774 seconds\n\n\n\nStep 3: For each schedule in each pair calculate the objective. For each pair save the index of the schedule that has the lowest objective value.\n\nfrom functions import calculate_objective_serv_time_lookup\n\n# objectives_schedule_1 = [w * calculate_objective_serv_time_lookup(neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(neighbor[0], s, d, q)[1] for neighbor in neighbors_list]\n# start = time.time()\n# objectives_schedule_2 = [w * calculate_objective(neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(neighbor[1], s, d, q)[1] for neighbor in neighbors_list]\nobjectives_schedule_1 = [\n    w * result[0] + (1 - w) * result[1]\n    for neighbor in neighbors_list\n    for result in [calculate_objective_serv_time_lookup(neighbor[0], d, convolutions)]\n]\nstart = time.time()\nobjectives_schedule_2 = [\n    w * result[0] + (1 - w) * result[1]\n    for neighbor in neighbors_list\n    for result in [calculate_objective_serv_time_lookup(neighbor[1], d, convolutions)]\n]\nend = time.time()\ntraining_set_lab_time = end - start\nobjectives = [[obj, objectives_schedule_2[i]] for i, obj in enumerate(objectives_schedule_1)]\nrankings = np.argmin(objectives, axis=1).tolist()\nfor i in range(5):\n    print(f\"Objectives: {objectives[i]}, Ranking: {rankings[i]}\")\n\nprint(f\"\\nProcessing time: {training_set_lab_time} seconds\\n\")\n\n# Saving neighbors_list and objectives to a pickle file\n\nfile_path_neighbors = f\"datasets/neighbors_and_objectives_{N}_{T}_{l}.pkl\"\nwith open(file_path_neighbors, 'wb') as f:\n    pickle.dump({'neighbors_list': neighbors_list, 'objectives': objectives, 'rankings': rankings}, f)\n    print(f\"Data saved successfully to '{file_path_neighbors}'\")\n\nObjectives: [81.2707368775113, 74.98339658289757], Ranking: 1\nObjectives: [69.86126608781181, 75.66374519649534], Ranking: 0\nObjectives: [80.18265497886782, 87.06918797799014], Ranking: 0\nObjectives: [84.3535393223155, 83.28247010905605], Ranking: 1\nObjectives: [66.86695054630184, 63.54314072087945], Ranking: 1\n\nProcessing time: 122.32050466537476 seconds\n\nData saved successfully to 'datasets/neighbors_and_objectives_22_20_10.pkl'\n\n\nStep 4: Create training and test sets.\n\n# Prepare the dataset\nX = []\nfor neighbors in neighbors_list:\n    X.append(neighbors[0] + neighbors[1])\n\nX = np.array(X)\ny = np.array(rankings)\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nStep 5: Train the XGBoost model.\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B[Initialize StratifiedKFold]\n    B --&gt; C[Initialize XGBClassifier]\n    C --&gt; D[Set results as empty list]\n    D --&gt; E[Loop through each split of cv split]\n    E --&gt; F[Get train and test indices]\n    F --&gt; G[Split X and y into X_train, X_test, y_train, y_test]\n    G --&gt; H[Clone the classifier]\n    H --&gt; I[Call fit_and_score function]\n    I --&gt; J[Fit the estimator]\n    J --&gt; K[Score on training set]\n    J --&gt; L[Score on test set]\n    K --&gt; M[Return estimator, train_score, test_score]\n    L --&gt; M\n    M --&gt; N[Append the results]\n    N --&gt; E\n    E --&gt; O[Loop ends]\n    O --&gt; P[Print results]\n    P --&gt; Q[End]\n\n\n\n\n\n\n\nclass CustomCallback(TrainingCallback):\n    def __init__(self, period=10):\n        self.period = period\n\n    def after_iteration(self, model, epoch, evals_log):\n        if (epoch + 1) % self.period == 0:\n            print(f\"Epoch {epoch}, Evaluation log: {evals_log['validation_0']['logloss'][epoch]}\")\n        return False\n    \ndef fit_and_score(estimator, X_train, X_test, y_train, y_test):\n    \"\"\"Fit the estimator on the train set and score it on both sets\"\"\"\n    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0\n    )\n\n    train_score = estimator.score(X_train, y_train)\n    test_score = estimator.score(X_test, y_test)\n\n    return estimator, train_score, test_score\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)\n\n# Initialize the XGBClassifier without early stopping here\n# Load the best trial parameters from a JSON file.\nwith open(\"model_params.json\", \"r\") as f:\n    model_params = json.load(f)\n    \n# Initialize the EarlyStopping callback with validation dataset\nearly_stop = xgb.callback.EarlyStopping(\n    rounds=10, metric_name='logloss', data_name='validation_0', save_best=True\n)\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n    early_stopping_rounds=9,\n    #callbacks=[CustomCallback(period=50), early_stop],\n    callbacks=[CustomCallback(period=50)],\n)\nprint(\"Params: \")\nfor key, value in model_params.items():\n    print(f\" {key}: {value}\")\n\nstart = time.time()\nresults = []\n\nfor train_idx, test_idx in cv.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    est, train_score, test_score = fit_and_score(\n        clone(clf), X_train, X_test, y_train, y_test\n    )\n    results.append((est, train_score, test_score))\nend = time.time()\ntraining_time = end - start\nprint(f\"\\nTraining time: {training_time} seconds\\n\")\n\nParams: \n max_depth: 6\n min_child_weight: 1\n gamma: 0.1\n subsample: 0.8\n colsample_bytree: 0.8\n learning_rate: 0.1\n n_estimators: 100\nEpoch 49, Evaluation log: 0.39888578372718764\nEpoch 99, Evaluation log: 0.35085373423276467\nEpoch 49, Evaluation log: 0.39998584845857693\nEpoch 99, Evaluation log: 0.35422567000192356\nEpoch 49, Evaluation log: 0.39949432109431365\nEpoch 99, Evaluation log: 0.352497755828721\nEpoch 49, Evaluation log: 0.3994420803423971\nEpoch 99, Evaluation log: 0.35151056314712625\nEpoch 49, Evaluation log: 0.39807213788484225\nEpoch 99, Evaluation log: 0.35018130926751767\n\nTraining time: 3.159844160079956 seconds\n\n\n\nStep 6: To evaluate the performance of the XGBoost ranking model, we will use Stratified K-Fold Cross-Validation with 5 splits, ensuring each fold maintains the same class distribution as the original dataset. Using StratifiedKFold(n_splits=5, shuffle=True, random_state=94), the dataset will be divided into five folds. In each iteration, the model will be trained on four folds and evaluated on the remaining fold. A custom callback, CustomCallback(period=10), will print the evaluation log every 10 epochs.\nThe fit_and_score function will fit the model and score it on both the training and test sets, storing the results for each fold. This provides insight into the model’s performance across different subsets of the data, helps in understanding how well the model generalizes to unseen data and identifies potential overfitting or underfitting issues. The overall processing time for the cross-validation will also be recorded.\n\n# Print results\nfor i, (est, train_score, test_score) in enumerate(results):\n    print(f\"Fold {i+1} - Train Score (Accuracy): {train_score:.4f}, Test Score (Accuracy): {test_score:.4f}\")\n\nFold 1 - Train Score (Accuracy): 0.8653, Test Score (Accuracy): 0.8575\nFold 2 - Train Score (Accuracy): 0.8644, Test Score (Accuracy): 0.8512\nFold 3 - Train Score (Accuracy): 0.8643, Test Score (Accuracy): 0.8559\nFold 4 - Train Score (Accuracy): 0.8660, Test Score (Accuracy): 0.8504\nFold 5 - Train Score (Accuracy): 0.8674, Test Score (Accuracy): 0.8535\n\n\nTraining the model on the entire dataset provides a final model that has learned from all available data. Recording the training time helps in understanding the computational efficiency and scalability of the model with the given hyperparameters.\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nclf.save_model('models/classifier_large_instance.json')\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\\n\")\n\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\nTraining accuracy: 86.44%\n\n\nTraining time: 0.4471580982208252 seconds\n\n\n\n\n\n4.4.7 Validation\nGenerating test schedules and calculating their objectives and rankings allows us to create a new dataset for evaluating the model’s performance on unseen data.\n\nnum_test_schedules = 1000\n\n#test_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_schedules = create_random_schedules(T, N, num_test_schedules)\n\ntest_neighbors = [create_neighbors_list(test_schedule, v_star) for test_schedule in test_schedules] # This can be done in parellel to improve speed\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\ntest_objectives_schedule_1 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[0], d, convolutions)]\n]\n# Start time measurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_2 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[1], d, convolutions)]\n]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\nend = time.time()\nevaluation_time = end - start\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\nprint(f\"\\nEvaluation time: {evaluation_time} seconds\\n\")\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nSampled: 1000 schedules\n\n\nEvaluation time: 1.1222620010375977 seconds\n\nNeighbors: ([0, 0, 0, 1, 3, 0, 1, 0, 1, 0, 2, 2, 0, 0, 3, 1, 1, 1, 5, 1], [0, 0, 0, 1, 3, 1, 0, 0, 1, 0, 3, 1, 0, 1, 3, 1, 1, 0, 5, 1]),\nObjectives: [85.78049833714549, 87.17014543597], Ranking: 0\n\nNeighbors: ([4, 3, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 2, 2, 0, 3], [3, 3, 1, 1, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 1, 2, 0, 4]),\nObjectives: [68.75122992818373, 64.84902484522401], Ranking: 1\n\nNeighbors: ([2, 2, 3, 0, 0, 3, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 0, 1, 3, 0], [2, 2, 2, 0, 1, 3, 0, 1, 0, 0, 3, 0, 2, 1, 0, 0, 0, 2, 2, 1]),\nObjectives: [73.0015118252496, 69.39398285309737], Ranking: 1\n\nNeighbors: ([0, 2, 0, 2, 0, 0, 4, 0, 3, 2, 1, 0, 2, 1, 1, 0, 1, 0, 3, 0], [1, 1, 0, 2, 0, 0, 4, 1, 3, 1, 1, 0, 2, 2, 0, 1, 0, 1, 2, 0]),\nObjectives: [84.654982021256, 83.28075533253462], Ranking: 1\n\nNeighbors: ([1, 1, 2, 3, 0, 1, 0, 3, 3, 0, 0, 0, 1, 0, 1, 1, 1, 1, 3, 0], [1, 1, 2, 2, 1, 0, 1, 2, 3, 0, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1]),\nObjectives: [71.40006631570213, 68.35741703605044], Ranking: 1\n\nNeighbors: ([2, 1, 1, 1, 2, 1, 1, 0, 1, 2, 3, 1, 2, 1, 0, 0, 1, 1, 1, 0], [2, 2, 0, 2, 2, 0, 1, 0, 1, 3, 2, 1, 2, 1, 0, 0, 2, 1, 0, 0]),\nObjectives: [73.45454054241097, 75.7120972917471], Ranking: 0\n\n\n\nMaking predictions on new data and comparing them to the actual rankings provides an evaluation of the model’s performance in practical applications. Recording the prediction time helps in understanding the model’s efficiency during inference.\n\ninput_X = test_neighbors\nX_new = []\nfor test_neighbor in input_X:\n    X_new.append(test_neighbor[0] + test_neighbor[1])\n    \n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.005290985107421875 seconds\n\ntest_rankings = [0 1 1 1 1 0], \ny_pred = [0 1 1 1 1 0], \ny_pred_proba = \n[[0.7399323  0.2600677 ]\n [0.47154093 0.5284591 ]\n [0.1181246  0.8818754 ]\n [0.07056803 0.929432  ]\n [0.1894933  0.8105067 ]\n [0.8681607  0.13183928]]\n\n\nCalculating the ambiguousness of the predicted probabilities helps in understanding the model’s confidence in its predictions. High ambiguousness indicates uncertain predictions, while low ambiguousness indicates confident predictions.\nAmbiguousness is calculated using the formula for entropy:\n\\[\nH(X) = - \\sum_{i} p(x_i) \\log_b p(x_i)\n\\]\nWhere in our case:\n\n\\(H(X)\\) is the ambiguousness of the random variable \\(X\\) - the set of probability scores for the predicted rankings,\n\\(p(x_i)\\) is probability score \\(x_i\\),\n\\(\\log_b\\) is the logarithm with base \\(b\\) (here \\(\\log_2\\) as we have two predicted values),\nThe sum is taken over all possible outcomes of \\(X\\).\n\nCalculating cumulative error rate and cumulative accuracy helps in understanding how the model’s performance evolves over the dataset.\nVisualizing the relationship between ambiguousness and error provides insights into how uncertainty in the model’s predictions correlates with its accuracy. This can help in identifying patterns and understanding the conditions under which the model performs well or poorly.\n\nfrom functions import calculate_ambiguousness\n\nerrors = np.abs(y_pred - np.array(test_rankings))\n\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9)))\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()\n\n                                                \n\n\n\n\n4.4.8 Hyperparameter Optimization\nIn the initial model the choice of hyperparameters was based on default values, examples from demo’s or trial and error. To improve the model’s performance, we applied a hyperparameter optimization technique to find the best set of hyperparameters. We used a grid search with cross-validation to find the optimal hyperparameters for the XGBoost model. The grid search was performed over a predefined set of hyperparameters, and the best hyperparameters were selected based on the model’s performance on the validation set. The best hyperparameters were then used to train the final model.\n\nfrom functions import compare_json\n\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n    \ndifferences = compare_json(model_params, best_trial_params)\n\nparams_tbl = pd.DataFrame(differences)\nparams_tbl.rename(index={'json1_value': 'base parameters', 'json2_value': 'optimized parameters'}, inplace=True)\nprint(params_tbl)\n\n                      max_depth     gamma  subsample  colsample_bytree  \\\nbase parameters               6  0.100000   0.800000          0.800000   \noptimized parameters          5  0.304548   0.781029          0.922528   \n\n                      learning_rate  n_estimators  \nbase parameters            0.100000           100  \noptimized parameters       0.239488           490  \n\n\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\n# Load the best trial parameters from a JSON file.\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=best_trial_params[\"max_depth\"],\n    min_child_weight=best_trial_params[\"min_child_weight\"],\n    gamma=best_trial_params[\"gamma\"],\n    subsample=best_trial_params[\"subsample\"],\n    colsample_bytree=best_trial_params[\"colsample_bytree\"],\n    learning_rate=best_trial_params[\"learning_rate\"],\n    n_estimators=best_trial_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\")\n\n\nTraining time: 1.8314552307128906 seconds\n\nTraining accuracy: 94.16%\n\n\n\n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.005810737609863281 seconds\n\ntest_rankings = [0 1 1 1 1 0], \ny_pred = [0 1 1 1 1 0], \ny_pred_proba = \n[[0.85928595 0.14071408]\n [0.13797253 0.86202747]\n [0.11790645 0.88209355]\n [0.0147208  0.9852792 ]\n [0.07304686 0.92695314]\n [0.9859452  0.01405478]]\n\n\n\nerrors = np.abs(y_pred - np.array(test_rankings))\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors, \"Schedules\": test_neighbors, \"Objectives\": test_objectives}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n\n\n\n\n\n\n\nAmbiguousness\nError\nSchedules\nObjectives\nCumulative error rate\nCumulative accuracy\n\n\n\n\n989\n0.000037\n0\n([0, 4, 1, 3, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 1,...\n[80.0908165241096, 72.43032177035644]\n0.0\n1.0\n\n\n980\n0.000264\n0\n([1, 4, 0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2,...\n[65.928665406435, 72.25024290110923]\n0.0\n1.0\n\n\n869\n0.000291\n0\n([1, 1, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2, 1,...\n[69.80214288003936, 78.798242576628]\n0.0\n1.0\n\n\n407\n0.000295\n0\n([0, 3, 1, 3, 4, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0,...\n[82.22401811719212, 74.58897159544897]\n0.0\n1.0\n\n\n318\n0.000335\n0\n([1, 0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 0, 1, 3, 2,...\n[83.75365189647391, 95.27827194620582]\n0.0\n1.0\n\n\n\n\n\n\n\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9),\n                    customdata=df[[\"Schedules\", \"Objectives\"]],\n                    hovertemplate=\n                        \"Ambiguousness: %{x} &lt;br&gt;\" +\n                        \"Error: %{y} &lt;br&gt;\" +\n                        \"Schedules: %{customdata[0][0]} / %{customdata[0][1]} &lt;br&gt;\" +\n                        \"Objectives: %{customdata[1]} &lt;br&gt;\"\n                    ))\n                  \nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#results",
    "href": "xgboost-pairwise-ranking-large.html#results",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "4.5 Results",
    "text": "4.5 Results\nWe wanted to test whether an XGBoost classification model could be used to assess and rank the quality of pairs of schedules. For performance benchmarking we use the conventional calculation method utilizing Lindley recursions.\nWe trained the XGBoost ranking model with a limited set of features (schedules) and labels (objectives). The total number of possible schedules is approximately 244663.0 million. For training and evaluation, we sampled 200000 schedules and corresponding neighbors. Generating the feature and label set took a total of 133.9319 seconds, with the calculation of objective values accounting for 122.3205 seconds.\nThe model demonstrates strong and consistent performance with high accuracies both for training, testing and validation (89.7%) with good generalization and stability. Total training time for the final model was 1.8315 seconds. The evaluation of 1000 test schedules took 0.0058 seconds for the the XGBoost model and 1.1223 for the conventional method, which is an improvement of 193X.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#discussion",
    "href": "xgboost-pairwise-ranking-large.html#discussion",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "4.6 Discussion",
    "text": "4.6 Discussion\n\ntraining_time = round(modeling_time, 4)\nconventional_time = round(evaluation_time, 4)\nxgboost_time = round(prediction_time, 4)\n\n# Define time values for plotting\ntime_values = np.linspace(0, training_time+0.1, 1000)  # 0 to 2 seconds\n\n# Calculate evaluations for method 1\nmethod1_evaluations = np.where(time_values &gt;= training_time, (time_values - training_time) / xgboost_time * 1000, 0)\n\n# Calculate evaluations for method 2\nmethod2_evaluations = time_values / conventional_time * 1000\n\n# Create line chart\nfig = go.Figure()\n\n# Add method 1 trace\nfig.add_trace(go.Scatter(x=time_values, y=method1_evaluations, mode='lines', name='Ranking model'))\n\n# Add method 2 trace\nfig.add_trace(go.Scatter(x=time_values, y=method2_evaluations, mode='lines', name='Conventional method'))\n\n# Update layout\nfig.update_layout(\n    title=\"Speed comparison between XGBoost ranking model and conventional method\",\n    xaxis_title=\"Time (seconds)\",\n    yaxis_title=\"Number of Evaluations\",\n    legend_title=\"Methods\",\n    template=\"plotly_white\"\n)\n\nfig.show()",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#timeline",
    "href": "xgboost-pairwise-ranking-large.html#timeline",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "4.7 Timeline",
    "text": "4.7 Timeline\nThis experiment was started on 15-10-2024. The expected completion date is 01-11-2024.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking-large.html#references",
    "href": "xgboost-pairwise-ranking-large.html#references",
    "title": "4  Large instance XGBoost classification model for pairwise ranking",
    "section": "4.8 References",
    "text": "4.8 References\n\n\n\n\nHo, Y-C, C G Cassandras, C-H Chen, and L Dai. 2000. “Ordinal Optimisation and Simulation.” Journal of the Operational Research Society 51 (4): 490–500. https://doi.org/10.1057/palgrave.jors.2600906.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Large instance XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html",
    "href": "xgboost-objective-calc-large.html",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "",
    "text": "5.1 Objective\nCompare the performance (speed and accuracy) of a surrogate model (XGBoost regressor) with a conventional calculation for appointment scheduling objective function and against a ranking model.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html#background",
    "href": "xgboost-objective-calc-large.html#background",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "5.2 Background",
    "text": "5.2 Background\nIn this experiment we’ll develop a Machine Learning model using XGBoost for evaluating a single schedule and let it compete with the conventional method as well as with the ranking model.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html#hypothesis",
    "href": "xgboost-objective-calc-large.html#hypothesis",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "5.3 Hypothesis",
    "text": "5.3 Hypothesis\nWe expect a ranking model to be superior in speed compared to a XGBoost regressor model. The XGBoost regressor model will outperform the conventional model in speed.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html#methodology",
    "href": "xgboost-objective-calc-large.html#methodology",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "5.4 Methodology",
    "text": "5.4 Methodology\n\n5.4.1 Tools and Materials\nWe use packages from Scikit-learn to prepare training data and evaluate the model and the XGBRegressor interface from the XGBoost library.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\nfrom sklearn.base import clone\nfrom sklearn.metrics import mean_squared_log_error\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\n\n\n\n5.4.2 Load Parameters\n\nfrom functions import get_v_star\nN = 22\nT = 20\nl = 10\n\nfile_path_parameters = f\"datasets/parameters_{N}_{T}_{l}.pkl\"\n# Load the data from the pickle file\nwith open(file_path_parameters, 'rb') as f:\n    data_params = pickle.load(f)\n    \nN = data_params['N'] # Number of patients\nT = data_params['T'] # Number of intervals\nd = data_params['d'] # Length of each interval\nmax_s = data_params['max_s'] # Maximum service time\nq = data_params['q'] # Probability of a scheduled patient not showing up\nw = data_params['w'] # Weight for the waiting time in objective function\nl = data_params['l']\nnum_schedules = data_params['num_schedules'] # Number of schedules to sample\nconvolutions = data_params['convolutions']\nv_star = get_v_star(T)\n\nfor key in data_params.keys():\n  print(f\"{key} = {data_params[key]}\")\n\nfor convolution in list(convolutions.items())[:2]: print(convolution, \"\\n\")\n\nN = 22\nT = 20\nd = 5\nmax_s = 20\nq = 0.2\nw = 0.1\nl = 10\nnum_schedules = 100000\nconvolutions = {1: [0.2, 0.011760082311389614, 0.018737887669852717, 0.03156447505670982, 0.13360091965816184, 0.13550492742489204, 0.1108511697139353, 0.07226954243956286, 0.07010973464572853, 0.041775869017845114, 0.04038774488928362, 0.023224990933043196, 0.02024011958205141, 0.017249748058332817, 0.016605178815719657, 0.015371018725734827, 0.012441116717360218, 0.011080147347236016, 0.007235275846378654, 0.00632161104533464, 0.003668440101954738], 2: array([0.00000000e+00, 2.94002058e-03, 4.85734634e-03, 8.44201652e-03,\n       3.47671175e-02, 3.92827554e-02, 3.92005578e-02, 3.82167303e-02,\n       5.78493269e-02, 6.98970091e-02, 8.02888289e-02, 7.61734696e-02,\n       7.41903730e-02, 6.69141946e-02, 6.10389588e-02, 5.24194843e-02,\n       4.52138495e-02, 3.88397799e-02, 3.43857713e-02, 3.07791506e-02,\n       2.74092159e-02, 2.36324898e-02, 2.04956521e-02, 1.75156273e-02,\n       1.43499891e-02, 1.09322432e-02, 7.94496249e-03, 5.86144073e-03,\n       4.31414707e-03, 3.17678814e-03, 2.39318264e-03, 1.78294201e-03,\n       1.37785690e-03, 1.04328529e-03, 7.73711124e-04, 5.38008712e-04,\n       3.54646204e-04, 2.15963641e-04, 1.16308898e-04, 5.79761287e-05,\n       1.68218160e-05]), 3: array([0.00000000e+00, 0.00000000e+00, 4.32186050e-05, 1.40265710e-04,\n       3.53869282e-04, 1.39144845e-03, 3.03403976e-03, 5.50805464e-03,\n       1.12045966e-02, 1.76075704e-02, 2.32499285e-02, 2.78477994e-02,\n       3.46910124e-02, 4.22505513e-02, 5.01159446e-02, 5.53915078e-02,\n       5.89758642e-02, 6.01215563e-02, 5.99423610e-02, 5.78632533e-02,\n       5.48655440e-02, 5.11004377e-02, 4.73564348e-02, 4.37070119e-02,\n       4.02402424e-02, 3.67137428e-02, 3.32503637e-02, 2.98707447e-02,\n       2.64939306e-02, 2.30340039e-02, 1.96059983e-02, 1.64060310e-02,\n       1.35696836e-02, 1.11162642e-02, 9.04724056e-03, 7.32634799e-03,\n       5.91852188e-03, 4.76814798e-03, 3.82017054e-03, 3.02750310e-03,\n       2.36485488e-03, 1.81485519e-03, 1.36839365e-03, 1.01155073e-03,\n       7.33111978e-04, 5.22631425e-04, 3.70472319e-04, 2.62868968e-04,\n       1.85973042e-04, 1.31237358e-04, 9.18363665e-05, 6.33417856e-05,\n       4.27658922e-05, 2.78349940e-05, 1.72697010e-05, 1.00584007e-05,\n       5.44928710e-06, 2.66671347e-06, 1.14360655e-06, 3.98778666e-07,\n       7.71372804e-08]), 4: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.35317940e-07,\n       3.07420208e-06, 1.01924845e-05, 4.14947126e-05, 1.21898778e-04,\n       2.95777252e-04, 7.29082488e-04, 1.54646029e-03, 2.86935326e-03,\n       5.03941842e-03, 8.10395568e-03, 1.18092601e-02, 1.58618976e-02,\n       2.04536739e-02, 2.55735385e-02, 3.10991933e-02, 3.64557423e-02,\n       4.12982386e-02, 4.52422233e-02, 4.82244237e-02, 5.00743660e-02,\n       5.08758176e-02, 5.06943477e-02, 4.97767772e-02, 4.82960629e-02,\n       4.64338380e-02, 4.42464571e-02, 4.18080229e-02, 3.91687504e-02,\n       3.63660273e-02, 3.34056615e-02, 3.03217052e-02, 2.71859440e-02,\n       2.40944965e-02, 2.11312208e-02, 1.83600898e-02, 1.58216111e-02,\n       1.35384972e-02, 1.15129032e-02, 9.73236987e-03, 8.17407196e-03,\n       6.81474447e-03, 5.63364260e-03, 4.61465608e-03, 3.74301056e-03,\n       3.00528177e-03, 2.38892841e-03, 1.88199499e-03, 1.47133129e-03,\n       1.14265141e-03, 8.81920749e-04, 6.76492739e-04, 5.15447656e-04,\n       3.89711426e-04, 2.91929513e-04, 2.16272111e-04, 1.58230534e-04,\n       1.14237711e-04, 8.13841253e-05, 5.72513050e-05, 3.98126390e-05,\n       2.74131488e-05, 1.87228096e-05, 1.26989339e-05, 8.53965213e-06,\n       5.67352874e-06, 3.70846579e-06, 2.37078715e-06, 1.47278678e-06,\n       8.81826178e-07, 5.03931537e-07, 2.71938862e-07, 1.36824477e-07,\n       6.31260223e-08, 2.59401007e-08, 9.09285656e-09, 2.43815942e-09,\n       3.53716866e-10]), 5: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       9.33923909e-09, 6.00717321e-08, 2.46902484e-07, 1.07610188e-06,\n       3.78698535e-06, 1.11512123e-05, 3.15944232e-05, 8.06113857e-05,\n       1.84183437e-04, 3.95885341e-04, 7.88467975e-04, 1.44458464e-03,\n       2.47203728e-03, 3.96941560e-03, 5.97657199e-03, 8.47242036e-03,\n       1.14461984e-02, 1.48794592e-02, 1.87230630e-02, 2.28366330e-02,\n       2.70364139e-02, 3.11077427e-02, 3.48702212e-02, 3.81571729e-02,\n       4.08581843e-02, 4.29024392e-02, 4.42869926e-02, 4.50429779e-02,\n       4.52336186e-02, 4.49162765e-02, 4.41490428e-02, 4.29821229e-02,\n       4.14631235e-02, 3.96294961e-02, 3.75191619e-02, 3.51774463e-02,\n       3.26629391e-02, 3.00419527e-02, 2.73820229e-02, 2.47453736e-02,\n       2.21856209e-02, 1.97446030e-02, 1.74513841e-02, 1.53226008e-02,\n       1.33653504e-02, 1.15802823e-02, 9.96465391e-03, 8.51356896e-03,\n       7.22081280e-03, 6.07917252e-03, 5.08067041e-03, 4.21619591e-03,\n       3.47527054e-03, 2.84619162e-03, 2.31662030e-03, 1.87419846e-03,\n       1.50708097e-03, 1.20430932e-03, 9.56050851e-04, 7.53703510e-04,\n       5.89859326e-04, 4.58170017e-04, 3.53185533e-04, 2.70214236e-04,\n       2.05223691e-04, 1.54767320e-04, 1.15924450e-04, 8.62487918e-05,\n       6.37294755e-05, 4.67470535e-05, 3.40192154e-05, 2.45424688e-05,\n       1.75382796e-05, 1.24053920e-05, 8.68073979e-06, 6.00804632e-06,\n       4.11318185e-06, 2.78627230e-06, 1.86818843e-06, 1.24005563e-06,\n       8.14650295e-07, 5.29162647e-07, 3.39183124e-07, 2.13861735e-07,\n       1.32118911e-07, 7.95975920e-08, 4.65104419e-08, 2.61928904e-08,\n       1.41105789e-08, 7.20777590e-09, 3.45396586e-09, 1.53149368e-09,\n       6.15952978e-10, 2.17751499e-10, 6.41611678e-11, 1.39753778e-11,\n       1.62198642e-12]), 6: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 1.37287775e-10, 1.10180766e-09, 5.40499885e-09,\n       2.55316766e-08, 1.02229543e-07, 3.47784439e-07, 1.10574507e-06,\n       3.22014854e-06, 8.52307587e-06, 2.11264440e-05, 4.89416545e-05,\n       1.05523845e-04, 2.13856975e-04, 4.08363978e-04, 7.34079216e-04,\n       1.24607635e-03, 2.00521331e-03, 3.06713884e-03, 4.47206830e-03,\n       6.24535758e-03, 8.39787265e-03, 1.09223889e-02, 1.37826874e-02,\n       1.69112845e-02, 2.02119297e-02, 2.35725940e-02, 2.68738686e-02,\n       3.00018540e-02, 3.28554743e-02, 3.53567448e-02, 3.74522177e-02,\n       3.91136858e-02, 4.03309189e-02, 4.11073798e-02, 4.14547538e-02,\n       4.13910230e-02, 4.09372197e-02, 4.01175990e-02, 3.89606711e-02,\n       3.75016933e-02, 3.57831259e-02, 3.38536058e-02, 3.17652874e-02,\n       2.95710087e-02, 2.73212957e-02, 2.50618484e-02, 2.28316953e-02,\n       2.06624890e-02, 1.85787536e-02, 1.65988553e-02, 1.47360638e-02,\n       1.29995281e-02, 1.13950216e-02, 9.92552138e-03, 8.59151109e-03,\n       7.39113288e-03, 6.32030752e-03, 5.37298875e-03, 4.54154197e-03,\n       3.81720641e-03, 3.19056551e-03, 2.65198600e-03, 2.19198636e-03,\n       1.80150953e-03, 1.47208951e-03, 1.19592787e-03, 9.65909979e-04,\n       7.75591871e-04, 6.19175625e-04, 4.91481166e-04, 3.87917772e-04,\n       3.04457667e-04, 2.37608519e-04, 1.84380001e-04, 1.42242049e-04,\n       1.09076944e-04, 8.31283342e-05, 6.29506788e-05, 4.73615618e-05,\n       3.53986572e-05, 2.62824219e-05, 1.93846973e-05, 1.42025740e-05,\n       1.03365475e-05, 7.47207578e-06, 5.36386711e-06, 3.82251455e-06,\n       2.70317029e-06, 1.89600968e-06, 1.31835177e-06, 9.08318477e-07,\n       6.19847121e-07, 4.18829190e-07, 2.80160067e-07, 1.85494460e-07,\n       1.21545372e-07, 7.87940292e-08, 5.05053384e-08, 3.19765210e-08,\n       1.99666483e-08, 1.22694135e-08, 7.39890897e-09, 4.36362584e-09,\n       2.50689903e-09, 1.39653646e-09, 7.50429849e-10, 3.86592194e-10,\n       1.89547068e-10, 8.76711109e-11, 3.78268355e-11, 1.49965203e-11,\n       5.34422400e-12, 1.65437230e-12, 4.19317279e-13, 7.69017545e-14,\n       7.43770003e-15]), 7: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 2.01814443e-12, 1.94122896e-11,\n       1.10677745e-10, 5.68315791e-10, 2.52131146e-09, 9.62258123e-09,\n       3.37784230e-08, 1.09215255e-07, 3.23867327e-07, 8.97823079e-07,\n       2.33562731e-06, 5.69512765e-06, 1.31015280e-05, 2.85202882e-05,\n       5.87647118e-05, 1.14886007e-04, 2.13592919e-04, 3.78099858e-04,\n       6.38267972e-04, 1.02976473e-03, 1.59153260e-03, 2.36191864e-03,\n       3.37514137e-03, 4.65842798e-03, 6.22917692e-03, 8.09127374e-03,\n       1.02319121e-02, 1.26199283e-02, 1.52069905e-02, 1.79305412e-02,\n       2.07185288e-02, 2.34945935e-02, 2.61838704e-02, 2.87177237e-02,\n       3.10373936e-02, 3.30953529e-02, 3.48554065e-02, 3.62916083e-02,\n       3.73871334e-02, 3.81328730e-02, 3.85265399e-02, 3.85722140e-02,\n       3.82805832e-02, 3.76692112e-02, 3.67625370e-02, 3.55912089e-02,\n       3.41908886e-02, 3.26005883e-02, 3.08608023e-02, 2.90116297e-02,\n       2.70911761e-02, 2.51343913e-02, 2.31724208e-02, 2.12323728e-02,\n       1.93373718e-02, 1.75067593e-02, 1.57563580e-02, 1.40987155e-02,\n       1.25432996e-02, 1.10966504e-02, 9.76254184e-03, 8.54219148e-03,\n       7.43453823e-03, 6.43657977e-03, 5.54374959e-03, 4.75030505e-03,\n       4.04969802e-03, 3.43490184e-03, 2.89867980e-03, 2.43379187e-03,\n       2.03314748e-03, 1.68991563e-03, 1.39760359e-03, 1.15011281e-03,\n       9.41778896e-04, 7.67399068e-04, 6.22248209e-04, 5.02082802e-04,\n       4.03132871e-04, 3.22082980e-04, 2.56044463e-04, 2.02521485e-04,\n       1.59373647e-04, 1.24777626e-04, 9.71898468e-05, 7.53114956e-05,\n       5.80564865e-05, 4.45225142e-05, 3.39650595e-05, 2.57741424e-05,\n       1.94536127e-05, 1.46027894e-05, 1.09003105e-05, 8.09009527e-06,\n       5.96931593e-06, 4.37824165e-06, 3.19177865e-06, 2.31250396e-06,\n       1.66498270e-06, 1.19116477e-06, 8.46673402e-07, 5.97822283e-07,\n       4.19226268e-07, 2.91896462e-07, 2.01731534e-07, 1.38333127e-07,\n       9.40847869e-08, 6.34434018e-08, 4.24001446e-08, 2.80745183e-08,\n       1.84110832e-08, 1.19542864e-08, 7.68208172e-09, 4.88348501e-09,\n       3.06887791e-09, 1.90465539e-09, 1.16595979e-09, 7.02839620e-10,\n       4.16318897e-10, 2.41709572e-10, 1.37140565e-10, 7.57799027e-11,\n       4.06220920e-11, 2.10304456e-11, 1.04607490e-11, 4.96879733e-12,\n       2.23721674e-12, 9.46117936e-13, 3.71359512e-13, 1.33106185e-13,\n       4.25521951e-14, 1.16981783e-14, 2.59774639e-15, 4.11409659e-16,\n       3.41059463e-17]), 8: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.96669307e-14,\n       3.32632359e-13, 2.16128295e-12, 1.20495904e-11, 5.83254011e-11,\n       2.44982264e-10, 9.37937964e-10, 3.31090086e-09, 1.07763075e-08,\n       3.27754187e-08, 9.37197103e-08, 2.52240817e-07, 6.42127344e-07,\n       1.55130357e-06, 3.56106697e-06, 7.78403657e-06, 1.62339430e-05,\n       3.23405268e-05, 6.16207471e-05, 1.12455479e-04, 1.96819590e-04,\n       3.30791101e-04, 5.34679044e-04, 8.32571530e-04, 1.25119762e-03,\n       1.81825202e-03, 2.56041648e-03, 3.50119906e-03, 4.65858915e-03,\n       6.04270414e-03, 7.65376161e-03, 9.48083281e-03, 1.15015825e-02,\n       1.36830855e-02, 1.59835591e-02, 1.83548561e-02, 2.07453258e-02,\n       2.31027057e-02, 2.53765994e-02, 2.75203688e-02, 2.94923504e-02,\n       3.12565581e-02, 3.27829693e-02, 3.40476137e-02, 3.50325988e-02,\n       3.57262235e-02, 3.61231503e-02, 3.62245560e-02, 3.60380999e-02,\n       3.55776239e-02, 3.48625294e-02, 3.39168622e-02, 3.27681720e-02,\n       3.14462686e-02, 2.99820016e-02, 2.84061785e-02, 2.67486884e-02,\n       2.50378470e-02, 2.32999409e-02, 2.15589337e-02, 1.98362846e-02,\n       1.81508401e-02, 1.65187689e-02, 1.49535343e-02, 1.34659095e-02,\n       1.20640461e-02, 1.07536041e-02, 9.53794025e-03, 8.41834816e-03,\n       7.39433321e-03, 6.46390441e-03, 5.62386379e-03, 4.87007810e-03,\n       4.19772307e-03, 3.60149645e-03, 3.07579985e-03, 2.61489219e-03,\n       2.21301827e-03, 1.86451598e-03, 1.56390469e-03, 1.30595630e-03,\n       1.08574960e-03, 8.98708674e-04, 7.40626363e-04, 6.07674253e-04,\n       4.96401246e-04, 4.03722969e-04, 3.26904421e-04, 2.63538065e-04,\n       2.11519238e-04, 1.69020315e-04, 1.34464629e-04, 1.06500865e-04,\n       8.39783503e-05, 6.59235857e-05, 5.15181907e-05, 4.00784542e-05,\n       3.10366016e-05, 2.39238636e-05, 1.83553737e-05, 1.40168654e-05,\n       1.06530900e-05, 8.05783422e-06, 6.06539235e-06, 4.54333360e-06,\n       3.38640636e-06, 2.51142976e-06, 1.85303697e-06, 1.36014968e-06,\n       9.93077528e-07, 7.21148556e-07, 5.20788255e-07, 3.73974252e-07,\n       2.67002539e-07, 1.89509349e-07, 1.33700650e-07, 9.37486958e-08,\n       6.53219310e-08, 4.52206751e-08, 3.10962522e-08, 2.12356780e-08,\n       1.43976318e-08, 9.68835673e-09, 6.46846181e-09, 4.28346429e-09,\n       2.81241920e-09, 1.83020494e-09, 1.18002634e-09, 7.53494695e-10,\n       4.76282755e-10, 2.97855405e-10, 1.84163557e-10, 1.12482006e-10,\n       6.77906759e-11, 4.02603155e-11, 2.35229019e-11, 1.34946492e-11,\n       7.58398118e-12, 4.16444181e-12, 2.22761842e-12, 1.15684434e-12,\n       5.81004596e-13, 2.80944221e-13, 1.30116794e-13, 5.73611648e-14,\n       2.38874283e-14, 9.30725023e-15, 3.35057381e-15, 1.09544511e-15,\n       3.17287149e-16, 7.83632125e-17, 1.54715185e-17, 2.15604527e-18,\n       1.56394527e-19]), 9: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       4.36106934e-16, 5.58459942e-15, 4.07326429e-14, 2.45831184e-13,\n       1.28546894e-12, 5.86419590e-12, 2.42542575e-11, 9.24187318e-11,\n       3.25655966e-10, 1.07235283e-09, 3.32274707e-09, 9.71469186e-09,\n       2.69127134e-08, 7.08902611e-08, 1.77886163e-07, 4.26123735e-07,\n       9.76353953e-07, 2.14259186e-06, 4.50900354e-06, 9.11105535e-06,\n       1.76955279e-05, 3.30670919e-05, 5.95131680e-05, 1.03269265e-04,\n       1.72957683e-04, 2.79915266e-04, 4.38314619e-04, 6.64990292e-04,\n       9.78924118e-04, 1.40039907e-03, 1.94986351e-03, 2.64655749e-03,\n       3.50698038e-03, 4.54332647e-03, 5.76206543e-03, 7.16284454e-03,\n       8.73785756e-03, 1.04717562e-02, 1.23421193e-02, 1.43204134e-02,\n       1.63733229e-02, 1.84642744e-02, 2.05549865e-02, 2.26069022e-02,\n       2.45824294e-02, 2.64459583e-02, 2.81646782e-02, 2.97092332e-02,\n       3.10542773e-02, 3.21789621e-02, 3.30673634e-02, 3.37088165e-02,\n       3.40981135e-02, 3.42355178e-02, 3.41265678e-02, 3.37816677e-02,\n       3.32154897e-02, 3.24462393e-02, 3.14948475e-02, 3.03841545e-02,\n       2.91381379e-02, 2.77812197e-02, 2.63376676e-02, 2.48310927e-02,\n       2.32840335e-02, 2.17176142e-02, 2.01512676e-02, 1.86025159e-02,\n       1.70868100e-02, 1.56174291e-02, 1.42054432e-02, 1.28597366e-02,\n       1.15870896e-02, 1.03923083e-02, 9.27839283e-03, 8.24672966e-03,\n       7.29729655e-03, 6.42886945e-03, 5.63922367e-03, 4.92532407e-03,\n       4.28350161e-03, 3.70961470e-03, 3.19919499e-03, 2.74757743e-03,\n       2.35001450e-03, 2.00177438e-03, 1.69822309e-03, 1.43489086e-03,\n       1.20752339e-03, 1.01211905e-03, 8.44953614e-04, 7.02594104e-04,\n       5.81903678e-04, 4.80039306e-04, 3.94443845e-04, 3.22833915e-04,\n       2.63184726e-04, 2.13712835e-04, 1.72857587e-04, 1.39261912e-04,\n       1.11752988e-04, 8.93232395e-05, 7.11120177e-05, 5.63882612e-05,\n       4.45343334e-05, 3.50311706e-05, 2.74448025e-05, 2.14142522e-05,\n       1.66407775e-05, 1.28783861e-05, 9.92553753e-06, 7.61793536e-06,\n       5.82230962e-06, 4.43108959e-06, 3.35787095e-06, 2.53358544e-06,\n       1.90328611e-06, 1.42346769e-06, 1.05984722e-06, 7.85537509e-07,\n       5.79552589e-07, 4.25591632e-07, 3.11054811e-07, 2.26251005e-07,\n       1.63763307e-07, 1.17943638e-07, 8.45124073e-08, 6.02431816e-08,\n       4.27157331e-08, 3.01237682e-08, 2.11260799e-08, 1.47319667e-08,\n       1.02135109e-08, 7.03877683e-09, 4.82120769e-09, 3.28149304e-09,\n       2.21898886e-09, 1.49041558e-09, 9.94073210e-10, 6.58215380e-10,\n       4.32540642e-10, 2.82005147e-10, 1.82352631e-10, 1.16905891e-10,\n       7.42784526e-11, 4.67528004e-11, 2.91382447e-11, 1.79717279e-11,\n       1.09623232e-11, 6.60786250e-12, 3.93238099e-12, 2.30779160e-12,\n       1.33384003e-12, 7.58050253e-13, 4.22857896e-13, 2.31044572e-13,\n       1.23362864e-13, 6.41965572e-14, 3.24624261e-14, 1.58972403e-14,\n       7.51018843e-15, 3.40733926e-15, 1.47676419e-15, 6.07524219e-16,\n       2.35369535e-16, 8.50209857e-17, 2.82606422e-17, 8.48996806e-18,\n       2.24638297e-18, 5.03260163e-19, 8.93969701e-20, 1.11224854e-20,\n       7.17154941e-22]), 10: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 6.41081679e-18, 9.23088394e-17, 7.46785395e-16,\n       4.86097235e-15, 2.72681056e-14, 1.33821167e-13, 5.93378980e-13,\n       2.42053289e-12, 9.14412398e-12, 3.22857479e-11, 1.07305613e-10,\n       3.37001018e-10, 1.00409751e-09, 2.84826926e-09, 7.71010932e-09,\n       1.99596188e-08, 4.95120014e-08, 1.17866285e-07, 2.69629248e-07,\n       5.93439977e-07, 1.25798181e-06, 2.57079664e-06, 5.06927180e-06,\n       9.65328668e-06, 1.77668521e-05, 3.16306961e-05, 5.45179106e-05,\n       9.10515099e-05, 1.47489422e-04, 2.31951454e-04, 3.54536947e-04,\n       5.27285221e-04, 7.63944251e-04, 1.07953145e-03, 1.48968920e-03,\n       2.00985770e-03, 2.65431146e-03, 3.43513054e-03, 4.36119672e-03,\n       5.43731097e-03, 6.66351902e-03, 8.03471129e-03, 9.54053146e-03,\n       1.11655932e-02, 1.28899689e-02, 1.46898879e-02, 1.65385709e-02,\n       1.84071274e-02, 2.02654584e-02, 2.20831247e-02, 2.38301614e-02,\n       2.54778310e-02, 2.69993212e-02, 2.83703842e-02, 2.95699139e-02,\n       3.05804397e-02, 3.13885169e-02, 3.19849851e-02, 3.23650781e-02,\n       3.25283755e-02, 3.24786013e-02, 3.22232899e-02, 3.17733470e-02,\n       3.11425420e-02, 3.03469637e-02, 2.94044696e-02, 2.83341512e-02,\n       2.71558277e-02, 2.58895793e-02, 2.45553213e-02, 2.31724233e-02,\n       2.17593747e-02, 2.03334993e-02, 1.89107236e-02, 1.75053990e-02,\n       1.61301818e-02, 1.47959682e-02, 1.35118814e-02, 1.22853051e-02,\n       1.11219559e-02, 1.00259851e-02, 9.00010389e-03, 8.04572215e-03,\n       7.16309602e-03, 6.35147847e-03, 5.60926896e-03, 4.93415921e-03,\n       4.32327241e-03, 3.77329405e-03, 3.28059249e-03, 2.84132801e-03,\n       2.45154952e-03, 2.10727818e-03, 1.80457807e-03, 1.53961416e-03,\n       1.30869838e-03, 1.10832467e-03, 9.35194382e-04, 7.86233024e-04,\n       6.58599786e-04, 5.49690857e-04, 4.57137689e-04, 3.78801151e-04,\n       3.12762470e-04, 2.57311722e-04, 2.10934601e-04, 1.72298064e-04,\n       1.40235389e-04, 1.13731103e-04, 9.19061280e-05, 7.40034399e-05,\n       5.93744522e-05, 4.74662583e-05, 3.78098316e-05, 3.00092222e-05,\n       2.37317646e-05, 1.86992761e-05, 1.46802120e-05, 1.14827291e-05,\n       8.94859567e-06, 6.94788498e-06, 5.37438330e-06, 4.14164200e-06,\n       3.17960559e-06, 2.43174910e-06, 1.85266191e-06, 1.40601993e-06,\n       1.06289284e-06, 8.00338501e-07, 6.00242011e-07, 4.48361645e-07,\n       3.33548966e-07, 2.47114555e-07, 1.82314821e-07, 1.33938890e-07,\n       9.79777251e-08, 7.13604119e-08, 5.17449992e-08, 3.73534035e-08,\n       2.68417109e-08, 1.91987696e-08, 1.36672803e-08, 9.68268688e-09,\n       6.82608385e-09, 4.78810285e-09, 3.34135764e-09, 2.31952409e-09,\n       1.60153746e-09, 1.09971486e-09, 7.50872793e-10, 5.09717580e-10,\n       3.43951949e-10, 2.30670528e-10, 1.53718568e-10, 1.01766754e-10,\n       6.69156534e-11, 4.36897630e-11, 2.83165783e-11, 1.82129674e-11,\n       1.16214266e-11, 7.35403839e-12, 4.61334294e-12, 2.86779455e-12,\n       1.76571434e-12, 1.07622530e-12, 6.48980865e-13, 3.86900717e-13,\n       2.27849582e-13, 1.32422273e-13, 7.58672388e-14, 4.27928002e-14,\n       2.37286641e-14, 1.29133611e-14, 6.88420719e-15, 3.58758708e-15,\n       1.82330531e-15, 9.01308195e-16, 4.32060783e-16, 2.00168371e-16,\n       8.92736583e-17, 3.81541282e-17, 1.55414177e-17, 5.99394710e-18,\n       2.17103280e-18, 7.30871249e-19, 2.25584021e-19, 6.26585699e-20,\n       1.52513864e-20, 3.12466633e-21, 5.04310338e-22, 5.66696825e-23,\n       3.28854993e-24]), 11: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 9.42396665e-20, 1.50710589e-18,\n       1.33928556e-17, 9.36609836e-17, 5.60665815e-16, 2.93889856e-15,\n       1.38846680e-14, 6.02499524e-14, 2.42242710e-13, 9.10334187e-13,\n       3.22061373e-12, 1.07752195e-11, 3.42305257e-11, 1.03619756e-10,\n       2.99675454e-10, 8.29892326e-10, 2.20511958e-09, 5.63110907e-09,\n       1.38395209e-08, 3.27767058e-08, 7.48862603e-08, 1.65215358e-07,\n       3.52283917e-07, 7.26570469e-07, 1.45052961e-06, 2.80508104e-06,\n       5.25812919e-06, 9.56042703e-06, 1.68725107e-05, 2.89230295e-05,\n       4.81934418e-05, 7.81172832e-05, 1.23275071e-04, 1.89559679e-04,\n       2.84283253e-04, 4.16196774e-04, 5.95397532e-04, 8.33107416e-04,\n       1.14131544e-03, 1.53229078e-03, 2.01798730e-03, 2.60937477e-03,\n       3.31574388e-03, 4.14403820e-03, 5.09826661e-03, 6.17904292e-03,\n       7.38328666e-03, 8.70410317e-03, 1.01308432e-02, 1.16493273e-02,\n       1.32422082e-02, 1.48894418e-02, 1.65688330e-02, 1.82566314e-02,\n       1.99281534e-02, 2.15584147e-02, 2.31227614e-02, 2.45974855e-02,\n       2.59604125e-02, 2.71914428e-02, 2.82730294e-02, 2.91905721e-02,\n       2.99327108e-02, 3.04915090e-02, 3.08625206e-02, 3.10447452e-02,\n       3.10404822e-02, 3.08550980e-02, 3.04967263e-02, 2.99759196e-02,\n       2.93052686e-02, 2.84990056e-02, 2.75726034e-02, 2.65423799e-02,\n       2.54251171e-02, 2.42377003e-02, 2.29967863e-02, 2.17185045e-02,\n       2.04181972e-02, 1.91102028e-02, 1.78076838e-02, 1.65225009e-02,\n       1.52651304e-02, 1.40446237e-02, 1.28686027e-02, 1.17432882e-02,\n       1.06735534e-02, 9.66300042e-03, 8.71405177e-03, 7.82805490e-03,\n       7.00539420e-03, 6.24560759e-03, 5.54750440e-03, 4.90928169e-03,\n       4.32863665e-03, 3.80287298e-03, 3.32899958e-03, 2.90382053e-03,\n       2.52401530e-03, 2.18620910e-03, 1.88703318e-03, 1.62317544e-03,\n       1.39142183e-03, 1.18868915e-03, 1.01205013e-03, 8.58751431e-04,\n       7.26225523e-04, 6.12097152e-04, 5.14185281e-04, 4.30501191e-04,\n       3.59243512e-04, 2.98790810e-04, 2.47692356e-04, 2.04657597e-04,\n       1.68544806e-04, 1.38349297e-04, 1.13191540e-04, 9.23054277e-05,\n       7.50269101e-05, 6.07831472e-05, 4.90822873e-05, 3.95039498e-05,\n       3.16904528e-05, 2.53388034e-05, 2.01934495e-05, 1.60397715e-05,\n       1.26982857e-05, 1.00195157e-05, 7.87948854e-06, 6.17580181e-06,\n       4.82421284e-06, 3.75569647e-06, 2.91392181e-06, 2.25309999e-06,\n       1.73615821e-06, 1.33319846e-06, 1.02020324e-06, 7.77954185e-07,\n       5.91132883e-07, 4.47576844e-07, 3.37666795e-07, 2.53824416e-07,\n       1.90102525e-07, 1.41852183e-07, 1.05453497e-07, 7.80988920e-08,\n       5.76193925e-08, 4.23459853e-08, 3.09994699e-08, 2.26033215e-08,\n       1.64150620e-08, 1.18724429e-08, 8.55142715e-09, 6.13352614e-09,\n       4.38051786e-09, 3.11496363e-09, 2.20525833e-09, 1.55420903e-09,\n       1.09034779e-09, 7.61353081e-10, 5.29090387e-10, 3.65890383e-10,\n       2.51768520e-10, 1.72357519e-10, 1.17377095e-10, 7.95066109e-11,\n       5.35584993e-11, 3.58750759e-11, 2.38905083e-11, 1.58142701e-11,\n       1.04035306e-11, 6.80032697e-12, 4.41568790e-12, 2.84761029e-12,\n       1.82331599e-12, 1.15882820e-12, 7.30833585e-13, 4.57209951e-13,\n       2.83630526e-13, 1.74404303e-13, 1.06251788e-13, 6.41025005e-14,\n       3.82763324e-14, 2.26061146e-14, 1.31961236e-14, 7.60731424e-15,\n       4.32683127e-15, 2.42546633e-15, 1.33837906e-15, 7.25984507e-16,\n       3.86522047e-16, 2.01640104e-16, 1.02874442e-16, 5.12204661e-17,\n       2.48287226e-17, 1.16864548e-17, 5.32499926e-18, 2.34082459e-18,\n       9.88782662e-19, 3.99471735e-19, 1.53498494e-19, 5.57202504e-20,\n       1.89477603e-20, 5.97146916e-21, 1.71976774e-21, 4.44029727e-22,\n       1.00024211e-22, 1.88714544e-23, 2.79008690e-24, 2.85847837e-25,\n       1.50798106e-26]), 12: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.38533279e-21,\n       2.43619271e-20, 2.35894613e-19, 1.76572026e-18, 1.12316803e-17,\n       6.25346330e-17, 3.13190723e-16, 1.43834459e-15, 6.12010719e-15,\n       2.43370556e-14, 9.11038310e-14, 3.22653157e-13, 1.08559751e-12,\n       3.48257368e-12, 1.06820458e-11, 3.14023204e-11, 8.86599786e-11,\n       2.40828968e-10, 6.30310514e-10, 1.59162382e-09, 3.88209812e-09,\n       9.15528199e-09, 2.08953695e-08, 4.61907672e-08, 9.89707724e-08,\n       2.05683876e-07, 4.14868361e-07, 8.12638746e-07, 1.54672415e-06,\n       2.86221924e-06, 5.15244983e-06, 9.02807538e-06, 1.54064997e-05,\n       2.56216533e-05, 4.15512284e-05, 6.57547191e-05, 1.01611577e-04,\n       1.53445093e-04, 2.26614953e-04, 3.27560463e-04, 4.63777514e-04,\n       6.43715661e-04, 8.76587026e-04, 1.17208597e-03, 1.54002680e-03,\n       1.98991549e-03, 2.53047881e-03, 3.16918011e-03, 3.91175327e-03,\n       4.76178567e-03, 5.72037698e-03, 6.78589395e-03, 7.95383298e-03,\n       9.21679442e-03, 1.05645649e-02, 1.19842984e-02, 1.34607850e-02,\n       1.49767916e-02, 1.65134628e-02, 1.80507680e-02, 1.95679817e-02,\n       2.10441834e-02, 2.24587644e-02, 2.37919236e-02, 2.50251393e-02,\n       2.61415973e-02, 2.71265631e-02, 2.79676833e-02, 2.86552090e-02,\n       2.91821363e-02, 2.95442636e-02, 2.97401703e-02, 2.97711237e-02,\n       2.96409246e-02, 2.93557001e-02, 2.89236559e-02, 2.83547970e-02,\n       2.76606279e-02, 2.68538394e-02, 2.59479928e-02, 2.49572080e-02,\n       2.38958629e-02, 2.27783124e-02, 2.16186307e-02, 2.04303841e-02,\n       1.92264347e-02, 1.80187799e-02, 1.68184262e-02, 1.56352970e-02,\n       1.44781739e-02, 1.33546669e-02, 1.22712123e-02, 1.12330938e-02,\n       1.02444845e-02, 9.30850444e-03, 8.42729320e-03, 7.60209112e-03,\n       6.83332844e-03, 6.12071837e-03, 5.46335165e-03, 4.85979042e-03,\n       4.30815926e-03, 3.80623185e-03, 3.35151186e-03, 2.94130729e-03,\n       2.57279751e-03, 2.24309269e-03, 1.94928570e-03, 1.68849631e-03,\n       1.45790829e-03, 1.25479951e-03, 1.07656574e-03, 9.20738622e-04,\n       7.84998350e-04, 6.67181807e-04, 5.65286639e-04, 4.77471941e-04,\n       4.02056124e-04, 3.37512485e-04, 2.82462988e-04, 2.35670696e-04,\n       1.96031248e-04, 1.62563727e-04, 1.34401190e-04, 1.10781130e-04,\n       9.10360340e-05, 7.45842233e-05, 6.09210723e-05, 4.96107107e-05,\n       4.02782614e-05, 3.26026541e-05, 2.63100328e-05, 2.11677567e-05,\n       1.69789843e-05, 1.35778185e-05, 1.08249847e-05, 8.60400636e-06,\n       6.81784300e-06, 5.38595064e-06, 4.24172642e-06, 3.33029889e-06,\n       2.60662740e-06, 2.03387539e-06, 1.58202506e-06, 1.22670328e-06,\n       9.48191081e-07, 7.30591969e-07, 5.61136590e-07, 4.29604057e-07,\n       3.27842386e-07, 2.49372769e-07, 1.89064418e-07, 1.42868489e-07,\n       1.07601263e-07, 8.07681788e-08, 6.04216081e-08, 4.50463592e-08,\n       3.34678764e-08, 2.47789271e-08, 1.82812851e-08, 1.34395260e-08,\n       9.84456153e-09, 7.18497427e-09, 5.22457134e-09, 3.78487770e-09,\n       2.73153524e-09, 1.96377813e-09, 1.40632067e-09, 1.00312957e-09,\n       7.12661797e-10, 5.04237657e-10, 3.55289537e-10, 2.49283299e-10,\n       1.74154221e-10, 1.21134912e-10, 8.38805923e-11, 5.78190003e-11,\n       3.96692805e-11, 2.70874389e-11, 1.84061944e-11, 1.24449228e-11,\n       8.37142051e-12, 5.60180588e-12, 3.72836419e-12, 2.46777297e-12,\n       1.62412419e-12, 1.06263910e-12, 6.91073979e-13, 4.46631065e-13,\n       2.86791081e-13, 1.82925433e-13, 1.15868612e-13, 7.28657989e-14,\n       4.54800942e-14, 2.81657643e-14, 1.73011512e-14, 1.05370333e-14,\n       6.36021294e-15, 3.80308019e-15, 2.25158054e-15, 1.31910268e-15,\n       7.64238556e-16, 4.37545839e-16, 2.47347852e-16, 1.37938289e-16,\n       7.58067831e-17, 4.10091232e-17, 2.18096494e-17, 1.13867183e-17,\n       5.82706542e-18, 2.91775862e-18, 1.42679591e-18, 6.79921440e-19,\n       3.14994035e-19, 1.41489837e-19, 6.14331479e-20, 2.56930623e-20,\n       1.03086390e-20, 3.94896889e-21, 1.43608750e-21, 4.92345757e-22,\n       1.57758738e-22, 4.67266441e-23, 1.26100067e-23, 3.04056678e-24,\n       6.37215894e-25, 1.11377398e-25, 1.51892401e-26, 1.42993046e-27,\n       6.91492272e-29]), 13: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       2.03645346e-23, 3.90570597e-22, 4.09294802e-21, 3.26740445e-20,\n       2.20074672e-19, 1.29571862e-18, 6.85013138e-18, 3.31566122e-17,\n       1.48626729e-16, 6.22488543e-16, 2.45384124e-15, 9.15296298e-15,\n       3.24449552e-14, 1.09697901e-13, 3.54815931e-13, 1.10062213e-12,\n       3.28124141e-12, 9.41881741e-12, 2.60732187e-11, 6.96999620e-11,\n       1.80149972e-10, 4.50671453e-10, 1.09224603e-09, 2.56674200e-09,\n       5.85294670e-09, 1.29597498e-08, 2.78818987e-08, 5.83183065e-08,\n       1.18653677e-07, 2.34950274e-07, 4.53007292e-07, 8.50902255e-07,\n       1.55778731e-06, 2.78099578e-06, 4.84361230e-06, 8.23444563e-06,\n       1.36716896e-05, 2.21803794e-05, 3.51820383e-05, 5.45927577e-05,\n       8.29235760e-05, 1.23374718e-04, 1.79913394e-04, 2.57323791e-04,\n       3.61217882e-04, 4.97996955e-04, 6.74756318e-04, 8.99129427e-04,\n       1.17907232e-03, 1.52259436e-03, 1.93744620e-03, 2.43078004e-03,\n       3.00880023e-03, 3.67642340e-03, 4.43696678e-03, 5.29188161e-03,\n       6.24054484e-03, 7.28011857e-03, 8.40548272e-03, 9.60924245e-03,\n       1.08818089e-02, 1.22115492e-02, 1.35850004e-02, 1.49871398e-02,\n       1.64017037e-02, 1.78115450e-02, 1.91990187e-02, 2.05463834e-02,\n       2.18362064e-02, 2.30517574e-02, 2.41773804e-02, 2.51988289e-02,\n       2.61035564e-02, 2.68809530e-02, 2.75225237e-02, 2.80220057e-02,\n       2.83754254e-02, 2.85810969e-02, 2.86395665e-02, 2.85535082e-02,\n       2.83275772e-02, 2.79682269e-02, 2.74834975e-02, 2.68827832e-02,\n       2.61765847e-02, 2.53762548e-02, 2.44937443e-02, 2.35413532e-02,\n       2.25314954e-02, 2.14764786e-02, 2.03883069e-02, 1.92785061e-02,\n       1.81579752e-02, 1.70368643e-02, 1.59244796e-02, 1.48292141e-02,\n       1.37585028e-02, 1.27188014e-02, 1.17155851e-02, 1.07533666e-02,\n       9.83572956e-03, 8.96537577e-03, 8.14418283e-03, 7.37327025e-03,\n       6.65307123e-03, 5.98340796e-03, 5.36356835e-03, 4.79238239e-03,\n       4.26829659e-03, 3.78944521e-03, 3.35371724e-03, 2.95881844e-03,\n       2.60232781e-03, 2.28174828e-03, 1.99455137e-03, 1.73821588e-03,\n       1.51026076e-03, 1.30827242e-03, 1.12992673e-03, 9.73006219e-04,\n       8.35412848e-04, 7.15176828e-04, 6.10461977e-04, 5.19568078e-04,\n       4.40930698e-04, 3.73118896e-04, 3.14831237e-04, 2.64890461e-04,\n       2.22237151e-04, 1.85922688e-04, 1.55101754e-04, 1.29024586e-04,\n       1.07029181e-04, 8.85335907e-05, 7.30284279e-05, 6.00696842e-05,\n       4.92719185e-05, 4.03018702e-05, 3.28725265e-05, 2.67376575e-05,\n       2.16868220e-05, 1.75408381e-05, 1.41477010e-05, 1.13789303e-05,\n       9.12631847e-06, 7.29905568e-06, 5.82120022e-06, 4.62946488e-06,\n       3.67129011e-06, 2.90317479e-06, 2.28923723e-06, 1.79998035e-06,\n       1.41123691e-06, 1.10327243e-06, 8.60025616e-07, 6.68467821e-07,\n       5.18065235e-07, 4.00329085e-07, 3.08441005e-07, 2.36942219e-07,\n       1.81476689e-07, 1.38579672e-07, 1.05504331e-07, 8.00800664e-08,\n       6.05972291e-08, 4.57136211e-08, 3.43789641e-08, 2.57740992e-08,\n       1.92622241e-08, 1.43499271e-08, 1.06561612e-08, 7.88763062e-09,\n       5.81933376e-09, 4.27923792e-09, 3.13625162e-09, 2.29081884e-09,\n       1.66758995e-09, 1.20973136e-09, 8.74523210e-10, 6.29966057e-10,\n       4.52174510e-10, 3.23382730e-10, 2.30423640e-10, 1.63573609e-10,\n       1.15678006e-10, 8.14917832e-11, 5.71840769e-11, 3.99674147e-11,\n       2.78212422e-11, 1.92865588e-11, 1.33139603e-11, 9.15163534e-12,\n       6.26313499e-12, 4.26723955e-12, 2.89416167e-12, 1.95377701e-12,\n       1.31267441e-12, 8.77646204e-13, 5.83861729e-13, 3.86431923e-13,\n       2.54418840e-13, 1.66600288e-13, 1.08488839e-13, 7.02433363e-14,\n       4.52125195e-14, 2.89243051e-14, 1.83877597e-14, 1.16134358e-14,\n       7.28543963e-15, 4.53840352e-15, 2.80661707e-15, 1.72252901e-15,\n       1.04884869e-15, 6.33386867e-16, 3.79199511e-16, 2.24970184e-16,\n       1.32201848e-16, 7.69095869e-17, 4.42694345e-17, 2.51959161e-17,\n       1.41693488e-17, 7.86718814e-18, 4.30881262e-18, 2.32563469e-18,\n       1.23567436e-18, 6.45549862e-19, 3.31169953e-19, 1.66587416e-19,\n       8.20379532e-20, 3.94828675e-20, 1.85345609e-20, 8.46836776e-21,\n       3.75676043e-21, 1.61377338e-21, 6.69179758e-22, 2.66912316e-22,\n       1.01981446e-22, 3.71431235e-23, 1.28203130e-23, 4.16374487e-24,\n       1.26120113e-24, 3.52291636e-25, 8.94211806e-26, 2.02192077e-26,\n       3.96034426e-27, 6.44642384e-28, 8.15757445e-29, 7.10343593e-30,\n       3.17087248e-31]), 14: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 2.99360754e-25, 6.21841341e-24, 7.01183368e-23,\n       5.94989411e-22, 4.23058835e-21, 2.62435430e-20, 1.45935430e-19,\n       7.41866492e-19, 3.49030578e-18, 1.53373245e-17, 6.34160189e-17,\n       2.48109289e-16, 9.22616758e-16, 3.27314531e-15, 1.11125563e-14,\n       3.61981591e-14, 1.13382635e-13, 3.42151905e-13, 9.96355740e-13,\n       2.80385611e-12, 7.63464938e-12, 2.01370304e-11, 5.14994184e-11,\n       1.27817863e-10, 3.08109602e-10, 7.21858855e-10, 1.64480116e-09,\n       3.64707854e-09, 7.87379025e-09, 1.65595844e-08, 3.39428473e-08,\n       6.78384953e-08, 1.32257813e-07, 2.51632393e-07, 4.67403404e-07,\n       8.47962659e-07, 1.50314879e-06, 2.60466399e-06, 4.41382276e-06,\n       7.31790297e-06, 1.18759748e-05, 1.88743864e-05, 2.93910777e-05,\n       4.48666168e-05, 6.71784048e-05, 9.87130316e-05, 1.42430469e-04,\n       2.01912872e-04, 2.81390383e-04, 3.85736704e-04, 5.20428277e-04,\n       6.91462824e-04, 9.05235498e-04, 1.16837384e-03, 1.48753586e-03,\n       1.86917838e-03, 2.31930533e-03, 2.84320733e-03, 3.44520463e-03,\n       4.12840561e-03, 4.89449186e-03, 5.74353970e-03, 6.67388582e-03,\n       7.68204260e-03, 8.76266694e-03, 9.90858389e-03, 1.11108650e-02,\n       1.23589596e-02, 1.36408751e-02, 1.49434012e-02, 1.62523728e-02,\n       1.75529609e-02, 1.88299855e-02, 2.00682387e-02, 2.12528080e-02,\n       2.23693904e-02, 2.34045868e-02, 2.43461685e-02, 2.51833096e-02,\n       2.59067780e-02, 2.65090839e-02, 2.69845816e-02, 2.73295251e-02,\n       2.75420797e-02, 2.76222894e-02, 2.75720057e-02, 2.73947806e-02,\n       2.70957290e-02, 2.66813655e-02, 2.61594215e-02, 2.55386483e-02,\n       2.48286118e-02, 2.40394848e-02, 2.31818417e-02, 2.22664599e-02,\n       2.13041342e-02, 2.03055036e-02, 1.92808973e-02, 1.82401994e-02,\n       1.71927329e-02, 1.61471667e-02, 1.51114412e-02, 1.40927164e-02,\n       1.30973375e-02, 1.21308199e-02, 1.11978503e-02, 1.03023017e-02,\n       9.44726203e-03, 8.63507317e-03, 7.86737809e-03, 7.14517512e-03,\n       6.46887667e-03, 5.83837087e-03, 5.25308460e-03, 4.71204638e-03,\n       4.21394791e-03, 3.75720335e-03, 3.34000531e-03, 2.96037712e-03,\n       2.61622077e-03, 2.30536025e-03, 2.02558015e-03, 1.77465941e-03,\n       1.55040044e-03, 1.35065354e-03, 1.17333708e-03, 1.01645360e-03,\n       8.78102207e-04, 7.56487542e-04, 6.49925848e-04, 5.56848348e-04,\n       4.75802381e-04, 4.05450614e-04, 3.44568684e-04, 2.92041546e-04,\n       2.46858830e-04, 2.08109443e-04, 1.74975648e-04, 1.46726803e-04,\n       1.22712940e-04, 1.02358304e-04, 8.51549905e-05, 7.06567464e-05,\n       5.84730314e-05, 4.82633759e-05, 3.97320795e-05, 3.26232737e-05,\n       2.67163607e-05, 2.18218302e-05, 1.77774517e-05, 1.44448282e-05,\n       1.17062989e-05, 9.46217007e-06, 7.62825311e-06, 6.13368788e-06,\n       4.91902746e-06, 3.93456127e-06, 3.13885385e-06, 2.49747728e-06,\n       1.98191645e-06, 1.56862771e-06, 1.23823273e-06, 9.74831092e-07,\n       7.65416287e-07, 5.99381744e-07, 4.68104439e-07, 3.64595324e-07,\n       2.83206914e-07, 2.19389608e-07, 1.69489341e-07, 1.30580171e-07,\n       1.00326254e-07, 7.68684556e-08, 5.87315180e-08, 4.47483221e-08,\n       3.39983087e-08, 2.57575816e-08, 1.94586116e-08, 1.46578064e-08,\n       1.10094956e-08, 8.24513308e-09, 6.15672516e-09, 4.58366931e-09,\n       3.40233656e-09, 2.51785263e-09, 1.85763509e-09, 1.36632824e-09,\n       1.00184634e-09, 7.32293064e-10, 5.33570898e-10, 3.87532186e-10,\n       2.80553823e-10, 2.02442174e-10, 1.45594526e-10, 1.04359126e-10,\n       7.45484110e-11, 5.30700243e-11, 3.76480570e-11, 2.66131766e-11,\n       1.87451619e-11, 1.31551680e-11, 9.19800390e-12, 6.40700150e-12,\n       4.44583046e-12, 3.07297649e-12, 2.11565008e-12, 1.45069177e-12,\n       9.90649384e-13, 6.73664043e-13, 4.56150875e-13, 3.07522287e-13,\n       2.06398568e-13, 1.37897231e-13, 9.17017330e-14, 6.06910139e-14,\n       3.99709976e-14, 2.61929945e-14, 1.70760483e-14, 1.10736429e-14,\n       7.14215819e-15, 4.58073114e-15, 2.92100564e-15, 1.85158215e-15,\n       1.16649193e-15, 7.30226752e-16, 4.54122949e-16, 2.80494314e-16,\n       1.72027058e-16, 1.04729702e-16, 6.32720314e-17, 3.79209977e-17,\n       2.25381618e-17, 1.32787886e-17, 7.75200435e-18, 4.48209791e-18,\n       2.56528853e-18, 1.45255173e-18, 8.13195877e-19, 4.49807523e-19,\n       2.45638031e-19, 1.32323836e-19, 7.02513212e-20, 3.67203122e-20,\n       1.88761369e-20, 9.53121690e-21, 4.72101486e-21, 2.29056012e-21,\n       1.08685663e-21, 5.03455084e-22, 2.27226245e-22, 9.97058283e-23,\n       4.24314042e-23, 1.74647230e-23, 6.93071117e-24, 2.64217713e-24,\n       9.63561022e-25, 3.34473987e-25, 1.09853384e-25, 3.38896067e-26,\n       9.73171705e-27, 2.57152104e-27, 6.15975592e-28, 1.31087492e-28,\n       2.40954239e-29, 3.66928849e-30, 4.33068881e-31, 3.50787893e-32,\n       1.45401947e-33]), 15: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 4.40063388e-27, 9.84230522e-26,\n       1.18820814e-24, 1.06840872e-23, 7.99818888e-23, 5.21153410e-22,\n       3.03900125e-21, 1.61767174e-20, 7.96307097e-20, 3.65945216e-19,\n       1.58185640e-18, 6.46926910e-18, 2.51470582e-17, 9.32681765e-17,\n       3.31113519e-16, 1.12817152e-15, 3.69760479e-15, 1.16806112e-14,\n       3.56243476e-14, 1.05053151e-13, 2.99929020e-13, 8.29993749e-13,\n       2.22854946e-12, 5.81108890e-12, 1.47277385e-11, 3.63059944e-11,\n       8.71113126e-11, 2.03558291e-10, 4.63513829e-10, 1.02900804e-09,\n       2.22824649e-09, 4.70856604e-09, 9.71351537e-09, 1.95703635e-08,\n       3.85231233e-08, 7.41147589e-08, 1.39413829e-07, 2.56496155e-07,\n       4.61727520e-07, 8.13538707e-07, 1.40352065e-06, 2.37176753e-06,\n       3.92742342e-06, 6.37530347e-06, 1.01492256e-05, 1.58522737e-05,\n       2.43036119e-05, 3.65906917e-05, 5.41247975e-05, 7.86969242e-05,\n       1.12530092e-04, 1.58323476e-04, 2.19283284e-04, 2.99135278e-04,\n       4.02114198e-04, 5.32926232e-04, 6.96681979e-04, 8.98798983e-04,\n       1.14487481e-03, 1.44053354e-03, 1.79125036e-03, 2.20216048e-03,\n       2.67785970e-03, 3.22220465e-03, 3.83812087e-03, 4.52742668e-03,\n       5.29068010e-03, 6.12705521e-03, 7.03425316e-03, 8.00845190e-03,\n       9.04429720e-03, 1.01349363e-02, 1.12720944e-02, 1.24461915e-02,\n       1.36464983e-02, 1.48613255e-02, 1.60782414e-02, 1.72843121e-02,\n       1.84663558e-02, 1.96112047e-02, 2.07059659e-02, 2.17382742e-02,\n       2.26965297e-02, 2.35701139e-02, 2.43495792e-02, 2.50268074e-02,\n       2.55951352e-02, 2.60494434e-02, 2.63862103e-02, 2.66035296e-02,\n       2.67010927e-02, 2.66801396e-02, 2.65433801e-02, 2.62948883e-02,\n       2.59399759e-02, 2.54850476e-02, 2.49374431e-02, 2.43052707e-02,\n       2.35972369e-02, 2.28224758e-02, 2.19903822e-02, 2.11104526e-02,\n       2.01921355e-02, 1.92446947e-02, 1.82770872e-02, 1.72978559e-02,\n       1.63150398e-02, 1.53361003e-02, 1.43678642e-02, 1.34164838e-02,\n       1.24874113e-02, 1.15853884e-02, 1.07144489e-02, 9.87793230e-03,\n       9.07850848e-03, 8.31821010e-03, 7.59847229e-03, 6.92017745e-03,\n       6.28370408e-03, 5.68897792e-03, 5.13552431e-03, 4.62252064e-03,\n       4.14884786e-03, 3.71314022e-03, 3.31383256e-03, 2.94920465e-03,\n       2.61742209e-03, 2.31657360e-03, 2.04470440e-03, 1.79984578e-03,\n       1.58004073e-03, 1.38336583e-03, 1.20794956e-03, 1.05198718e-03,\n       9.13752484e-04, 7.91606674e-04, 6.84004655e-04, 5.89499025e-04,\n       5.06742063e-04, 4.34485990e-04, 3.71581782e-04, 3.16976783e-04,\n       2.69711354e-04, 2.28914771e-04, 1.93800564e-04, 1.63661479e-04,\n       1.37864183e-04, 1.15843876e-04, 9.70988781e-05, 8.11853147e-05,\n       6.77119432e-05, 5.63351921e-05, 4.67544477e-05, 3.87076187e-05,\n       3.19669978e-05, 2.63354294e-05, 2.16427865e-05, 1.77427533e-05,\n       1.45099044e-05, 1.18370696e-05, 9.63296909e-06, 7.82010219e-06,\n       6.33287267e-06, 5.11593129e-06, 4.12271776e-06, 3.31418371e-06,\n       2.65767901e-06, 2.12598467e-06, 1.69647648e-06, 1.35040461e-06,\n       1.07227539e-06, 8.49323065e-07, 6.71059764e-07, 5.28893837e-07,\n       4.15807123e-07, 3.26083108e-07, 2.55078726e-07, 1.99033460e-07,\n       1.54910184e-07, 1.20262912e-07, 9.31272793e-08, 7.19301382e-08,\n       5.54151738e-08, 4.25819065e-08, 3.26358243e-08, 2.49477479e-08,\n       1.90208216e-08, 1.44637849e-08, 1.09693945e-08, 8.29706166e-09,\n       6.25892220e-09, 4.70869568e-09, 3.53280312e-09, 2.64330654e-09,\n       1.97231406e-09, 1.46755987e-09, 1.08892298e-09, 8.05693798e-10,\n       5.94434362e-10, 4.37308455e-10, 3.20782379e-10, 2.34617222e-10,\n       1.71089600e-10, 1.24390933e-10, 9.01657782e-11, 6.51581226e-11,\n       4.69412375e-11, 3.37119867e-11, 2.41347075e-11, 1.72230856e-11,\n       1.22510619e-11, 8.68584800e-12, 6.13772606e-12, 4.32254765e-12,\n       3.03381041e-12, 2.12193395e-12, 1.47892961e-12, 1.02709774e-12,\n       7.10722382e-13, 4.89988996e-13, 3.36545451e-13, 2.30273433e-13,\n       1.56948414e-13, 1.06549599e-13, 7.20436558e-14, 4.85125701e-14,\n       3.25305384e-14, 2.17204374e-14, 1.44392998e-14, 9.55612234e-15,\n       6.29550690e-15, 4.12806095e-15, 2.69387958e-15, 1.74934046e-15,\n       1.13026136e-15, 7.26495128e-16, 4.64486470e-16, 2.95347460e-16,\n       1.86742075e-16, 1.17388122e-16, 7.33496986e-17, 4.55489478e-17,\n       2.81042361e-17, 1.72258087e-17, 1.04856553e-17, 6.33731630e-18,\n       3.80177071e-18, 2.26310248e-18, 1.33633806e-18, 7.82467061e-19,\n       4.54133433e-19, 2.61145985e-19, 1.48717971e-19, 8.38306191e-20,\n       4.67475783e-20, 2.57731849e-20, 1.40391242e-20, 7.55019737e-21,\n       4.00568797e-21, 2.09468628e-21, 1.07862940e-21, 5.46371646e-22,\n       2.71942742e-22, 1.32833174e-22, 6.35905288e-23, 2.97918106e-23,\n       1.36370044e-23, 6.08815427e-24, 2.64569659e-24, 1.11667439e-24,\n       4.56637911e-25, 1.80410222e-25, 6.86445109e-26, 2.50613105e-26,\n       8.74147953e-27, 2.89827076e-27, 9.07854219e-28, 2.66679095e-28,\n       7.27869991e-29, 1.82447229e-29, 4.13662275e-30, 8.31267578e-31,\n       1.43910718e-31, 2.05852169e-32, 2.27620243e-33, 1.72345229e-34,\n       6.66747916e-36]), 16: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.46897709e-29,\n       1.54990222e-27, 1.99457116e-26, 1.89506071e-25, 1.49005213e-24,\n       1.01716332e-23, 6.20355569e-23, 3.44883078e-22, 1.77155938e-21,\n       8.49078097e-21, 3.82633511e-20, 1.63102574e-19, 6.60770657e-19,\n       2.55425337e-18, 9.45197345e-18, 3.35752493e-17, 1.14755677e-16,\n       3.78150912e-16, 1.20351672e-15, 3.70509964e-15, 1.10482465e-14,\n       3.19484217e-14, 8.96866346e-14, 2.44646546e-13, 6.49010824e-13,\n       1.67570783e-12, 4.21384582e-12, 1.03268043e-11, 2.46779623e-11,\n       5.75356512e-11, 1.30936121e-10, 2.90985510e-10, 6.31762918e-10,\n       1.34053411e-09, 2.78101425e-09, 5.64264932e-09, 1.12011905e-08,\n       2.17614955e-08, 4.13900262e-08, 7.70942861e-08, 1.40671050e-07,\n       2.51524559e-07, 4.40847003e-07, 7.57649743e-07, 1.27722323e-06,\n       2.11266958e-06, 3.43017340e-06, 5.46862949e-06, 8.56410822e-06,\n       1.31793922e-05, 1.99384523e-05, 2.96652552e-05, 4.34257238e-05,\n       6.25710567e-05, 8.87799930e-05, 1.24097066e-04, 1.70963481e-04,\n       2.32237047e-04, 3.11197648e-04, 4.11535080e-04, 5.37316689e-04,\n       6.92933158e-04, 8.83021854e-04, 1.11236836e-03, 1.38578807e-03,\n       1.70799091e-03, 2.08343323e-03, 2.51616186e-03, 3.00965566e-03,\n       3.56667047e-03, 4.18909326e-03, 4.87781089e-03, 5.63259893e-03,\n       6.45203477e-03, 7.33343914e-03, 8.27284860e-03, 9.26502117e-03,\n       1.03034757e-02, 1.13805650e-02, 1.24875806e-02, 1.36148876e-02,\n       1.47520852e-02, 1.58881887e-02, 1.70118284e-02, 1.81114586e-02,\n       1.91755720e-02, 2.01929133e-02, 2.11526855e-02, 2.20447449e-02,\n       2.28597794e-02, 2.35894654e-02, 2.42266017e-02, 2.47652160e-02,\n       2.52006437e-02, 2.55295779e-02, 2.57500896e-02, 2.58616211e-02,\n       2.58649514e-02, 2.57621373e-02, 2.55564337e-02, 2.52521927e-02,\n       2.48547496e-02, 2.43702948e-02, 2.38057386e-02, 2.31685698e-02,\n       2.24667138e-02, 2.17083916e-02, 2.09019833e-02, 2.00558980e-02,\n       1.91784540e-02, 1.82777681e-02, 1.73616581e-02, 1.64375578e-02,\n       1.55124455e-02, 1.45927866e-02, 1.36844890e-02, 1.27928726e-02,\n       1.19226503e-02, 1.10779214e-02, 1.02621746e-02, 9.47830177e-03,\n       8.72861795e-03, 8.01488991e-03, 7.33836934e-03, 6.69983068e-03,\n       6.09961207e-03, 5.53765833e-03, 5.01356505e-03, 4.52662273e-03,\n       4.07586029e-03, 3.66008720e-03, 3.27793377e-03, 2.92788892e-03,\n       2.60833542e-03, 2.31758197e-03, 2.05389230e-03, 1.81551103e-03,\n       1.60068634e-03, 1.40768947e-03, 1.23483133e-03, 1.08047608e-03,\n       9.43052206e-04, 8.21060998e-04, 7.13082885e-04, 6.17781704e-04,\n       5.33907230e-04, 4.60296150e-04, 3.95871716e-04, 3.39642306e-04,\n       2.90699053e-04, 2.48212767e-04, 2.11430284e-04, 1.79670407e-04,\n       1.52319562e-04, 1.28827290e-04, 1.08701665e-04, 9.15047293e-05,\n       7.68480033e-05, 6.43881319e-05, 5.38227082e-05, 4.48863051e-05,\n       3.73467379e-05, 3.10015726e-05, 2.56748877e-05, 2.12142909e-05,\n       1.74881875e-05, 1.43832952e-05, 1.18023942e-05, 9.66230175e-06,\n       7.89205846e-06, 6.43131059e-06, 5.22887505e-06, 4.24147149e-06,\n       3.43260704e-06, 2.77159923e-06, 2.23272360e-06, 1.79447281e-06,\n       1.43891522e-06, 1.15114166e-06, 9.18789941e-07, 7.31637658e-07,\n       5.81254742e-07, 4.60707942e-07, 3.64310359e-07, 2.87409874e-07,\n       2.26210991e-07, 1.77625328e-07, 1.39146527e-07, 1.08745940e-07,\n       8.47859009e-08, 6.59478484e-08, 5.11729329e-08, 3.96130917e-08,\n       3.05908654e-08, 2.35664952e-08, 1.81110583e-08, 1.38846010e-08,\n       1.06183889e-08, 8.10054360e-09, 6.16445113e-09, 4.67943613e-09,\n       3.54327918e-09, 2.67623078e-09, 2.01623622e-09, 1.51513718e-09,\n       1.13565894e-09, 8.49027461e-10, 6.33090073e-10, 4.70837450e-10,\n       3.49244570e-10, 2.58364347e-10, 1.90620887e-10, 1.40259963e-10,\n       1.02922957e-10, 7.53174554e-11, 5.49633277e-11, 3.99975231e-11,\n       2.90244586e-11, 2.10016730e-11, 1.51526880e-11, 1.09007977e-11,\n       7.81890507e-12, 5.59162910e-12, 3.98676508e-12, 2.83385300e-12,\n       2.00813198e-12, 1.41856310e-12, 9.98916200e-13, 7.01156923e-13,\n       4.90555544e-13, 3.42080369e-13, 2.37746693e-13, 1.64674235e-13,\n       1.13668256e-13, 7.81864786e-14, 5.35893540e-14, 3.65977336e-14,\n       2.49018656e-14, 1.68804330e-14, 1.13993465e-14, 7.66814410e-15,\n       5.13786047e-15, 3.42864311e-15, 2.27863477e-15, 1.50800354e-15,\n       9.93724574e-16, 6.51965358e-16, 4.25828220e-16, 2.76853527e-16,\n       1.79152612e-16, 1.15372620e-16, 7.39324417e-17, 4.71371198e-17,\n       2.98969139e-17, 1.88608372e-17, 1.18331087e-17, 7.38189249e-18,\n       4.57815607e-18, 2.82218493e-18, 1.72887989e-18, 1.05228928e-18,\n       6.36203972e-19, 3.81980575e-19, 2.27695642e-19, 1.34714040e-19,\n       7.90828398e-20, 4.60488523e-20, 2.65868362e-20, 1.52144734e-20,\n       8.62593853e-21, 4.84301614e-21, 2.69134409e-21, 1.47955460e-21,\n       8.04165361e-22, 4.31851211e-22, 2.28978679e-22, 1.19784257e-22,\n       6.17720215e-23, 3.13750509e-23, 1.56804252e-23, 7.70293500e-24,\n       3.71521821e-24, 1.75712630e-24, 8.13811801e-25, 3.68556133e-25,\n       1.62942661e-25, 7.01999792e-26, 2.94133175e-26, 1.19588265e-26,\n       4.70633254e-27, 1.78769138e-27, 6.53291877e-28, 2.28821390e-28,\n       7.64815805e-29, 2.42681910e-29, 7.26509413e-30, 2.03650757e-30,\n       5.29548366e-31, 1.26228579e-31, 2.71628780e-32, 5.16951242e-33,\n       8.45651374e-34, 1.14032180e-34, 1.18598160e-35, 8.42984199e-37,\n       3.05740599e-38]), 17: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       9.50946288e-31, 2.42989092e-29, 3.32058753e-28, 3.32488995e-27,\n       2.73993616e-26, 1.95504111e-25, 1.24421038e-24, 7.20801230e-24,\n       3.85469914e-23, 1.92225333e-22, 9.00912533e-22, 3.99277684e-21,\n       1.68157578e-20, 6.75707852e-20, 2.59932709e-19, 9.59948372e-19,\n       3.41166326e-18, 1.16927614e-17, 3.87152529e-17, 1.24035164e-16,\n       3.85041232e-16, 1.15958341e-15, 3.39158835e-15, 9.64349765e-15,\n       2.66794531e-14, 7.18742448e-14, 1.88683647e-13, 4.82994211e-13,\n       1.20629481e-12, 2.94106223e-12, 7.00342308e-12, 1.62956350e-11,\n       3.70656547e-11, 8.24486257e-11, 1.79418549e-10, 3.82097990e-10,\n       7.96615832e-10, 1.62639664e-09, 3.25265895e-09, 6.37400001e-09,\n       1.22425225e-08, 2.30535015e-08, 4.25726612e-08, 7.71211135e-08,\n       1.37083700e-07, 2.39161553e-07, 4.09652095e-07, 6.89104942e-07,\n       1.13876310e-06, 1.84924502e-06, 2.95194200e-06, 4.63358206e-06,\n       7.15433264e-06, 1.08696667e-05, 1.62559948e-05, 2.39397691e-05,\n       3.47294020e-05, 4.96489363e-05, 6.99719786e-05, 9.72540072e-05,\n       1.33360825e-04, 1.80490696e-04, 2.41187602e-04, 3.18343159e-04,\n       4.15184949e-04, 5.35249510e-04, 6.82338793e-04, 8.60459640e-04,\n       1.07374663e-03, 1.32636952e-03, 1.62242718e-03, 1.96583097e-03,\n       2.36018066e-03, 2.80863696e-03, 3.31379479e-03, 3.87756151e-03,\n       4.50104455e-03, 5.18445260e-03, 5.92701407e-03, 6.72691622e-03,\n       7.58126777e-03, 8.48608690e-03, 9.43631598e-03, 1.04258634e-02,\n       1.14476720e-02, 1.24938127e-02, 1.35556011e-02, 1.46237345e-02,\n       1.56884450e-02, 1.67396654e-02, 1.77672034e-02, 1.87609191e-02,\n       1.97109017e-02, 2.06076408e-02, 2.14421888e-02, 2.22063089e-02,\n       2.28926081e-02, 2.34946500e-02, 2.40070471e-02, 2.44255297e-02,\n       2.47469921e-02, 2.49695145e-02, 2.50923625e-02, 2.51159636e-02,\n       2.50418640e-02, 2.48726658e-02, 2.46119489e-02, 2.42641787e-02,\n       2.38346021e-02, 2.33291367e-02, 2.27542537e-02, 2.21168580e-02,\n       2.14241693e-02, 2.06836042e-02, 1.99026640e-02, 1.90888283e-02,\n       1.82494565e-02, 1.73916988e-02, 1.65224176e-02, 1.56481191e-02,\n       1.47748967e-02, 1.39083853e-02, 1.30537273e-02, 1.22155481e-02,\n       1.13979430e-02, 1.06044730e-02, 9.83816903e-03, 9.10154358e-03,\n       8.39660960e-03, 7.72490437e-03, 7.08751820e-03, 6.48512659e-03,\n       5.91802505e-03, 5.38616563e-03, 4.88919432e-03, 4.42648860e-03,\n       3.99719453e-03, 3.60026271e-03, 3.23448278e-03, 2.89851596e-03,\n       2.59092538e-03, 2.31020402e-03, 2.05480004e-03, 1.82313949e-03,\n       1.61364638e-03, 1.42476012e-03, 1.25495042e-03, 1.10272977e-03,\n       9.66663616e-04, 8.45378493e-04, 7.37568124e-04, 6.41997824e-04,\n       5.57507327e-04, 4.83012234e-04, 4.17504274e-04, 3.60050546e-04,\n       3.09791922e-04, 2.65940750e-04, 2.27778013e-04, 1.94650069e-04,\n       1.65965083e-04, 1.41189264e-04, 1.19842980e-04, 1.01496840e-04,\n       8.57678045e-05, 7.23153664e-05, 6.08378598e-05, 5.10689172e-05,\n       4.27741060e-05, 3.57477591e-05, 2.98100123e-05, 2.48040525e-05,\n       2.05935791e-05, 1.70604747e-05, 1.41026822e-05, 1.16322771e-05,\n       9.57372830e-06, 7.86233555e-06, 6.44283184e-06, 5.26813915e-06,\n       4.29826537e-06, 3.49933025e-06, 2.84270886e-06, 2.30428108e-06,\n       1.86377665e-06, 1.50420558e-06, 1.21136455e-06, 9.73410743e-07,\n       7.80495015e-07, 6.24447343e-07, 4.98507861e-07, 3.97097684e-07,\n       3.15624241e-07, 2.50316421e-07, 1.98085418e-07, 1.56407606e-07,\n       1.23226264e-07, 9.68693619e-08, 7.59809758e-08, 5.94642467e-08,\n       4.64340738e-08, 3.61779932e-08, 2.81239173e-08, 2.18136057e-08,\n       1.68809110e-08, 1.30339893e-08, 1.00407925e-08, 7.71726958e-09,\n       5.91779750e-09, 4.52744074e-09, 3.45570758e-09, 2.63152688e-09,\n       1.99921780e-09, 1.51526477e-09, 1.14574368e-09, 8.64273337e-10,\n       6.50389323e-10, 4.88256489e-10, 3.65652388e-10, 2.73166696e-10,\n       2.03572419e-10, 1.51333337e-10, 1.12219184e-10, 8.30058082e-11,\n       6.12421572e-11, 4.50696858e-11, 3.30827604e-11, 2.42210450e-11,\n       1.76867633e-11, 1.28812574e-11, 9.35647467e-12, 6.77796974e-12,\n       4.89676530e-12, 3.52800921e-12, 2.53483052e-12, 1.81616176e-12,\n       1.29757843e-12, 9.24427424e-13, 6.56686736e-13, 4.65131185e-13,\n       3.28480410e-13, 2.31283537e-13, 1.62354754e-13, 1.13619669e-13,\n       7.92670609e-14, 5.51270196e-14, 3.82164072e-14, 2.64076083e-14,\n       1.81878610e-14, 1.24849308e-14, 8.54122810e-15, 5.82318961e-15,\n       3.95625002e-15, 2.67832587e-15, 1.80664810e-15, 1.21418981e-15,\n       8.12968290e-16, 5.42256096e-16, 3.60286091e-16, 2.38434816e-16,\n       1.57157920e-16, 1.03159902e-16, 6.74303517e-17, 4.38863710e-17,\n       2.84375048e-17, 1.83441043e-17, 1.17787178e-17, 7.52743065e-18,\n       4.78730163e-18, 3.02952980e-18, 1.90740125e-18, 1.19462032e-18,\n       7.44172621e-19, 4.61003734e-19, 2.83954604e-19, 1.73871837e-19,\n       1.05818734e-19, 6.39971420e-20, 3.84529001e-20, 2.29491961e-20,\n       1.36009120e-20, 8.00230985e-21, 4.67289078e-21, 2.70735811e-21,\n       1.55579465e-21, 8.86443068e-22, 5.00581383e-22, 2.80055229e-22,\n       1.55154042e-22, 8.50789862e-23, 4.61523150e-23, 2.47531338e-23,\n       1.31179464e-23, 6.86455315e-24, 3.54452395e-24, 1.80453825e-24,\n       9.05050733e-25, 4.46771041e-25, 2.16858658e-25, 1.03392062e-25,\n       4.83633253e-26, 2.21676535e-26, 9.94270767e-27, 4.35734176e-27,\n       1.86275924e-27, 7.75391995e-28, 3.13645554e-28, 1.23007167e-28,\n       4.66543157e-29, 1.70636178e-29, 5.99838975e-30, 2.01894987e-30,\n       6.47751072e-31, 1.97058331e-31, 5.64866230e-32, 1.51401263e-32,\n       3.75860006e-33, 8.53954288e-34, 1.74835083e-34, 3.15966827e-35,\n       4.89827288e-36, 6.24664191e-37, 6.13215684e-38, 4.10714294e-39,\n       1.40198884e-40]), 18: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 1.39790083e-32, 3.79469872e-31, 5.48795578e-30,\n       5.77713609e-29, 4.97970796e-28, 3.70657549e-27, 2.45652040e-26,\n       1.48001784e-25, 8.22347688e-25, 4.25801669e-24, 2.07111394e-23,\n       9.52310419e-23, 4.16020561e-22, 1.73382549e-21, 6.91740158e-21,\n       2.64961976e-20, 9.76784329e-20, 3.47305548e-19, 1.19322961e-18,\n       3.96768180e-18, 1.27869805e-17, 3.99912294e-17, 1.21510677e-16,\n       3.59048573e-16, 1.03269708e-15, 2.89352507e-15, 7.90380621e-15,\n       2.10615822e-14, 5.47843633e-14, 1.39179663e-13, 3.45518355e-13,\n       8.38586048e-13, 1.99064902e-12, 4.62368158e-12, 1.05121313e-11,\n       2.34021682e-11, 5.10302152e-11, 1.09028532e-10, 2.28308974e-10,\n       4.68703964e-10, 9.43593806e-10, 1.86335880e-09, 3.61030635e-09,\n       6.86494249e-09, 1.28139458e-08, 2.34849331e-08, 4.22730679e-08,\n       7.47505823e-08, 1.29882785e-07, 2.21812801e-07, 3.72420744e-07,\n       6.14908399e-07, 9.98703266e-07, 1.59600962e-06, 2.51035112e-06,\n       3.88744071e-06, 5.92866929e-06, 8.90741804e-06, 1.31882636e-05,\n       1.92489593e-05, 2.77048445e-05, 3.93350629e-05, 5.51096821e-05,\n       7.62165137e-05, 1.04086166e-04, 1.40413647e-04, 1.87174686e-04,\n       2.46634921e-04, 3.21350127e-04, 4.14155910e-04, 5.28145529e-04,\n       6.66634986e-04, 8.33114966e-04, 1.03118981e-03, 1.26450425e-03,\n       1.53665924e-03, 1.85111877e-03, 2.21110998e-03, 2.61951943e-03,\n       3.07878847e-03, 3.59081119e-03, 4.15683802e-03, 4.77738861e-03,\n       5.45217682e-03, 6.18005099e-03, 6.95895167e-03, 7.78588901e-03,\n       8.65694106e-03, 9.56727385e-03, 1.05111833e-02, 1.14821584e-02,\n       1.24729645e-02, 1.34757444e-02, 1.44821359e-02, 1.54834018e-02,\n       1.64705697e-02, 1.74345782e-02, 1.83664261e-02, 1.92573200e-02,\n       2.00988185e-02, 2.08829681e-02, 2.16024291e-02, 2.22505876e-02,\n       2.28216526e-02, 2.33107357e-02, 2.37139120e-02, 2.40282626e-02,\n       2.42518970e-02, 2.43839562e-02, 2.44245984e-02, 2.43749660e-02,\n       2.42371376e-02, 2.40140654e-02, 2.37095013e-02, 2.33279118e-02,\n       2.28743863e-02, 2.23545393e-02, 2.17744095e-02, 2.11403583e-02,\n       2.04589684e-02, 1.97369463e-02, 1.89810281e-02, 1.81978921e-02,\n       1.73940782e-02, 1.65759149e-02, 1.57494557e-02, 1.49204242e-02,\n       1.40941685e-02, 1.32756252e-02, 1.24692924e-02, 1.16792116e-02,\n       1.09089577e-02, 1.01616373e-02, 9.43989302e-03, 8.74591506e-03,\n       8.08145729e-03, 7.44785854e-03, 6.84606727e-03, 6.27666935e-03,\n       5.73991792e-03, 5.23576468e-03, 4.76389198e-03, 4.32374500e-03,\n       3.91456359e-03, 3.53541325e-03, 3.18521483e-03, 2.86277271e-03,\n       2.56680115e-03, 2.29594859e-03, 2.04881991e-03, 1.82399637e-03,\n       1.62005348e-03, 1.43557646e-03, 1.26917376e-03, 1.11948835e-03,\n       9.85207182e-04, 8.65068692e-04, 7.57868750e-04, 6.62464988e-04,\n       5.77779780e-04, 5.02801997e-04, 4.36587680e-04, 3.78259800e-04,\n       3.27007234e-04, 2.82083084e-04, 2.42802483e-04, 2.08539978e-04,\n       1.78726602e-04, 1.52846729e-04, 1.30434782e-04, 1.11071870e-04,\n       9.43824164e-05, 8.00308119e-05, 6.77181547e-05, 5.71790931e-05,\n       4.81788042e-05, 4.05101250e-05, 3.39908506e-05, 2.84612058e-05,\n       2.37814957e-05, 1.98299354e-05, 1.65006564e-05, 1.37018852e-05,\n       1.13542870e-05, 9.38946775e-06, 7.74862507e-06, 6.38133805e-06,\n       5.24448717e-06, 4.30129357e-06, 3.52046803e-06, 2.87546009e-06,\n       2.34379773e-06, 1.90650899e-06, 1.54761705e-06, 1.25370083e-06,\n       1.01351412e-06, 8.17656245e-07, 6.58288464e-07, 5.28890288e-07,\n       4.24050916e-07, 3.39291169e-07, 2.70911966e-07, 2.15865735e-07,\n       1.71647627e-07, 1.36203733e-07, 1.07853873e-07, 8.52268178e-08,\n       6.72061067e-08, 5.28848325e-08, 4.15280289e-08, 3.25414578e-08,\n       2.54457797e-08, 1.98552344e-08, 1.54600909e-08, 1.20122390e-08,\n       9.31338911e-09, 7.20543513e-09, 5.56260233e-09, 4.28506729e-09,\n       3.29378645e-09, 2.52631532e-09, 1.93343683e-09, 1.47644934e-09,\n       1.12499057e-09, 8.55295989e-10, 6.48808428e-10, 4.91070786e-10,\n       3.70846483e-10, 2.79422491e-10, 2.10058452e-10, 1.57552329e-10,\n       1.17898807e-10, 8.80212896e-11, 6.55621781e-11, 4.87191504e-11,\n       3.61176795e-11, 2.67120143e-11, 1.97084608e-11, 1.45060907e-11,\n       1.06510334e-11, 7.80132836e-12, 5.69996667e-12, 4.15426508e-12,\n       3.02012624e-12, 2.19005760e-12, 1.58407499e-12, 1.14281401e-12,\n       8.22326905e-13, 5.90162607e-13, 4.22421350e-13, 3.01547229e-13,\n       2.14678248e-13, 1.52416307e-13, 1.07912692e-13, 7.61899806e-14,\n       5.36405819e-14, 3.76569295e-14, 2.63594971e-14, 1.83973193e-14,\n       1.28020940e-14, 8.88177424e-15, 6.14318031e-15, 4.23587853e-15,\n       2.91159933e-15, 1.99497763e-15, 1.36251849e-15, 9.27520582e-16,\n       6.29302473e-16, 4.25526978e-16, 2.86749468e-16, 1.92557781e-16,\n       1.28847636e-16, 8.59056323e-17, 5.70647996e-17, 3.77647693e-17,\n       2.48969602e-17, 1.63498739e-17, 1.06944197e-17, 6.96689557e-18,\n       4.51984427e-18, 2.91991862e-18, 1.87819296e-18, 1.20278740e-18,\n       7.66781344e-19, 4.86564775e-19, 3.07288404e-19, 1.93123567e-19,\n       1.20768112e-19, 7.51343193e-20, 4.64976852e-20, 2.86197217e-20,\n       1.75174496e-20, 1.06604081e-20, 6.44905098e-21, 3.87751458e-21,\n       2.31663711e-21, 1.37503902e-21, 8.10631901e-22, 4.74543886e-22,\n       2.75776974e-22, 1.59054265e-22, 9.10135866e-23, 5.16534053e-23,\n       2.90650581e-23, 1.62091101e-23, 8.95543496e-24, 4.89963871e-24,\n       2.65330424e-24, 1.42146355e-24, 7.52962300e-25, 3.94134569e-25,\n       2.03739403e-25, 1.03936747e-25, 5.22887820e-26, 2.59209244e-26,\n       1.26510238e-26, 6.07345439e-27, 2.86517180e-27, 1.32679875e-27,\n       6.02413146e-28, 2.67836838e-28, 1.16448597e-28, 4.94345859e-29,\n       2.04568691e-29, 8.23685974e-30, 3.22041303e-30, 1.21982151e-30,\n       4.46474920e-31, 1.57450224e-31, 5.33187024e-32, 1.72712367e-32,\n       5.32733137e-33, 1.55638364e-33, 4.27923127e-34, 1.09870942e-34,\n       2.60915945e-35, 5.66198570e-36, 1.10538008e-36, 1.90159795e-37,\n       2.80110439e-38, 3.38808001e-39, 3.14915798e-40, 1.99413634e-41,\n       6.42889012e-43]), 19: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 2.05492860e-34, 5.90566752e-33,\n       9.01131445e-32, 9.95092543e-31, 8.95563376e-30, 6.94128025e-29,\n       4.78206788e-28, 2.99100465e-27, 1.72362654e-26, 9.24990675e-26,\n       4.66076197e-25, 2.21919981e-24, 1.00367157e-23, 4.32986966e-23,\n       1.78801660e-22, 7.08869701e-22, 2.70492453e-21, 9.95593355e-21,\n       3.54133452e-20, 1.21934854e-19, 4.07002819e-19, 1.31867088e-18,\n       4.15187821e-18, 1.27165561e-17, 3.79239508e-17, 1.10214851e-16,\n       3.12376511e-16, 8.64027672e-16, 2.33378564e-15, 6.15925323e-15,\n       1.58912515e-14, 4.01016243e-14, 9.90225873e-14, 2.39361983e-13,\n       5.66620088e-13, 1.31401554e-12, 2.98625224e-12, 6.65283390e-12,\n       1.45334911e-11, 3.11414116e-11, 6.54678025e-11, 1.35067026e-10,\n       2.73533005e-10, 5.43891420e-10, 1.06208005e-09, 2.03724525e-09,\n       3.83943621e-09, 7.11092291e-09, 1.29453849e-08, 2.31702611e-08,\n       4.07822512e-08, 7.06048367e-08, 1.20259978e-07, 2.01573625e-07,\n       3.32565441e-07, 5.40205349e-07, 8.64150345e-07, 1.36170050e-06,\n       2.11422818e-06, 3.23533356e-06, 4.88095668e-06, 7.26162553e-06,\n       1.06569379e-05, 1.54322581e-05, 2.20574603e-05, 3.11273733e-05,\n       4.33833794e-05, 5.97354148e-05, 8.12834133e-05, 1.09337052e-04,\n       1.45432519e-04, 1.91344918e-04, 2.49094936e-04, 3.20948402e-04,\n       4.09407559e-04, 5.17193036e-04, 6.47215824e-04, 8.02538899e-04,\n       9.86328524e-04, 1.20179568e-03, 1.45212853e-03, 1.74041719e-03,\n       2.06957248e-03, 2.44224076e-03, 2.86071698e-03, 3.32685866e-03,\n       3.84200315e-03, 4.40689109e-03, 5.02159836e-03, 5.68547920e-03,\n       6.39712234e-03, 7.15432230e-03, 7.95406702e-03, 8.79254286e-03,\n       9.66515750e-03, 1.05665805e-02, 1.14908011e-02, 1.24312023e-02,\n       1.33806488e-02, 1.43315886e-02, 1.52761640e-02, 1.62063308e-02,\n       1.71139819e-02, 1.79910740e-02, 1.88297525e-02, 1.96224738e-02,\n       2.03621203e-02, 2.10421079e-02, 2.16564820e-02, 2.22000013e-02,\n       2.26682068e-02, 2.30574766e-02, 2.33650642e-02, 2.35891207e-02,\n       2.37287015e-02, 2.37837567e-02, 2.37551077e-02, 2.36444091e-02,\n       2.34540996e-02, 2.31873412e-02, 2.28479502e-02, 2.24403200e-02,\n       2.19693399e-02, 2.14403093e-02, 2.08588506e-02, 2.02308223e-02,\n       1.95622333e-02, 1.88591606e-02, 1.81276707e-02, 1.73737474e-02,\n       1.66032246e-02, 1.58217271e-02, 1.50346183e-02, 1.42469560e-02,\n       1.34634554e-02, 1.26884608e-02, 1.19259243e-02, 1.11793921e-02,\n       1.04519975e-02, 9.74646054e-03, 9.06509301e-03, 8.40980897e-03,\n       7.78213946e-03, 7.18325113e-03, 6.61396785e-03, 6.07479483e-03,\n       5.56594452e-03, 5.08736362e-03, 4.63876080e-03, 4.21963457e-03,\n       3.82930074e-03, 3.46691929e-03, 3.13152017e-03, 2.82202775e-03,\n       2.53728389e-03, 2.27606917e-03, 2.03712249e-03, 1.81915869e-03,\n       1.62088439e-03, 1.44101186e-03, 1.27827114e-03, 1.13142036e-03,\n       9.99254326e-04, 8.80611633e-04, 7.74380200e-04, 6.79501526e-04,\n       5.94973700e-04, 5.19853333e-04, 4.53256519e-04, 3.94358968e-04,\n       3.42395409e-04, 2.96658404e-04, 2.56496653e-04, 2.21312903e-04,\n       1.90561550e-04, 1.63746000e-04, 1.40415887e-04, 1.20164177e-04,\n       1.02624246e-04, 8.74669453e-05, 7.43977270e-05, 6.31538272e-05,\n       5.35015580e-05, 4.52337145e-05, 3.81671159e-05, 3.21402891e-05,\n       2.70113018e-05, 2.26557471e-05, 1.89648809e-05, 1.58439078e-05,\n       1.32104144e-05, 1.09929409e-05, 9.12968759e-06, 7.56734722e-06,\n       6.26005515e-06, 5.16845013e-06, 4.25883668e-06, 3.50244097e-06,\n       2.87475235e-06, 2.35494248e-06, 1.92535490e-06, 1.57105783e-06,\n       1.27945374e-06, 1.03993953e-06, 8.43611715e-07, 6.83011414e-07,\n       5.51904431e-07, 4.45092182e-07, 3.58249602e-07, 2.87786567e-07,\n       2.30729778e-07, 1.84622349e-07, 1.47438684e-07, 1.17512511e-07,\n       9.34762075e-08, 7.42097714e-08, 5.87980245e-08, 4.64948112e-08,\n       3.66931269e-08, 2.89002556e-08, 2.27171319e-08, 1.78212506e-08,\n       1.39525505e-08, 1.09017830e-08, 8.50095280e-09, 6.61547944e-09,\n       5.13778668e-09, 3.98207177e-09, 3.08004797e-09, 2.37748748e-09,\n       1.83142102e-09, 1.40787483e-09, 1.08004623e-09, 8.26836238e-10,\n       6.31672219e-10, 4.81565400e-10, 3.66358229e-10, 2.78124723e-10,\n       2.10693841e-10, 1.59271530e-10, 1.20141715e-10, 9.04303031e-11,\n       6.79193584e-11, 5.09011218e-11, 3.80636032e-11, 2.84011279e-11,\n       2.11445580e-11, 1.57069894e-11, 1.16415920e-11, 8.60895525e-12,\n       6.35185407e-12, 4.67579726e-12, 3.43406735e-12, 2.51624287e-12,\n       1.83941323e-12, 1.34147068e-12, 9.76000540e-13, 7.08398312e-13,\n       5.12926185e-13, 3.70487135e-13, 2.66945750e-13, 1.91864624e-13,\n       1.37555795e-13, 9.83704581e-14, 7.01684208e-14, 4.99228001e-14,\n       3.54262382e-14, 2.50731131e-14, 1.76984992e-14, 1.24593965e-14,\n       8.74735851e-15, 6.12438836e-15, 4.27602692e-15, 2.97711485e-15,\n       2.06687024e-15, 1.43079617e-15, 9.87581989e-16, 6.79645886e-16,\n       4.66325370e-16, 3.18987924e-16, 2.17530236e-16, 1.47878772e-16,\n       1.00210385e-16, 6.76892023e-17, 4.55726289e-17, 3.05804707e-17,\n       2.04510732e-17, 1.36299850e-17, 9.05224835e-18, 5.99063324e-18,\n       3.95017595e-18, 2.59512708e-18, 1.69851374e-18, 1.10742971e-18,\n       7.19228572e-19, 4.65250478e-19, 2.99736563e-19, 1.92303758e-19,\n       1.22854568e-19, 7.81463565e-20, 4.94875986e-20, 3.11966798e-20,\n       1.95747621e-20, 1.22239057e-20, 7.59618312e-21, 4.69673951e-21,\n       2.88904102e-21, 1.76768298e-21, 1.07567769e-21, 6.50903922e-22,\n       3.91592398e-22, 2.34183064e-22, 1.39186463e-22, 8.21996562e-23,\n       4.82258697e-23, 2.81013172e-23, 1.62593317e-23, 9.33885873e-24,\n       5.32326323e-24, 3.01040267e-24, 1.68847295e-24, 9.38938098e-25,\n       5.17479247e-25, 2.82546731e-25, 1.52772377e-25, 8.17634196e-26,\n       4.32933328e-26, 2.26674909e-26, 1.17290410e-26, 5.99427429e-27,\n       3.02374485e-27, 1.50448182e-27, 7.37800096e-28, 3.56330570e-28,\n       1.69338814e-28, 7.91127934e-29, 3.62985857e-29, 1.63386522e-29,\n       7.20638733e-30, 3.11057452e-30, 1.31214385e-30, 5.40105196e-31,\n       2.16572182e-31, 8.44399428e-32, 3.19459971e-32, 1.17004548e-32,\n       4.13783189e-33, 1.40876405e-33, 4.60174823e-34, 1.43654799e-34,\n       4.26616371e-35, 1.19873235e-35, 3.16636598e-36, 7.80085192e-37,\n       1.77524006e-37, 3.68649971e-38, 6.87697503e-39, 1.12865716e-39,\n       1.58353019e-40, 1.82139354e-41, 1.60745346e-42, 9.65222392e-44,\n       2.94799979e-45]), 20: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.02076618e-36,\n       9.16270478e-35, 1.47110501e-33, 1.70059544e-32, 1.59532681e-31,\n       1.28547716e-30, 9.19113239e-30, 5.95847198e-29, 3.55554680e-28,\n       1.97442902e-27, 1.02890013e-26, 5.06471457e-26, 2.36740161e-25,\n       1.05534611e-24, 4.50278346e-24, 1.84434544e-23, 7.27105366e-23,\n       2.76509753e-22, 1.01629377e-21, 3.61624010e-21, 1.24758787e-20,\n       4.17863512e-20, 1.36037467e-19, 4.30924884e-19, 1.32946173e-18,\n       3.99810119e-18, 1.17293272e-17, 3.35923981e-17, 9.39805218e-17,\n       2.56992361e-16, 6.87263987e-16, 1.79831050e-15, 4.60620695e-15,\n       1.15543327e-14, 2.83949118e-14, 6.83895899e-14, 1.61488701e-13,\n       3.73969518e-13, 8.49577268e-13, 1.89393583e-12, 4.14419028e-12,\n       8.90300448e-12, 1.87828391e-11, 3.89237286e-11, 7.92488948e-11,\n       1.58559204e-10, 3.11817507e-10, 6.02850595e-10, 1.14605903e-09,\n       2.14278891e-09, 3.94106412e-09, 7.13174725e-09, 1.27002949e-08,\n       2.22615312e-08, 3.84157027e-08, 6.52778355e-08, 1.09249241e-07,\n       1.80119770e-07, 2.92611496e-07, 4.68497819e-07, 7.39454631e-07,\n       1.15081978e-06, 1.76645034e-06, 2.67487045e-06, 3.99689194e-06,\n       5.89486151e-06, 8.58363895e-06, 1.23433385e-05, 1.75337698e-05,\n       2.46103961e-05, 3.41414932e-05, 4.68260419e-05, 6.35117385e-05,\n       8.52123587e-05, 1.13123586e-04, 1.48636314e-04, 1.93346365e-04,\n       2.49059577e-04, 3.17791206e-04, 4.01758737e-04, 5.03367310e-04,\n       6.25187192e-04, 7.69922959e-04, 9.40374352e-04, 1.13938907e-03,\n       1.36980810e-03, 1.63440444e-03, 1.93581651e-03, 2.27647767e-03,\n       2.65854357e-03, 3.08381931e-03, 3.55368838e-03, 4.06904547e-03,\n       4.63023529e-03, 5.23699942e-03, 5.88843292e-03, 6.58295248e-03,\n       7.31827732e-03, 8.09142402e-03, 8.89871576e-03, 9.73580631e-03,\n       1.05977186e-02, 1.14788974e-02, 1.23732750e-02, 1.32743484e-02,\n       1.41752674e-02, 1.50689304e-02, 1.59480862e-02, 1.68054404e-02,\n       1.76337632e-02, 1.84259962e-02, 1.91753566e-02, 1.98754366e-02,\n       2.05202947e-02, 2.11045393e-02, 2.16234008e-02, 2.20727930e-02,\n       2.24493615e-02, 2.27505183e-02, 2.29744645e-02, 2.31201974e-02,\n       2.31875069e-02, 2.31769568e-02, 2.30898566e-02, 2.29282213e-02,\n       2.26947222e-02, 2.23926298e-02, 2.20257496e-02, 2.15983532e-02,\n       2.11151056e-02, 2.05809906e-02, 2.00012353e-02, 1.93812352e-02,\n       1.87264820e-02, 1.80424931e-02, 1.73347466e-02, 1.66086206e-02,\n       1.58693372e-02, 1.51219145e-02, 1.43711228e-02, 1.36214492e-02,\n       1.28770677e-02, 1.21418165e-02, 1.14191815e-02, 1.07122860e-02,\n       1.00238858e-02, 9.35637032e-03, 8.71176746e-03, 8.09175379e-03,\n       7.49766775e-03, 6.93052620e-03, 6.39104350e-03, 5.87965264e-03,\n       5.39652781e-03, 4.94160798e-03, 4.51462102e-03, 4.11510787e-03,\n       3.74244657e-03, 3.39587558e-03, 3.07451635e-03, 2.77739470e-03,\n       2.50346100e-03, 2.25160895e-03, 2.02069277e-03, 1.80954288e-03,\n       1.61697997e-03, 1.44182745e-03, 1.28292235e-03, 1.13912464e-03,\n       1.00932522e-03, 8.92452350e-04, 7.87476971e-04, 6.93416735e-04,\n       6.09338998e-04, 5.34362836e-04, 4.67660194e-04, 4.08456282e-04,\n       3.56029313e-04, 3.09709685e-04, 2.68878692e-04, 2.32966856e-04,\n       2.01451960e-04, 1.73856844e-04, 1.49747031e-04, 1.28728251e-04,\n       1.10443889e-04, 9.45724255e-05, 8.08248870e-05, 6.89423421e-05,\n       5.86934725e-05, 4.98722320e-05, 4.22956116e-05, 3.58015213e-05,\n       3.02467962e-05, 2.55053306e-05, 2.14663429e-05, 1.80327697e-05,\n       1.51197888e-05, 1.26534649e-05, 1.05695159e-05, 8.81219220e-06,\n       7.33326364e-06, 6.09110734e-06, 5.04988943e-06, 4.17883377e-06,\n       3.45157081e-06, 2.84555968e-06, 2.34157727e-06, 1.92326770e-06,\n       1.57674660e-06, 1.29025445e-06, 1.05385392e-06, 8.59166299e-07,\n       6.99142852e-07, 5.67866803e-07, 4.60382512e-07, 3.72548440e-07,\n       3.00910950e-07, 2.42596300e-07, 1.95218433e-07, 1.56800477e-07,\n       1.25708076e-07, 1.00592933e-07, 8.03451011e-08, 6.40527859e-08,\n       5.09685515e-08, 4.04809840e-08, 3.20909880e-08, 2.53920072e-08,\n       2.00535585e-08, 1.58075584e-08, 1.24369939e-08, 9.76655901e-09,\n       7.65493326e-09, 5.98842964e-09, 4.67578071e-09, 3.64386923e-09,\n       2.83423988e-09, 2.20025593e-09, 1.70478672e-09, 1.31833122e-09,\n       1.01749879e-09, 7.83781994e-10, 6.02567481e-10, 4.62340582e-10,\n       3.54047083e-10, 2.70582274e-10, 2.06382793e-10, 1.57101316e-10,\n       1.19347847e-10, 9.04844359e-11, 6.84626431e-11, 5.16951424e-11,\n       3.89545122e-11, 2.92936357e-11, 2.19832354e-11, 1.64629620e-11,\n       1.23031807e-11, 9.17518367e-12, 6.82801967e-12, 5.07051319e-12,\n       3.75734064e-12, 2.77827276e-12, 2.04988179e-12, 1.50916302e-12,\n       1.10863979e-12, 8.12615505e-13, 5.94310268e-13, 4.33678389e-13,\n       3.15748613e-13, 2.29364773e-13, 1.66232451e-13, 1.20198959e-13,\n       8.67107893e-14, 6.24057437e-14, 4.48070306e-14, 3.20943690e-14,\n       2.29331231e-14, 1.63470560e-14, 1.16237930e-14, 8.24475622e-15,\n       5.83335921e-15, 4.11679785e-15, 2.89793663e-15, 2.03467463e-15,\n       1.42483845e-15, 9.95149362e-16, 6.93186168e-16, 4.81545165e-16,\n       3.33607469e-16, 2.30479180e-16, 1.58785164e-16, 1.09082478e-16,\n       7.47224217e-17, 5.10365361e-17, 3.47559041e-17, 2.35980083e-17,\n       1.59736079e-17, 1.07793472e-17, 7.25143259e-18, 4.86268857e-18,\n       3.25034133e-18, 2.16550454e-18, 1.43794974e-18, 9.51609415e-19,\n       6.27594502e-19, 4.12457153e-19, 2.70103806e-19, 1.76240788e-19,\n       1.14571474e-19, 7.42010644e-20, 4.78712973e-20, 3.07636676e-20,\n       1.96908192e-20, 1.25520748e-20, 7.96810225e-21, 5.03664910e-21,\n       3.16981374e-21, 1.98603465e-21, 1.23866684e-21, 7.68932209e-22,\n       4.75046575e-22, 2.92041786e-22, 1.78631351e-22, 1.08696212e-22,\n       6.57888137e-23, 3.96008023e-23, 2.37028077e-23, 1.41047378e-23,\n       8.34297312e-24, 4.90437599e-24, 2.86460795e-24, 1.66215350e-24,\n       9.57859186e-25, 5.48088338e-25, 3.11318344e-25, 1.75486464e-25,\n       9.81383687e-26, 5.44318732e-26, 2.99323382e-26, 1.63134064e-26,\n       8.80842695e-27, 4.71002611e-27, 2.49303748e-27, 1.30560244e-27,\n       6.76163586e-28, 3.46113248e-28, 1.75009273e-28, 8.73602202e-29,\n       4.30220352e-29, 2.08875431e-29, 9.99023495e-30, 4.70332461e-30,\n       2.17769994e-30, 9.90716031e-31, 4.42405823e-31, 1.93704585e-31,\n       8.30602893e-32, 3.48356071e-32, 1.42698785e-32, 5.70053613e-33,\n       2.21703812e-33, 8.37870540e-34, 3.07056575e-34, 1.08862767e-34,\n       3.72401149e-35, 1.22548416e-35, 3.86610475e-36, 1.16460832e-36,\n       3.33433071e-37, 9.02358339e-38, 2.29322604e-38, 5.42958479e-39,\n       1.18602916e-39, 2.36105349e-40, 4.21647181e-41, 6.61537149e-42,\n       8.85983133e-43, 9.71368199e-44, 8.16044046e-45, 4.65902701e-46,\n       1.35182008e-47]), 21: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       4.44055737e-38, 1.41768050e-36, 2.38907027e-35, 2.88565701e-34,\n       2.81732320e-33, 2.35658731e-32, 1.74616117e-31, 1.17163380e-30,\n       7.22914218e-30, 4.14796307e-29, 2.23225412e-28, 1.13428841e-27,\n       5.47150371e-27, 2.51652598e-26, 1.10763171e-25, 4.67979175e-25,\n       1.90298718e-24, 7.46460107e-24, 2.83004429e-23, 1.03882913e-22,\n       3.69759423e-22, 1.27792149e-21, 4.29359608e-21, 1.40390742e-20,\n       4.47175021e-20, 1.38873501e-19, 4.20832881e-19, 1.24526850e-18,\n       3.60053191e-18, 1.01784983e-17, 2.81485260e-17, 7.61912080e-17,\n       2.01946574e-16, 5.24373035e-16, 1.33441967e-15, 3.32932600e-15,\n       8.14675045e-15, 1.95577575e-14, 4.60779929e-14, 1.06569537e-13,\n       2.42022370e-13, 5.39848895e-13, 1.18301094e-12, 2.54744943e-12,\n       5.39161113e-12, 1.12181107e-11, 2.29507913e-11, 4.61783230e-11,\n       9.13954600e-11, 1.77966641e-10, 3.41004592e-10, 6.43085360e-10,\n       1.19382961e-09, 2.18202516e-09, 3.92734789e-09, 6.96209971e-09,\n       1.21580018e-08, 2.09192559e-08, 3.54710985e-08, 5.92831564e-08,\n       9.76791639e-08, 1.58698950e-07, 2.54294676e-07, 4.01960390e-07,\n       6.26910903e-07, 9.64941231e-07, 1.46610927e-06, 2.19938963e-06,\n       3.25844304e-06, 4.76863050e-06, 6.89537270e-06, 9.85391035e-06,\n       1.39204597e-05, 1.94446806e-05, 2.68632800e-05, 3.67144737e-05,\n       4.96529128e-05, 6.64645739e-05, 8.80810043e-05, 1.15592220e-04,\n       1.50257480e-04, 1.93513131e-04, 2.46976669e-04, 3.12446247e-04,\n       3.91894872e-04, 4.87458671e-04, 6.01418745e-04, 7.36176320e-04,\n       8.94221082e-04, 1.07809287e-03, 1.29033709e-03, 1.53345446e-03,\n       1.80984608e-03, 2.12175469e-03, 2.47120375e-03, 2.85993547e-03,\n       3.28934966e-03, 3.76044489e-03, 4.27376371e-03, 4.82934367e-03,\n       5.42667558e-03, 6.06467049e-03, 6.74163671e-03, 7.45526780e-03,\n       8.20264221e-03, 8.98023517e-03, 9.78394280e-03, 1.06091183e-02,\n       1.14506199e-02, 1.23028689e-02, 1.31599185e-02, 1.40155299e-02,\n       1.48632553e-02, 1.56965267e-02, 1.65087471e-02, 1.72933829e-02,\n       1.80440569e-02, 1.87546371e-02, 1.94193228e-02, 2.00327240e-02,\n       2.05899334e-02, 2.10865900e-02, 2.15189332e-02, 2.18838456e-02,\n       2.21788856e-02, 2.24023082e-02, 2.25530744e-02, 2.26308494e-02,\n       2.26359903e-02, 2.25695232e-02, 2.24331117e-02, 2.22290160e-02,\n       2.19600460e-02, 2.16295072e-02, 2.12411427e-02, 2.07990708e-02,\n       2.03077207e-02, 1.97717674e-02, 1.91960659e-02, 1.85855868e-02,\n       1.79453549e-02, 1.72803893e-02, 1.65956486e-02, 1.58959797e-02,\n       1.51860721e-02, 1.44704168e-02, 1.37532717e-02, 1.30386314e-02,\n       1.23302039e-02, 1.16313925e-02, 1.09452822e-02, 1.02746328e-02,\n       9.62187584e-03, 8.98911581e-03, 8.37813608e-03, 7.79040788e-03,\n       7.22710252e-03, 6.68910621e-03, 6.17703697e-03, 5.69126329e-03,\n       5.23192396e-03, 4.79894878e-03, 4.39207963e-03, 4.01089173e-03,\n       3.65481458e-03, 3.32315248e-03, 3.01510427e-03, 2.72978220e-03,\n       2.46622966e-03, 2.22343774e-03, 2.00036051e-03, 1.79592895e-03,\n       1.60906347e-03, 1.43868513e-03, 1.28372539e-03, 1.14313469e-03,\n       1.01588959e-03, 9.00998868e-04, 7.97508392e-04, 7.04504983e-04,\n       6.21119324e-04, 5.46527997e-04, 4.79954753e-04, 4.20671090e-04,\n       3.67996234e-04, 3.21296615e-04, 2.79984893e-04, 2.43518640e-04,\n       2.11398721e-04, 1.83167447e-04, 1.58406561e-04, 1.36735100e-04,\n       1.17807178e-04, 1.01309743e-04, 8.69603151e-05, 7.45047632e-05,\n       6.37151229e-05, 5.43874847e-05, 4.63399643e-05, 3.94107684e-05,\n       3.34563618e-05, 2.83497444e-05, 2.39788382e-05, 2.02449877e-05,\n       1.70615715e-05, 1.43527239e-05, 1.20521627e-05, 1.01021187e-05,\n       8.45236352e-06, 7.05932833e-06, 5.88530977e-06, 4.89775584e-06,\n       4.06862663e-06, 3.37382385e-06, 2.79268342e-06, 2.30752564e-06,\n       1.90325772e-06, 1.56702355e-06, 1.28789616e-06, 1.05660835e-06,\n       8.65317463e-07, 7.07400621e-07, 5.77276873e-07, 4.70253209e-07,\n       3.82391576e-07, 3.10394327e-07, 2.51505816e-07, 2.03428079e-07,\n       1.64248758e-07, 1.32379662e-07, 1.06504505e-07, 8.55345762e-08,\n       6.85712161e-08, 5.48741394e-08, 4.38347517e-08, 3.49537264e-08,\n       2.78222071e-08, 2.21060841e-08, 1.75328730e-08, 1.38807903e-08,\n       1.09696773e-08, 8.65347796e-09, 6.81401768e-09, 5.35586960e-09,\n       4.20212790e-09, 3.29093530e-09, 2.57263634e-09, 2.00744899e-09,\n       1.56356409e-09, 1.21559750e-09, 9.43332170e-10, 7.30698008e-10,\n       5.64946377e-10, 4.35983498e-10, 3.35833320e-10, 2.58205631e-10,\n       1.98149511e-10, 1.51775874e-10, 1.16035767e-10, 8.85436157e-11,\n       6.74365902e-11, 5.12629436e-11, 3.88935476e-11, 2.94519483e-11,\n       2.22591821e-11, 1.67903286e-11, 1.26403763e-11, 9.49746021e-12,\n       7.12192435e-12, 5.32997545e-12, 3.98094779e-12, 2.96740259e-12,\n       2.20744722e-12, 1.63878901e-12, 1.21414193e-12, 8.97685574e-13,\n       6.62341433e-13, 4.87682118e-13, 3.58329975e-13, 2.62733129e-13,\n       1.92232021e-13, 1.40349038e-13, 1.02249074e-13, 7.43307958e-14,\n       5.39176125e-14, 3.90245404e-14, 2.81827129e-14, 2.03075722e-14,\n       1.46000906e-14, 1.04729084e-14, 7.49522901e-15, 5.35179816e-15,\n       3.81243869e-15, 2.70947511e-15, 1.92104334e-15, 1.35877990e-15,\n       9.58762316e-16, 6.74857875e-16, 4.73851764e-16, 3.31887164e-16,\n       2.31870120e-16, 1.61582277e-16, 1.12311730e-16, 7.78621555e-17,\n       5.38374740e-17, 3.71267115e-17, 2.55339502e-17, 1.75131770e-17,\n       1.19787769e-17, 8.17043769e-18, 5.55709266e-18, 3.76879952e-18,\n       2.54855814e-18, 1.71832217e-18, 1.15508773e-18, 7.74117358e-19,\n       5.17202403e-19, 3.44473533e-19, 2.28702927e-19, 1.51351337e-19,\n       9.98336096e-20, 6.56326091e-20, 4.30021754e-20, 2.80778303e-20,\n       1.82689038e-20, 1.18443065e-20, 7.65114122e-21, 4.92416104e-21,\n       3.15715907e-21, 2.01644437e-21, 1.28282538e-21, 8.12839483e-22,\n       5.12933201e-22, 3.22327027e-22, 2.01684180e-22, 1.25644513e-22,\n       7.79232658e-23, 4.81056236e-23, 2.95583699e-23, 1.80746298e-23,\n       1.09978648e-23, 6.65794638e-24, 4.00963717e-24, 2.40181424e-24,\n       1.43079220e-24, 8.47512449e-25, 4.99083936e-25, 2.92132887e-25,\n       1.69935254e-25, 9.82187999e-26, 5.63923962e-26, 3.21560203e-26,\n       1.82060121e-26, 1.02321429e-26, 5.70688390e-27, 3.15781054e-27,\n       1.73297995e-27, 9.42928227e-28, 5.08498046e-28, 2.71683649e-28,\n       1.43756895e-28, 7.53010288e-29, 3.90287066e-29, 2.00064244e-29,\n       1.01375754e-29, 5.07505144e-30, 2.50862132e-30, 1.22362290e-30,\n       5.88557675e-31, 2.78965569e-31, 1.30197262e-31, 5.97844994e-32,\n       2.69855094e-32, 1.19624159e-32, 5.20250323e-33, 2.21734910e-33,\n       9.25053228e-34, 3.77265600e-34, 1.50196640e-34, 5.82814726e-35,\n       2.20046071e-35, 8.06834571e-36, 2.86697422e-36, 9.84919624e-37,\n       3.26251408e-37, 1.03885909e-37, 3.16883210e-38, 9.22211409e-39,\n       2.54864554e-39, 6.65165425e-40, 1.62861878e-40, 3.71111060e-41,\n       7.79309411e-42, 1.48963754e-42, 2.55117602e-43, 3.83352119e-44,\n       4.91076342e-45, 5.14310568e-46, 4.12239382e-47, 2.24324120e-48,\n       6.19883875e-50]), 22: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 6.52766502e-40, 2.18801325e-38, 3.86153259e-37,\n       4.86487333e-36, 4.93607282e-35, 4.28030703e-34, 3.28244029e-33,\n       2.27656805e-32, 1.45056144e-31, 8.58877239e-31, 4.76700481e-30,\n       2.49715410e-29, 1.24138844e-28, 5.88270452e-28, 2.66729256e-27,\n       1.16078440e-26, 4.86163220e-26, 1.96410102e-25, 7.66950415e-25,\n       2.89971338e-24, 1.06316296e-23, 3.78528451e-23, 1.31033941e-22,\n       4.41502647e-22, 1.44936332e-21, 4.63985839e-21, 1.44966888e-20,\n       4.42375567e-20, 1.31936655e-19, 3.84822966e-19, 1.09830998e-18,\n       3.06891611e-18, 8.39946154e-18, 2.25277960e-17, 5.92334659e-17,\n       1.52744073e-16, 3.86426109e-16, 9.59442857e-16, 2.33861429e-15,\n       5.59773949e-15, 1.31613802e-14, 3.04045080e-14, 6.90286189e-14,\n       1.54055174e-13, 3.38045766e-13, 7.29488662e-13, 1.54843573e-12,\n       3.23358061e-12, 6.64463819e-12, 1.34380052e-11, 2.67516529e-11,\n       5.24316522e-11, 1.01189849e-10, 1.92332730e-10, 3.60092406e-10,\n       6.64187319e-10, 1.20713082e-09, 2.16210503e-09, 3.81706887e-09,\n       6.64334503e-09, 1.14004259e-08, 1.92933592e-08, 3.22050199e-08,\n       5.30330015e-08, 8.61698589e-08, 1.38175950e-07, 2.18705952e-07,\n       3.41762817e-07, 5.27365723e-07, 8.03730548e-07, 1.21007105e-06,\n       1.80013489e-06, 2.64658891e-06, 3.84636092e-06, 5.52702898e-06,\n       7.85432202e-06, 1.10407568e-05, 1.53553854e-05, 2.11345656e-05,\n       2.87935923e-05, 3.88389510e-05, 5.18808663e-05, 6.86457377e-05,\n       8.99879733e-05, 1.16900664e-04, 1.50524485e-04, 1.92154182e-04,\n       2.43241981e-04, 3.05397296e-04, 3.80382124e-04, 4.70101642e-04,\n       5.76589573e-04, 7.01988068e-04, 8.48521979e-04, 1.01846758e-03,\n       1.21411602e-03, 1.43773182e-03, 1.69150732e-03, 1.97751352e-03,\n       2.29764870e-03, 2.65358557e-03, 3.04671855e-03, 3.47811225e-03,\n       3.94845263e-03, 4.45800224e-03, 5.00656080e-03, 5.59343241e-03,\n       6.21740051e-03, 6.87671145e-03, 7.56906762e-03, 8.29163049e-03,\n       9.04103392e-03, 9.81340780e-03, 1.06044118e-02, 1.14092787e-02,\n       1.22228666e-02, 1.30397193e-02, 1.38541334e-02, 1.46602306e-02,\n       1.54520351e-02, 1.62235522e-02, 1.69688496e-02, 1.76821365e-02,\n       1.83578421e-02, 1.89906893e-02, 1.95757646e-02, 2.01085807e-02,\n       2.05851328e-02, 2.10019463e-02, 2.13561156e-02, 2.16453335e-02,\n       2.18679116e-02, 2.20227896e-02, 2.21095370e-02, 2.21283433e-02,\n       2.20800012e-02, 2.19658806e-02, 2.17878958e-02, 2.15484657e-02,\n       2.12504687e-02, 2.08971929e-02, 2.04922836e-02, 2.00396867e-02,\n       1.95435927e-02, 1.90083785e-02, 1.84385513e-02, 1.78386924e-02,\n       1.72134049e-02, 1.65672626e-02, 1.59047635e-02, 1.52302872e-02,\n       1.45480562e-02, 1.38621021e-02, 1.31762365e-02, 1.24940271e-02,\n       1.18187785e-02, 1.11535171e-02, 1.05009821e-02, 9.86361884e-03,\n       9.24357838e-03, 8.64271900e-03, 8.06261205e-03, 7.50455052e-03,\n       6.96956017e-03, 6.45841294e-03, 5.97164200e-03, 5.50955835e-03,\n       5.07226838e-03, 4.65969211e-03, 4.27158177e-03, 3.90754053e-03,\n       3.56704097e-03, 3.24944308e-03, 2.95401177e-03, 2.67993342e-03,\n       2.42633168e-03, 2.19228208e-03, 1.97682562e-03, 1.77898121e-03,\n       1.59775687e-03, 1.43215979e-03, 1.28120514e-03, 1.14392387e-03,\n       1.01936922e-03, 9.06622353e-04, 8.04796859e-04, 7.13042432e-04,\n       6.30547649e-04, 5.56541999e-04, 4.90297202e-04, 4.31127923e-04,\n       3.78391932e-04, 3.31489794e-04, 2.89864163e-04, 2.52998731e-04,\n       2.20416901e-04, 1.91680242e-04, 1.66386768e-04, 1.44169097e-04,\n       1.24692519e-04, 1.07653023e-04, 9.27752967e-05, 7.98107438e-05,\n       6.85355256e-05, 5.87486550e-05, 5.02701544e-05, 4.29392894e-05,\n       3.66128868e-05, 3.11637447e-05, 2.64791369e-05, 2.24594141e-05,\n       1.90167038e-05, 1.60737057e-05, 1.35625820e-05, 1.14239397e-05,\n       9.60590049e-06, 8.06325373e-06, 6.75668955e-06, 5.65210545e-06,\n       4.71998242e-06, 3.93482520e-06, 3.27466197e-06, 2.72059836e-06,\n       2.25642133e-06, 1.86824821e-06, 1.54421691e-06, 1.27421305e-06,\n       1.04963039e-06, 8.63161112e-07, 7.08612658e-07, 5.80748223e-07,\n       4.75148236e-07, 3.88090340e-07, 3.16445690e-07, 2.57589566e-07,\n       2.09324517e-07, 1.69814443e-07, 1.37528189e-07, 1.11191401e-07,\n       8.97455219e-08, 7.23129612e-08, 5.81675628e-08, 4.67096344e-08,\n       3.74448759e-08, 2.99666380e-08, 2.39410198e-08, 1.90943772e-08,\n       1.52028751e-08, 1.20837690e-08, 9.58814434e-09, 7.59488327e-09,\n       6.00566201e-09, 4.74081153e-09, 3.73589974e-09, 2.93891534e-09,\n       2.30795227e-09, 1.80930972e-09, 1.41593637e-09, 1.10615909e-09,\n       8.62646165e-10, 6.71563659e-10, 5.21890169e-10, 4.04861472e-10,\n       3.13521314e-10, 2.42358785e-10, 1.87016207e-10, 1.44054264e-10,\n       1.10763559e-10, 8.50137221e-11, 6.51328128e-11, 4.98111477e-11,\n       3.80247453e-11, 2.89745144e-11, 2.20380439e-11, 1.67314577e-11,\n       1.26792949e-11, 9.59077339e-12, 7.24112214e-12, 5.45692809e-12,\n       4.10465808e-12, 3.08168543e-12, 2.30928873e-12, 1.72720030e-12,\n       1.28936985e-12, 9.60679065e-13, 7.14398765e-13, 5.30224784e-13,\n       3.92763918e-13, 2.90369171e-13, 2.14245532e-13, 1.57764843e-13,\n       1.15941939e-13, 8.50349177e-14, 6.22407485e-14, 4.54639643e-14,\n       3.31412449e-14, 2.41086683e-14, 1.75014568e-14, 1.26784234e-14,\n       9.16515248e-15, 6.61135755e-15, 4.75894867e-15, 3.41816902e-15,\n       2.44980029e-15, 1.75192190e-15, 1.25007988e-15, 8.90003193e-16,\n       6.32219253e-16, 4.48082047e-16, 3.16848831e-16, 2.23533289e-16,\n       1.57332470e-16, 1.10476726e-16, 7.73908207e-17, 5.40833960e-17,\n       3.77036684e-17, 2.62202838e-17, 1.81892138e-17, 1.25863992e-17,\n       8.68736394e-18, 5.98082348e-18, 4.10683758e-18, 2.81264127e-18,\n       1.92117844e-18, 1.30874013e-18, 8.89112745e-19, 6.02369266e-19,\n       4.06963696e-19, 2.74169560e-19, 1.84177575e-19, 1.23364693e-19,\n       8.23879476e-20, 5.48575715e-20, 3.64158384e-20, 2.40993285e-20,\n       1.58986330e-20, 1.04552253e-20, 6.85335955e-21, 4.47761813e-21,\n       2.91568104e-21, 1.89215834e-21, 1.22369599e-21, 7.88608135e-22,\n       5.06398717e-22, 3.23995061e-22, 2.06522912e-22, 1.31144620e-22,\n       8.29568175e-23, 5.22683274e-23, 3.28000176e-23, 2.04984463e-23,\n       1.27567471e-23, 7.90478437e-24, 4.87672455e-24, 2.99508776e-24,\n       1.83099376e-24, 1.11406552e-24, 6.74573518e-25, 4.06432163e-25,\n       2.43629485e-25, 1.45276192e-25, 8.61625497e-26, 5.08200922e-26,\n       2.98040230e-26, 1.73765177e-26, 1.00697989e-26, 5.79917766e-27,\n       3.31827420e-27, 1.88610556e-27, 1.06470628e-27, 5.96760657e-28,\n       3.32022376e-28, 1.83322158e-28, 1.00419848e-28, 5.45569547e-29,\n       2.93878313e-29, 1.56900406e-29, 8.29970690e-30, 4.34827332e-30,\n       2.25532465e-30, 1.15758013e-30, 5.87682184e-31, 2.94964982e-31,\n       1.46287859e-31, 7.16497798e-32, 3.46364531e-32, 1.65154463e-32,\n       7.76235860e-33, 3.59361796e-33, 1.63746349e-33, 7.33763047e-34,\n       3.23073511e-34, 1.39635537e-34, 5.91827421e-35, 2.45707185e-35,\n       9.98027390e-36, 3.96096153e-36, 1.53380821e-36, 5.78590907e-37,\n       2.12251017e-37, 7.55738154e-38, 2.60619183e-38, 8.68384609e-39,\n       2.78812198e-39, 8.59939586e-40, 2.53892010e-40, 7.14638104e-41,\n       1.90861005e-41, 4.80964198e-42, 1.13599514e-42, 2.49463966e-43,\n       5.04321743e-44, 9.27031092e-45, 1.52500211e-45, 2.19851465e-46,\n       2.69875076e-47, 2.70529566e-48, 2.07321187e-49, 1.07763281e-50,\n       2.84250858e-52])}\n(1, [0.2, 0.011760082311389614, 0.018737887669852717, 0.03156447505670982, 0.13360091965816184, 0.13550492742489204, 0.1108511697139353, 0.07226954243956286, 0.07010973464572853, 0.041775869017845114, 0.04038774488928362, 0.023224990933043196, 0.02024011958205141, 0.017249748058332817, 0.016605178815719657, 0.015371018725734827, 0.012441116717360218, 0.011080147347236016, 0.007235275846378654, 0.00632161104533464, 0.003668440101954738]) \n\n(2, array([0.00000000e+00, 2.94002058e-03, 4.85734634e-03, 8.44201652e-03,\n       3.47671175e-02, 3.92827554e-02, 3.92005578e-02, 3.82167303e-02,\n       5.78493269e-02, 6.98970091e-02, 8.02888289e-02, 7.61734696e-02,\n       7.41903730e-02, 6.69141946e-02, 6.10389588e-02, 5.24194843e-02,\n       4.52138495e-02, 3.88397799e-02, 3.43857713e-02, 3.07791506e-02,\n       2.74092159e-02, 2.36324898e-02, 2.04956521e-02, 1.75156273e-02,\n       1.43499891e-02, 1.09322432e-02, 7.94496249e-03, 5.86144073e-03,\n       4.31414707e-03, 3.17678814e-03, 2.39318264e-03, 1.78294201e-03,\n       1.37785690e-03, 1.04328529e-03, 7.73711124e-04, 5.38008712e-04,\n       3.54646204e-04, 2.15963641e-04, 1.16308898e-04, 5.79761287e-05,\n       1.68218160e-05])) \n\n\n\n\n\n5.4.3 Experimental Design\nWe will create a random set of pairs of neighboring schedules with \\(N = 22\\) patients and \\(\\ T = 20\\) intervals of length \\(d = 5\\).\nA neighbor of a schedule x is considered a schedule x’ where single patients have been shifted one interval to the left. Eg: ([2,1,1,2], [1,2,0,3]) are neighbors and ([2,1,1,2], [2,1,3,0]) are not, because [1,2,0,3] - [2,1,1,2] = [-1, 1, -1, 1] and [2,1,3,0] - [2,1,1,2] = [0, 0, 2, -2].\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.2\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. First all the paired schedules will be evaluated by computing the objective value. Then an XGBoost regressor model for predicting objective values will be trained and evaluated.\nThe model will be validated using a new sample of paired schedules the model has never seen (not in the training or the evaluation phase). All the objective values will be computed and the computation time will be recorded. Using the regressor model the objectives will be predicted and the prediciotn time will be measured. The predicted values will be compared to the actual values and the accuracy of the model will be assessed.\nIn order to be able to compare the objective regressor to the ranking model in the other experiment we will also predict the rankings of the paired schedules and compare them to the actual rankings. An opaqueness measure will be calculated for each prediction to assess the confidence of the model and relate it to accuracy.\n\n\n5.4.4 Variables\n\nIndependent Variables: A list of tuples with pairs of neighboring schedules.\nDependent Variables:\n\nA list of tuples with the objective values for each pair of neighboring schedules.\nLists with rankings for each tuple of pairwise schedules. Eg: If the rank for ([2,1,1], [1,1,2]) equals 0 this means that the schedule with index 0 ([2,1,1]) has the lowest objective value.\n\n\n\n\n5.4.5 Data Collection\nThe data set will be generated using simulation in which random samples will be drawn from the population of all possible schedules. For each sample a random neighboring schedule will be created.\n\n\n5.4.6 Sample Size and Selection\nSample Size: The total population size equals \\({{N + T -1}\\choose{N}} \\approx\\) 244663.0 mln. For this experiment we will be using a relatively small sample of 100000 schedules.\nSample Selection: The samples will be drawn from a lexicographic order of possible schedules in order to accurately reflect the combinatorial nature of the problem and to ensure unbiased sampling from the entire combinatorial space.\n\n\n5.4.7 Data Collection\nThe data sample has been generated in an earlier experiment using simulation in which random samples were drawn from the population of all possible schedules.\n\nfile_path_schedules = f\"datasets/neighbors_and_objectives_{N}_{T}_{l}.pkl\"\n# Load the data from the pickle file\nwith open(file_path_schedules, 'rb') as f:\n    data_sch = pickle.load(f)\n\n# Extract the variables from the loaded data\nneighbors_list = data_sch['neighbors_list']\nobjectives_list = data_sch['objectives']\nrankings_list = data_sch['rankings']\n\nprint(\"Data loaded successfully.\\n\")\nfor neigbors in neighbors_list[:2]: print(neigbors, \"\\n\")\nfor objectives in objectives_list[:2]: print(objectives, \"\\n\")\nfor rankings in rankings_list[:2]: print(rankings, \"\\n\")\n\nData loaded successfully.\n\n([2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 2, 3, 1, 1, 1, 1, 3, 2, 1], [2, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 3, 1, 2, 1, 0, 3, 2, 1]) \n\n([1, 4, 0, 2, 0, 1, 3, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 3, 1, 1], [0, 4, 1, 1, 0, 1, 3, 1, 0, 0, 0, 0, 0, 2, 0, 2, 1, 4, 1, 1]) \n\n[81.2707368775113, 74.98339658289757] \n\n[69.86126608781181, 75.66374519649534] \n\n1 \n\n0 \n\n\n\nThe experiment involves multiple steps, beginning with data preparation and concluding with model evaluation.The diagram below illustrates the sequence of steps.\n\n\n\n\n\ngraph TD\n    A[\"From population\"] --&gt;|\"Sample\"| B[\"Random subset\"]\n    B --&gt; |Create neighbors| C[\"Features: Schedule pairs\"]\n    C --&gt; |Calculate objectives| D[\"Labels: Objective values\"]\n    D --&gt; |Flatten lists| E[\"Features and labels\"]\n    E --&gt; |\"Split\"| F[\"Training set\"]\n    E --&gt; |\"Split\"| G[\"Test set\"]\n    F --&gt; |\"Train\"| H[\"Model\"]\n    H[\"Model\"] --&gt; |\"Apply\"| G[\"Test set\"]\n    G[\"Test set\"] --&gt; |\"Evaluate\"| I[\"Performance\"]\n\n\n\n\n\n\n\nPrepare the data for training the XGBoost regressor model.\n\n\n# Transform the schedule and objective data into lists of NumPy arrays\nX = [item for tup in neighbors_list for item in tup]\ny = [item for tup in objectives_list for item in tup]\nprint(f\"Flattened neighbors list: {X[:3]}\")\nprint(f\"Flattened objectives list: {y[:3]}\")\nprint(f\"Number of schedules: {len(X)}\")\n\nFlattened neighbors list: [[2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 2, 3, 1, 1, 1, 1, 3, 2, 1], [2, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 3, 1, 2, 1, 0, 3, 2, 1], [1, 4, 0, 2, 0, 1, 3, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 3, 1, 1]]\nFlattened objectives list: [81.2707368775113, 74.98339658289757, 69.86126608781181]\nNumber of schedules: 200000\n\n\n\nRun hyperparameter optimization for the XGBoost regressor model and record the time taken to find the optimal hyperparameters.\nTrain XGBoost regressor model to predict objective values from given schedules and measure training time.\n\n\n# Ensure that X and y are numpy arrays (convert if needed)\nX = np.array(X)\ny = np.array(y)\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Check the shapes of X and y to ensure compatibility\nprint(f\"X shape: {X.shape}, y shape: {y.shape}\")\n\n#=========================================================================\n# XGBoost regression:\n# Parameters:\n# n_estimators  \"Number of gradient boosted trees. Equivalent to number\n#                of boosting rounds.\"\n# learning_rate \"Boosting learning rate (also known as “eta”)\"\n# max_depth     \"Maximum depth of a tree. Increasing this value will make\n#                the model more complex and more likely to overfit.\"\n#=========================================================================\nregressor=xgb.XGBRegressor(eval_metric='rmsle')\n\n#=========================================================================\n# exhaustively search for the optimal hyperparameters\n#=========================================================================\nfrom sklearn.model_selection import GridSearchCV\n# set up our search grid\nparam_grid = {\"max_depth\":    [4, 5, 7],\n              \"n_estimators\": [500, 700, 900],\n              \"learning_rate\": [0.05, 0.1, 0.15]}\n\n# try out every combination of the above values\nstart = time.time()\nsearch = GridSearchCV(regressor, param_grid, cv=5, verbose=3, n_jobs=-1).fit(X_train, y_train)\nend = time.time()\nhyper_search_time = end - start\nprint(f'Hyperparameter optimization time: {hyper_search_time}')\n\nprint(\"The best hyperparameters are \", search.best_params_)\n\nX shape: (200000, 20), y shape: (200000,)\nFitting 5 folds for each of 27 candidates, totalling 135 fits\nHyperparameter optimization time: 287.8828978538513\nThe best hyperparameters are  {'learning_rate': 0.15, 'max_depth': 7, 'n_estimators': 900}\n\n\n\nregressor=xgb.XGBRegressor(learning_rate = search.best_params_[\"learning_rate\"],\n                       n_estimators  = search.best_params_[\"n_estimators\"],\n                       max_depth     = search.best_params_[\"max_depth\"],\n                       eval_metric='rmsle')\n\nstart = time.time()\nregressor.fit(X_train, y_train)\nend = time.time()\ntraining_time = end - start\nprint(f\"\\nTraining time: {training_time} seconds\\n\")\n#Save model\nregressor.save_model('models/regressor_large_instance.json')\n# Save parameters\nparams = regressor.get_params()\nwith open('models/regressor_params.json', 'w') as f:\n    json.dump(params, f)\n\n\nTraining time: 9.762606143951416 seconds\n\n\n\n\nUse the trained model to predict the objective values for the test set and calculate the Mean Absolute Percentage Error (MAPE) between the predicted and true values.\n\n\n# Make predictions on the test set\npredictions = regressor.predict(X_test)\n\n# Calculate Mean Absolute Percentage Error (MAPE)\ndef mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\nmape = mean_absolute_percentage_error(y_test, predictions)\nprint(f'MAPE: {mape:.2f}%')\n\nMAPE: 1.05%\n\n\n\n# Create the scatter plot\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=y_test, \n    y=predictions, \n    mode='markers',\n    marker=dict(color='blue'),\n    name='Predictions vs. true values'\n))\nfig.add_trace(go.Scatter(\n    x=[0, max(max(y_test), max(predictions))],\n    y=[0, max(max(y_test), max(predictions))],\n    mode='lines',\n    line=dict(color='tomato', dash='dash'),\n    name='Base line',\n))\n\n# Add axis labels and a title\nfig.update_layout(\n    title='Predictions vs. true values',\n    xaxis_title='True values',\n    yaxis_title='Predictions',\n    showlegend=True\n)\n\n# Show the plot\nfig.show()\n\n                                                \n\n\n\n\n5.4.8 Validation\n\nCreate validation set with pairs of neighboring schedules and calculate their objectives. Measure calculation time.\n\n\nfrom functions import random_combination_with_replacement, create_neighbors_list, calculate_objective_serv_time_lookup\n\nnum_test_schedules = 1000\n\ntest_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_neighbors = [create_neighbors_list(test_schedule, v_star) for test_schedule in test_schedules] # This can be done in parellel to improve speed\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\n# Start time measeurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_1 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[0], d, convolutions)]\n]\nend = time.time()\nevaluation_time = end - start\nprint(f\"Evaluation time: {evaluation_time} seconds,\\nNumber of evaluated schedules: {len(test_schedules)}\\n\")\ntest_objectives_schedule_2 = [\n    w * result[0] + (1 - w) * result[1]\n    for test_neighbor in test_neighbors\n    for result in [calculate_objective_serv_time_lookup(test_neighbor[1], d, convolutions)]\n]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nTotal number of combinations: 244,662,670,200\nSampled: 1000 schedules\n\nEvaluation time: 4.337012052536011 seconds,\nNumber of evaluated schedules: 1000\n\nNeighbors: ([10, 5, 3, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 5, 3, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [141.56797537792352, 132.28609296509896], Ranking: 1\n\nNeighbors: ([11, 6, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [11, 6, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [147.5679720818301, 139.78607684820375], Ranking: 1\n\nNeighbors: ([16, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [15, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]),\nObjectives: [141.5682200807479, 133.6372066343275], Ranking: 1\n\nNeighbors: ([8, 7, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [8, 6, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [146.06804621994024, 137.78614553350565], Ranking: 1\n\nNeighbors: ([10, 5, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [10, 4, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [139.5699335980151, 132.78667300944142], Ranking: 1\n\nNeighbors: ([12, 6, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [13, 5, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\nObjectives: [139.13698095982733, 142.09419227359442], Ranking: 0\n\n\n\n\nPredict for each schedule in the validation set the objectives using the regressor model. Measure prediction time.\n\n\ndef predict_objective(neighbors):\n    neighbors_array = [np.array(neighbor) for neighbor in neighbors] # Convert schedules to a NumPy array\n    neighbors_array = np.vstack(neighbors_array)\n    predictions = regressor.predict(neighbors_array)\n    return predictions\n\n# Start time measurement for the prediction\nstart = time.time()\npredictions = regressor.predict(test_schedules)\nend = time.time()\nprediction_time = end - start\nprint(f\"Prediction time: {prediction_time},\\nNumber of predicted schedules: {len(predictions)}\\n\")\n\n# Calculate the rankings based on the predicted objectives\npredictions = [predict_objective(neighbors) for neighbors in test_neighbors]\npred_rankings = [np.argmin(objectives) for objectives in predictions]\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nPredictions: {predictions[i]}, Ranking: {pred_rankings[i]}\\n\")\n\nPrediction time: 0.006134986877441406,\nNumber of predicted schedules: 1000\n\nNeighbors: ([10, 5, 3, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [9, 5, 3, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nPredictions: [120.69343 116.85778], Ranking: 1\n\nNeighbors: ([11, 6, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [11, 6, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nPredictions: [120.45598  111.875084], Ranking: 1\n\nNeighbors: ([16, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [15, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]),\nPredictions: [99.86046 98.93282], Ranking: 1\n\nNeighbors: ([8, 7, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [8, 6, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nPredictions: [118.224106 115.95842 ], Ranking: 1\n\nNeighbors: ([10, 5, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [10, 4, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]),\nPredictions: [115.46417 110.51194], Ranking: 1\n\nNeighbors: ([12, 6, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [13, 5, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\nPredictions: [109.534904 107.357574], Ranking: 1\n\n\n\n\nCalculate opaqueness and accuracy comparing true and predicted rankings.\n\nOpaqueness is calculated using the formula for entropy:\n\\[\nH(X) = - \\sum_{i} p(x_i) \\log_b p(x_i)\n\\]\nWhere in our case:\n\n\\(H(X)\\) is the opaqueness of the random variable \\(X\\) - the set of predicted normalized objective values for each of the paired schedules,\n\\(p(x_i)\\) is the normalized outcome \\(x_i\\),\n\\(\\log_b\\) is the logarithm with base \\(b\\) (here \\(\\log_2\\) as we have two predicted values),\nThe sum is taken over all possible outcomes of \\(X\\).\n\n\nfrom functions import calculate_opaqueness\n\nerrors = np.abs(np.array(test_rankings) - pred_rankings)\naccuracy = 1 - errors.mean()\nprint(f\"Accuracy = {accuracy}\")\n\n# Calculate the opaqueness of each prediction\nnormalised_predictions = [prediction / np.sum(prediction) for prediction in predictions]\nopaqueness = [calculate_opaqueness(vector) for vector in normalised_predictions]\n\nAccuracy = 0.657\n\n\n\npredicted_values_left = [prediction[0] for prediction in predictions]\n\n\ndf = pd.DataFrame({\"Opaqueness\": opaqueness, \"Error\": errors, \"Predictions\": predictions}).sort_values(by=\"Opaqueness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\nprint(df.head())\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Opaqueness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9),\n                    text=[f'{prediction}' for prediction in df[\"Predictions\"]],))\nfig.add_trace(go.Scatter(x=df[\"Opaqueness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Opaqueness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Opaqueness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()\n\n     Opaqueness  Error             Predictions  Cumulative error rate  \\\n978    0.997419      0   [105.58317, 93.66761]                    0.0   \n753    0.997862      0   [101.92029, 91.39842]                    0.0   \n441    0.997947      0  [106.83198, 96.013855]                    0.0   \n131    0.998101      0   [109.58637, 98.89068]                    0.0   \n633    0.998102      0  [110.45487, 99.677536]                    0.0   \n\n     Cumulative accuracy  \n978                  1.0  \n753                  1.0  \n441                  1.0  \n131                  1.0  \n633                  1.0",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html#results",
    "href": "xgboost-objective-calc-large.html#results",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "5.5 Results",
    "text": "5.5 Results\nWe wanted to test whether an XGBoost regressor model could be used to assess the objective values schedules. For performance benchmarking we use the conventional calculation method utilizing Lindley recursions.\nWe trained the XGBoost regressor model with a limited set of features (schedules) and labels (objectives). The total number of possible schedules is approximately 244663.0 million. For training and validation, we sampled 100000 schedules.\nThe model demonstrates strong and consistent performance with high prediction ability both for training as well as testing, good generalization and stability. Total training time for the final model was 9.7626 seconds. The evaluation of 1000 test schedules took 0.0061 seconds for the the XGBoost model and 4.337 for the conventional method, which is an improvement of 706X.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html#discussion",
    "href": "xgboost-objective-calc-large.html#discussion",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "5.6 Discussion",
    "text": "5.6 Discussion\n\ntraining_time = round(training_time, 4)\nconventional_time = round(evaluation_time, 4)\nxgboost_time = round(prediction_time, 4)\n\n# Define time values for plotting\ntime_values = np.linspace(0, training_time+0.1, 1000)  # 0 to 2 seconds\n\n# Calculate evaluations for method 1\nmethod1_evaluations = np.where(time_values &gt;= training_time, (time_values - training_time) / xgboost_time * 1000, 0)\n\n# Calculate evaluations for method 2\nmethod2_evaluations = time_values / conventional_time * 1000\n\n# Create line chart\nfig = go.Figure()\n\n# Add method 1 trace\nfig.add_trace(go.Scatter(x=time_values, y=method1_evaluations, mode='lines', name='Regressor model'))\n\n# Add method 2 trace\nfig.add_trace(go.Scatter(x=time_values, y=method2_evaluations, mode='lines', name='Conventional method'))\n\n# Update layout\nfig.update_layout(\n    title=\"Speed comparison between XGBoost regressor model and conventional method\",\n    xaxis_title=\"Time (seconds)\",\n    yaxis_title=\"Number of Evaluations\",\n    legend_title=\"Methods\",\n    template=\"plotly_white\"\n)\n\nfig.show()",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html#timeline",
    "href": "xgboost-objective-calc-large.html#timeline",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "5.7 Timeline",
    "text": "5.7 Timeline\nThis experiment was started on 16-10-2024. The expected completion date is 01-11-2024.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc-large.html#references",
    "href": "xgboost-objective-calc-large.html#references",
    "title": "5  Large instance XGBoost regression model for objective calculation",
    "section": "5.8 References",
    "text": "5.8 References\nCite all sources that informed your experiment, including research papers, datasets, and tools. This section ensures that your work is properly grounded in existing research and that others can trace the origins of your methods and data.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Large instance XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html",
    "href": "local-search-regressor-large.html",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "",
    "text": "6.1 Objective\nTest the working and performance of a previously trained XGBoost Regressor model in a local search application.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html#background",
    "href": "local-search-regressor-large.html#background",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "6.2 Background",
    "text": "6.2 Background\nIn previous experiments, we trained an XGBoost Regressor model to predict the objective values of neighboring schedules. In this experiment, we will use the trained models to perform a local search to find the best schedule.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html#hypothesis",
    "href": "local-search-regressor-large.html#hypothesis",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "6.3 Hypothesis",
    "text": "6.3 Hypothesis\nThe XGBoost Regressor model will be able to efficiently guide the local search algorithm to find a schedule with a lower objective value than the initial schedule.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html#methodology",
    "href": "local-search-regressor-large.html#methodology",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "6.4 Methodology",
    "text": "6.4 Methodology\n\n6.4.1 Tools and Materials\n\nimport numpy as np\nimport json\nfrom itertools import chain, combinations\nimport sys\nfrom math import comb  # Available in Python 3.8 and later\nimport xgboost as xgb\nfrom functions import calculate_objective\nimport pickle\n\n\n\n6.4.2 Load Parameters\n\nN = 22\nT = 20\nl = 10\n\nfile_path_parameters = f\"datasets/parameters_{N}_{T}_{l}.pkl\"\n# Load the data from the pickle file\nwith open(file_path_parameters, 'rb') as f:\n    data_params = pickle.load(f)\n\nfor key in data_params.keys():\n  print(f\"{key} = {data_params[key]}\")\n\nN = data_params['N'] # Number of patients\nT = data_params['T'] # Number of intervals\nd = data_params['d'] # Length of each interval\nmax_s = data_params['max_s'] # Maximum service time\nq = data_params['q'] # Probability of a scheduled patient not showing up\nw = data_params['w'] # Weight for the waiting time in objective function\nl = data_params['l']\n\nfor key in data_params.keys():\n  print(f\"{key} = {data_params[key]}\")\n  \nnum_schedules = data_params['num_schedules'] # Number of schedules to sample\nconvolutions = data_params['convolutions']\n\nN = 22\nT = 20\nd = 5\nmax_s = 20\nq = 0.2\nw = 0.1\nl = 10\nnum_schedules = 100000\nconvolutions = {1: [0.2, 0.011760082311389614, 0.018737887669852717, 0.03156447505670982, 0.13360091965816184, 0.13550492742489204, 0.1108511697139353, 0.07226954243956286, 0.07010973464572853, 0.041775869017845114, 0.04038774488928362, 0.023224990933043196, 0.02024011958205141, 0.017249748058332817, 0.016605178815719657, 0.015371018725734827, 0.012441116717360218, 0.011080147347236016, 0.007235275846378654, 0.00632161104533464, 0.003668440101954738], 2: array([0.00000000e+00, 2.94002058e-03, 4.85734634e-03, 8.44201652e-03,\n       3.47671175e-02, 3.92827554e-02, 3.92005578e-02, 3.82167303e-02,\n       5.78493269e-02, 6.98970091e-02, 8.02888289e-02, 7.61734696e-02,\n       7.41903730e-02, 6.69141946e-02, 6.10389588e-02, 5.24194843e-02,\n       4.52138495e-02, 3.88397799e-02, 3.43857713e-02, 3.07791506e-02,\n       2.74092159e-02, 2.36324898e-02, 2.04956521e-02, 1.75156273e-02,\n       1.43499891e-02, 1.09322432e-02, 7.94496249e-03, 5.86144073e-03,\n       4.31414707e-03, 3.17678814e-03, 2.39318264e-03, 1.78294201e-03,\n       1.37785690e-03, 1.04328529e-03, 7.73711124e-04, 5.38008712e-04,\n       3.54646204e-04, 2.15963641e-04, 1.16308898e-04, 5.79761287e-05,\n       1.68218160e-05]), 3: array([0.00000000e+00, 0.00000000e+00, 4.32186050e-05, 1.40265710e-04,\n       3.53869282e-04, 1.39144845e-03, 3.03403976e-03, 5.50805464e-03,\n       1.12045966e-02, 1.76075704e-02, 2.32499285e-02, 2.78477994e-02,\n       3.46910124e-02, 4.22505513e-02, 5.01159446e-02, 5.53915078e-02,\n       5.89758642e-02, 6.01215563e-02, 5.99423610e-02, 5.78632533e-02,\n       5.48655440e-02, 5.11004377e-02, 4.73564348e-02, 4.37070119e-02,\n       4.02402424e-02, 3.67137428e-02, 3.32503637e-02, 2.98707447e-02,\n       2.64939306e-02, 2.30340039e-02, 1.96059983e-02, 1.64060310e-02,\n       1.35696836e-02, 1.11162642e-02, 9.04724056e-03, 7.32634799e-03,\n       5.91852188e-03, 4.76814798e-03, 3.82017054e-03, 3.02750310e-03,\n       2.36485488e-03, 1.81485519e-03, 1.36839365e-03, 1.01155073e-03,\n       7.33111978e-04, 5.22631425e-04, 3.70472319e-04, 2.62868968e-04,\n       1.85973042e-04, 1.31237358e-04, 9.18363665e-05, 6.33417856e-05,\n       4.27658922e-05, 2.78349940e-05, 1.72697010e-05, 1.00584007e-05,\n       5.44928710e-06, 2.66671347e-06, 1.14360655e-06, 3.98778666e-07,\n       7.71372804e-08]), 4: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.35317940e-07,\n       3.07420208e-06, 1.01924845e-05, 4.14947126e-05, 1.21898778e-04,\n       2.95777252e-04, 7.29082488e-04, 1.54646029e-03, 2.86935326e-03,\n       5.03941842e-03, 8.10395568e-03, 1.18092601e-02, 1.58618976e-02,\n       2.04536739e-02, 2.55735385e-02, 3.10991933e-02, 3.64557423e-02,\n       4.12982386e-02, 4.52422233e-02, 4.82244237e-02, 5.00743660e-02,\n       5.08758176e-02, 5.06943477e-02, 4.97767772e-02, 4.82960629e-02,\n       4.64338380e-02, 4.42464571e-02, 4.18080229e-02, 3.91687504e-02,\n       3.63660273e-02, 3.34056615e-02, 3.03217052e-02, 2.71859440e-02,\n       2.40944965e-02, 2.11312208e-02, 1.83600898e-02, 1.58216111e-02,\n       1.35384972e-02, 1.15129032e-02, 9.73236987e-03, 8.17407196e-03,\n       6.81474447e-03, 5.63364260e-03, 4.61465608e-03, 3.74301056e-03,\n       3.00528177e-03, 2.38892841e-03, 1.88199499e-03, 1.47133129e-03,\n       1.14265141e-03, 8.81920749e-04, 6.76492739e-04, 5.15447656e-04,\n       3.89711426e-04, 2.91929513e-04, 2.16272111e-04, 1.58230534e-04,\n       1.14237711e-04, 8.13841253e-05, 5.72513050e-05, 3.98126390e-05,\n       2.74131488e-05, 1.87228096e-05, 1.26989339e-05, 8.53965213e-06,\n       5.67352874e-06, 3.70846579e-06, 2.37078715e-06, 1.47278678e-06,\n       8.81826178e-07, 5.03931537e-07, 2.71938862e-07, 1.36824477e-07,\n       6.31260223e-08, 2.59401007e-08, 9.09285656e-09, 2.43815942e-09,\n       3.53716866e-10]), 5: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       9.33923909e-09, 6.00717321e-08, 2.46902484e-07, 1.07610188e-06,\n       3.78698535e-06, 1.11512123e-05, 3.15944232e-05, 8.06113857e-05,\n       1.84183437e-04, 3.95885341e-04, 7.88467975e-04, 1.44458464e-03,\n       2.47203728e-03, 3.96941560e-03, 5.97657199e-03, 8.47242036e-03,\n       1.14461984e-02, 1.48794592e-02, 1.87230630e-02, 2.28366330e-02,\n       2.70364139e-02, 3.11077427e-02, 3.48702212e-02, 3.81571729e-02,\n       4.08581843e-02, 4.29024392e-02, 4.42869926e-02, 4.50429779e-02,\n       4.52336186e-02, 4.49162765e-02, 4.41490428e-02, 4.29821229e-02,\n       4.14631235e-02, 3.96294961e-02, 3.75191619e-02, 3.51774463e-02,\n       3.26629391e-02, 3.00419527e-02, 2.73820229e-02, 2.47453736e-02,\n       2.21856209e-02, 1.97446030e-02, 1.74513841e-02, 1.53226008e-02,\n       1.33653504e-02, 1.15802823e-02, 9.96465391e-03, 8.51356896e-03,\n       7.22081280e-03, 6.07917252e-03, 5.08067041e-03, 4.21619591e-03,\n       3.47527054e-03, 2.84619162e-03, 2.31662030e-03, 1.87419846e-03,\n       1.50708097e-03, 1.20430932e-03, 9.56050851e-04, 7.53703510e-04,\n       5.89859326e-04, 4.58170017e-04, 3.53185533e-04, 2.70214236e-04,\n       2.05223691e-04, 1.54767320e-04, 1.15924450e-04, 8.62487918e-05,\n       6.37294755e-05, 4.67470535e-05, 3.40192154e-05, 2.45424688e-05,\n       1.75382796e-05, 1.24053920e-05, 8.68073979e-06, 6.00804632e-06,\n       4.11318185e-06, 2.78627230e-06, 1.86818843e-06, 1.24005563e-06,\n       8.14650295e-07, 5.29162647e-07, 3.39183124e-07, 2.13861735e-07,\n       1.32118911e-07, 7.95975920e-08, 4.65104419e-08, 2.61928904e-08,\n       1.41105789e-08, 7.20777590e-09, 3.45396586e-09, 1.53149368e-09,\n       6.15952978e-10, 2.17751499e-10, 6.41611678e-11, 1.39753778e-11,\n       1.62198642e-12]), 6: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 1.37287775e-10, 1.10180766e-09, 5.40499885e-09,\n       2.55316766e-08, 1.02229543e-07, 3.47784439e-07, 1.10574507e-06,\n       3.22014854e-06, 8.52307587e-06, 2.11264440e-05, 4.89416545e-05,\n       1.05523845e-04, 2.13856975e-04, 4.08363978e-04, 7.34079216e-04,\n       1.24607635e-03, 2.00521331e-03, 3.06713884e-03, 4.47206830e-03,\n       6.24535758e-03, 8.39787265e-03, 1.09223889e-02, 1.37826874e-02,\n       1.69112845e-02, 2.02119297e-02, 2.35725940e-02, 2.68738686e-02,\n       3.00018540e-02, 3.28554743e-02, 3.53567448e-02, 3.74522177e-02,\n       3.91136858e-02, 4.03309189e-02, 4.11073798e-02, 4.14547538e-02,\n       4.13910230e-02, 4.09372197e-02, 4.01175990e-02, 3.89606711e-02,\n       3.75016933e-02, 3.57831259e-02, 3.38536058e-02, 3.17652874e-02,\n       2.95710087e-02, 2.73212957e-02, 2.50618484e-02, 2.28316953e-02,\n       2.06624890e-02, 1.85787536e-02, 1.65988553e-02, 1.47360638e-02,\n       1.29995281e-02, 1.13950216e-02, 9.92552138e-03, 8.59151109e-03,\n       7.39113288e-03, 6.32030752e-03, 5.37298875e-03, 4.54154197e-03,\n       3.81720641e-03, 3.19056551e-03, 2.65198600e-03, 2.19198636e-03,\n       1.80150953e-03, 1.47208951e-03, 1.19592787e-03, 9.65909979e-04,\n       7.75591871e-04, 6.19175625e-04, 4.91481166e-04, 3.87917772e-04,\n       3.04457667e-04, 2.37608519e-04, 1.84380001e-04, 1.42242049e-04,\n       1.09076944e-04, 8.31283342e-05, 6.29506788e-05, 4.73615618e-05,\n       3.53986572e-05, 2.62824219e-05, 1.93846973e-05, 1.42025740e-05,\n       1.03365475e-05, 7.47207578e-06, 5.36386711e-06, 3.82251455e-06,\n       2.70317029e-06, 1.89600968e-06, 1.31835177e-06, 9.08318477e-07,\n       6.19847121e-07, 4.18829190e-07, 2.80160067e-07, 1.85494460e-07,\n       1.21545372e-07, 7.87940292e-08, 5.05053384e-08, 3.19765210e-08,\n       1.99666483e-08, 1.22694135e-08, 7.39890897e-09, 4.36362584e-09,\n       2.50689903e-09, 1.39653646e-09, 7.50429849e-10, 3.86592194e-10,\n       1.89547068e-10, 8.76711109e-11, 3.78268355e-11, 1.49965203e-11,\n       5.34422400e-12, 1.65437230e-12, 4.19317279e-13, 7.69017545e-14,\n       7.43770003e-15]), 7: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 2.01814443e-12, 1.94122896e-11,\n       1.10677745e-10, 5.68315791e-10, 2.52131146e-09, 9.62258123e-09,\n       3.37784230e-08, 1.09215255e-07, 3.23867327e-07, 8.97823079e-07,\n       2.33562731e-06, 5.69512765e-06, 1.31015280e-05, 2.85202882e-05,\n       5.87647118e-05, 1.14886007e-04, 2.13592919e-04, 3.78099858e-04,\n       6.38267972e-04, 1.02976473e-03, 1.59153260e-03, 2.36191864e-03,\n       3.37514137e-03, 4.65842798e-03, 6.22917692e-03, 8.09127374e-03,\n       1.02319121e-02, 1.26199283e-02, 1.52069905e-02, 1.79305412e-02,\n       2.07185288e-02, 2.34945935e-02, 2.61838704e-02, 2.87177237e-02,\n       3.10373936e-02, 3.30953529e-02, 3.48554065e-02, 3.62916083e-02,\n       3.73871334e-02, 3.81328730e-02, 3.85265399e-02, 3.85722140e-02,\n       3.82805832e-02, 3.76692112e-02, 3.67625370e-02, 3.55912089e-02,\n       3.41908886e-02, 3.26005883e-02, 3.08608023e-02, 2.90116297e-02,\n       2.70911761e-02, 2.51343913e-02, 2.31724208e-02, 2.12323728e-02,\n       1.93373718e-02, 1.75067593e-02, 1.57563580e-02, 1.40987155e-02,\n       1.25432996e-02, 1.10966504e-02, 9.76254184e-03, 8.54219148e-03,\n       7.43453823e-03, 6.43657977e-03, 5.54374959e-03, 4.75030505e-03,\n       4.04969802e-03, 3.43490184e-03, 2.89867980e-03, 2.43379187e-03,\n       2.03314748e-03, 1.68991563e-03, 1.39760359e-03, 1.15011281e-03,\n       9.41778896e-04, 7.67399068e-04, 6.22248209e-04, 5.02082802e-04,\n       4.03132871e-04, 3.22082980e-04, 2.56044463e-04, 2.02521485e-04,\n       1.59373647e-04, 1.24777626e-04, 9.71898468e-05, 7.53114956e-05,\n       5.80564865e-05, 4.45225142e-05, 3.39650595e-05, 2.57741424e-05,\n       1.94536127e-05, 1.46027894e-05, 1.09003105e-05, 8.09009527e-06,\n       5.96931593e-06, 4.37824165e-06, 3.19177865e-06, 2.31250396e-06,\n       1.66498270e-06, 1.19116477e-06, 8.46673402e-07, 5.97822283e-07,\n       4.19226268e-07, 2.91896462e-07, 2.01731534e-07, 1.38333127e-07,\n       9.40847869e-08, 6.34434018e-08, 4.24001446e-08, 2.80745183e-08,\n       1.84110832e-08, 1.19542864e-08, 7.68208172e-09, 4.88348501e-09,\n       3.06887791e-09, 1.90465539e-09, 1.16595979e-09, 7.02839620e-10,\n       4.16318897e-10, 2.41709572e-10, 1.37140565e-10, 7.57799027e-11,\n       4.06220920e-11, 2.10304456e-11, 1.04607490e-11, 4.96879733e-12,\n       2.23721674e-12, 9.46117936e-13, 3.71359512e-13, 1.33106185e-13,\n       4.25521951e-14, 1.16981783e-14, 2.59774639e-15, 4.11409659e-16,\n       3.41059463e-17]), 8: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.96669307e-14,\n       3.32632359e-13, 2.16128295e-12, 1.20495904e-11, 5.83254011e-11,\n       2.44982264e-10, 9.37937964e-10, 3.31090086e-09, 1.07763075e-08,\n       3.27754187e-08, 9.37197103e-08, 2.52240817e-07, 6.42127344e-07,\n       1.55130357e-06, 3.56106697e-06, 7.78403657e-06, 1.62339430e-05,\n       3.23405268e-05, 6.16207471e-05, 1.12455479e-04, 1.96819590e-04,\n       3.30791101e-04, 5.34679044e-04, 8.32571530e-04, 1.25119762e-03,\n       1.81825202e-03, 2.56041648e-03, 3.50119906e-03, 4.65858915e-03,\n       6.04270414e-03, 7.65376161e-03, 9.48083281e-03, 1.15015825e-02,\n       1.36830855e-02, 1.59835591e-02, 1.83548561e-02, 2.07453258e-02,\n       2.31027057e-02, 2.53765994e-02, 2.75203688e-02, 2.94923504e-02,\n       3.12565581e-02, 3.27829693e-02, 3.40476137e-02, 3.50325988e-02,\n       3.57262235e-02, 3.61231503e-02, 3.62245560e-02, 3.60380999e-02,\n       3.55776239e-02, 3.48625294e-02, 3.39168622e-02, 3.27681720e-02,\n       3.14462686e-02, 2.99820016e-02, 2.84061785e-02, 2.67486884e-02,\n       2.50378470e-02, 2.32999409e-02, 2.15589337e-02, 1.98362846e-02,\n       1.81508401e-02, 1.65187689e-02, 1.49535343e-02, 1.34659095e-02,\n       1.20640461e-02, 1.07536041e-02, 9.53794025e-03, 8.41834816e-03,\n       7.39433321e-03, 6.46390441e-03, 5.62386379e-03, 4.87007810e-03,\n       4.19772307e-03, 3.60149645e-03, 3.07579985e-03, 2.61489219e-03,\n       2.21301827e-03, 1.86451598e-03, 1.56390469e-03, 1.30595630e-03,\n       1.08574960e-03, 8.98708674e-04, 7.40626363e-04, 6.07674253e-04,\n       4.96401246e-04, 4.03722969e-04, 3.26904421e-04, 2.63538065e-04,\n       2.11519238e-04, 1.69020315e-04, 1.34464629e-04, 1.06500865e-04,\n       8.39783503e-05, 6.59235857e-05, 5.15181907e-05, 4.00784542e-05,\n       3.10366016e-05, 2.39238636e-05, 1.83553737e-05, 1.40168654e-05,\n       1.06530900e-05, 8.05783422e-06, 6.06539235e-06, 4.54333360e-06,\n       3.38640636e-06, 2.51142976e-06, 1.85303697e-06, 1.36014968e-06,\n       9.93077528e-07, 7.21148556e-07, 5.20788255e-07, 3.73974252e-07,\n       2.67002539e-07, 1.89509349e-07, 1.33700650e-07, 9.37486958e-08,\n       6.53219310e-08, 4.52206751e-08, 3.10962522e-08, 2.12356780e-08,\n       1.43976318e-08, 9.68835673e-09, 6.46846181e-09, 4.28346429e-09,\n       2.81241920e-09, 1.83020494e-09, 1.18002634e-09, 7.53494695e-10,\n       4.76282755e-10, 2.97855405e-10, 1.84163557e-10, 1.12482006e-10,\n       6.77906759e-11, 4.02603155e-11, 2.35229019e-11, 1.34946492e-11,\n       7.58398118e-12, 4.16444181e-12, 2.22761842e-12, 1.15684434e-12,\n       5.81004596e-13, 2.80944221e-13, 1.30116794e-13, 5.73611648e-14,\n       2.38874283e-14, 9.30725023e-15, 3.35057381e-15, 1.09544511e-15,\n       3.17287149e-16, 7.83632125e-17, 1.54715185e-17, 2.15604527e-18,\n       1.56394527e-19]), 9: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       4.36106934e-16, 5.58459942e-15, 4.07326429e-14, 2.45831184e-13,\n       1.28546894e-12, 5.86419590e-12, 2.42542575e-11, 9.24187318e-11,\n       3.25655966e-10, 1.07235283e-09, 3.32274707e-09, 9.71469186e-09,\n       2.69127134e-08, 7.08902611e-08, 1.77886163e-07, 4.26123735e-07,\n       9.76353953e-07, 2.14259186e-06, 4.50900354e-06, 9.11105535e-06,\n       1.76955279e-05, 3.30670919e-05, 5.95131680e-05, 1.03269265e-04,\n       1.72957683e-04, 2.79915266e-04, 4.38314619e-04, 6.64990292e-04,\n       9.78924118e-04, 1.40039907e-03, 1.94986351e-03, 2.64655749e-03,\n       3.50698038e-03, 4.54332647e-03, 5.76206543e-03, 7.16284454e-03,\n       8.73785756e-03, 1.04717562e-02, 1.23421193e-02, 1.43204134e-02,\n       1.63733229e-02, 1.84642744e-02, 2.05549865e-02, 2.26069022e-02,\n       2.45824294e-02, 2.64459583e-02, 2.81646782e-02, 2.97092332e-02,\n       3.10542773e-02, 3.21789621e-02, 3.30673634e-02, 3.37088165e-02,\n       3.40981135e-02, 3.42355178e-02, 3.41265678e-02, 3.37816677e-02,\n       3.32154897e-02, 3.24462393e-02, 3.14948475e-02, 3.03841545e-02,\n       2.91381379e-02, 2.77812197e-02, 2.63376676e-02, 2.48310927e-02,\n       2.32840335e-02, 2.17176142e-02, 2.01512676e-02, 1.86025159e-02,\n       1.70868100e-02, 1.56174291e-02, 1.42054432e-02, 1.28597366e-02,\n       1.15870896e-02, 1.03923083e-02, 9.27839283e-03, 8.24672966e-03,\n       7.29729655e-03, 6.42886945e-03, 5.63922367e-03, 4.92532407e-03,\n       4.28350161e-03, 3.70961470e-03, 3.19919499e-03, 2.74757743e-03,\n       2.35001450e-03, 2.00177438e-03, 1.69822309e-03, 1.43489086e-03,\n       1.20752339e-03, 1.01211905e-03, 8.44953614e-04, 7.02594104e-04,\n       5.81903678e-04, 4.80039306e-04, 3.94443845e-04, 3.22833915e-04,\n       2.63184726e-04, 2.13712835e-04, 1.72857587e-04, 1.39261912e-04,\n       1.11752988e-04, 8.93232395e-05, 7.11120177e-05, 5.63882612e-05,\n       4.45343334e-05, 3.50311706e-05, 2.74448025e-05, 2.14142522e-05,\n       1.66407775e-05, 1.28783861e-05, 9.92553753e-06, 7.61793536e-06,\n       5.82230962e-06, 4.43108959e-06, 3.35787095e-06, 2.53358544e-06,\n       1.90328611e-06, 1.42346769e-06, 1.05984722e-06, 7.85537509e-07,\n       5.79552589e-07, 4.25591632e-07, 3.11054811e-07, 2.26251005e-07,\n       1.63763307e-07, 1.17943638e-07, 8.45124073e-08, 6.02431816e-08,\n       4.27157331e-08, 3.01237682e-08, 2.11260799e-08, 1.47319667e-08,\n       1.02135109e-08, 7.03877683e-09, 4.82120769e-09, 3.28149304e-09,\n       2.21898886e-09, 1.49041558e-09, 9.94073210e-10, 6.58215380e-10,\n       4.32540642e-10, 2.82005147e-10, 1.82352631e-10, 1.16905891e-10,\n       7.42784526e-11, 4.67528004e-11, 2.91382447e-11, 1.79717279e-11,\n       1.09623232e-11, 6.60786250e-12, 3.93238099e-12, 2.30779160e-12,\n       1.33384003e-12, 7.58050253e-13, 4.22857896e-13, 2.31044572e-13,\n       1.23362864e-13, 6.41965572e-14, 3.24624261e-14, 1.58972403e-14,\n       7.51018843e-15, 3.40733926e-15, 1.47676419e-15, 6.07524219e-16,\n       2.35369535e-16, 8.50209857e-17, 2.82606422e-17, 8.48996806e-18,\n       2.24638297e-18, 5.03260163e-19, 8.93969701e-20, 1.11224854e-20,\n       7.17154941e-22]), 10: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 6.41081679e-18, 9.23088394e-17, 7.46785395e-16,\n       4.86097235e-15, 2.72681056e-14, 1.33821167e-13, 5.93378980e-13,\n       2.42053289e-12, 9.14412398e-12, 3.22857479e-11, 1.07305613e-10,\n       3.37001018e-10, 1.00409751e-09, 2.84826926e-09, 7.71010932e-09,\n       1.99596188e-08, 4.95120014e-08, 1.17866285e-07, 2.69629248e-07,\n       5.93439977e-07, 1.25798181e-06, 2.57079664e-06, 5.06927180e-06,\n       9.65328668e-06, 1.77668521e-05, 3.16306961e-05, 5.45179106e-05,\n       9.10515099e-05, 1.47489422e-04, 2.31951454e-04, 3.54536947e-04,\n       5.27285221e-04, 7.63944251e-04, 1.07953145e-03, 1.48968920e-03,\n       2.00985770e-03, 2.65431146e-03, 3.43513054e-03, 4.36119672e-03,\n       5.43731097e-03, 6.66351902e-03, 8.03471129e-03, 9.54053146e-03,\n       1.11655932e-02, 1.28899689e-02, 1.46898879e-02, 1.65385709e-02,\n       1.84071274e-02, 2.02654584e-02, 2.20831247e-02, 2.38301614e-02,\n       2.54778310e-02, 2.69993212e-02, 2.83703842e-02, 2.95699139e-02,\n       3.05804397e-02, 3.13885169e-02, 3.19849851e-02, 3.23650781e-02,\n       3.25283755e-02, 3.24786013e-02, 3.22232899e-02, 3.17733470e-02,\n       3.11425420e-02, 3.03469637e-02, 2.94044696e-02, 2.83341512e-02,\n       2.71558277e-02, 2.58895793e-02, 2.45553213e-02, 2.31724233e-02,\n       2.17593747e-02, 2.03334993e-02, 1.89107236e-02, 1.75053990e-02,\n       1.61301818e-02, 1.47959682e-02, 1.35118814e-02, 1.22853051e-02,\n       1.11219559e-02, 1.00259851e-02, 9.00010389e-03, 8.04572215e-03,\n       7.16309602e-03, 6.35147847e-03, 5.60926896e-03, 4.93415921e-03,\n       4.32327241e-03, 3.77329405e-03, 3.28059249e-03, 2.84132801e-03,\n       2.45154952e-03, 2.10727818e-03, 1.80457807e-03, 1.53961416e-03,\n       1.30869838e-03, 1.10832467e-03, 9.35194382e-04, 7.86233024e-04,\n       6.58599786e-04, 5.49690857e-04, 4.57137689e-04, 3.78801151e-04,\n       3.12762470e-04, 2.57311722e-04, 2.10934601e-04, 1.72298064e-04,\n       1.40235389e-04, 1.13731103e-04, 9.19061280e-05, 7.40034399e-05,\n       5.93744522e-05, 4.74662583e-05, 3.78098316e-05, 3.00092222e-05,\n       2.37317646e-05, 1.86992761e-05, 1.46802120e-05, 1.14827291e-05,\n       8.94859567e-06, 6.94788498e-06, 5.37438330e-06, 4.14164200e-06,\n       3.17960559e-06, 2.43174910e-06, 1.85266191e-06, 1.40601993e-06,\n       1.06289284e-06, 8.00338501e-07, 6.00242011e-07, 4.48361645e-07,\n       3.33548966e-07, 2.47114555e-07, 1.82314821e-07, 1.33938890e-07,\n       9.79777251e-08, 7.13604119e-08, 5.17449992e-08, 3.73534035e-08,\n       2.68417109e-08, 1.91987696e-08, 1.36672803e-08, 9.68268688e-09,\n       6.82608385e-09, 4.78810285e-09, 3.34135764e-09, 2.31952409e-09,\n       1.60153746e-09, 1.09971486e-09, 7.50872793e-10, 5.09717580e-10,\n       3.43951949e-10, 2.30670528e-10, 1.53718568e-10, 1.01766754e-10,\n       6.69156534e-11, 4.36897630e-11, 2.83165783e-11, 1.82129674e-11,\n       1.16214266e-11, 7.35403839e-12, 4.61334294e-12, 2.86779455e-12,\n       1.76571434e-12, 1.07622530e-12, 6.48980865e-13, 3.86900717e-13,\n       2.27849582e-13, 1.32422273e-13, 7.58672388e-14, 4.27928002e-14,\n       2.37286641e-14, 1.29133611e-14, 6.88420719e-15, 3.58758708e-15,\n       1.82330531e-15, 9.01308195e-16, 4.32060783e-16, 2.00168371e-16,\n       8.92736583e-17, 3.81541282e-17, 1.55414177e-17, 5.99394710e-18,\n       2.17103280e-18, 7.30871249e-19, 2.25584021e-19, 6.26585699e-20,\n       1.52513864e-20, 3.12466633e-21, 5.04310338e-22, 5.66696825e-23,\n       3.28854993e-24]), 11: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 9.42396665e-20, 1.50710589e-18,\n       1.33928556e-17, 9.36609836e-17, 5.60665815e-16, 2.93889856e-15,\n       1.38846680e-14, 6.02499524e-14, 2.42242710e-13, 9.10334187e-13,\n       3.22061373e-12, 1.07752195e-11, 3.42305257e-11, 1.03619756e-10,\n       2.99675454e-10, 8.29892326e-10, 2.20511958e-09, 5.63110907e-09,\n       1.38395209e-08, 3.27767058e-08, 7.48862603e-08, 1.65215358e-07,\n       3.52283917e-07, 7.26570469e-07, 1.45052961e-06, 2.80508104e-06,\n       5.25812919e-06, 9.56042703e-06, 1.68725107e-05, 2.89230295e-05,\n       4.81934418e-05, 7.81172832e-05, 1.23275071e-04, 1.89559679e-04,\n       2.84283253e-04, 4.16196774e-04, 5.95397532e-04, 8.33107416e-04,\n       1.14131544e-03, 1.53229078e-03, 2.01798730e-03, 2.60937477e-03,\n       3.31574388e-03, 4.14403820e-03, 5.09826661e-03, 6.17904292e-03,\n       7.38328666e-03, 8.70410317e-03, 1.01308432e-02, 1.16493273e-02,\n       1.32422082e-02, 1.48894418e-02, 1.65688330e-02, 1.82566314e-02,\n       1.99281534e-02, 2.15584147e-02, 2.31227614e-02, 2.45974855e-02,\n       2.59604125e-02, 2.71914428e-02, 2.82730294e-02, 2.91905721e-02,\n       2.99327108e-02, 3.04915090e-02, 3.08625206e-02, 3.10447452e-02,\n       3.10404822e-02, 3.08550980e-02, 3.04967263e-02, 2.99759196e-02,\n       2.93052686e-02, 2.84990056e-02, 2.75726034e-02, 2.65423799e-02,\n       2.54251171e-02, 2.42377003e-02, 2.29967863e-02, 2.17185045e-02,\n       2.04181972e-02, 1.91102028e-02, 1.78076838e-02, 1.65225009e-02,\n       1.52651304e-02, 1.40446237e-02, 1.28686027e-02, 1.17432882e-02,\n       1.06735534e-02, 9.66300042e-03, 8.71405177e-03, 7.82805490e-03,\n       7.00539420e-03, 6.24560759e-03, 5.54750440e-03, 4.90928169e-03,\n       4.32863665e-03, 3.80287298e-03, 3.32899958e-03, 2.90382053e-03,\n       2.52401530e-03, 2.18620910e-03, 1.88703318e-03, 1.62317544e-03,\n       1.39142183e-03, 1.18868915e-03, 1.01205013e-03, 8.58751431e-04,\n       7.26225523e-04, 6.12097152e-04, 5.14185281e-04, 4.30501191e-04,\n       3.59243512e-04, 2.98790810e-04, 2.47692356e-04, 2.04657597e-04,\n       1.68544806e-04, 1.38349297e-04, 1.13191540e-04, 9.23054277e-05,\n       7.50269101e-05, 6.07831472e-05, 4.90822873e-05, 3.95039498e-05,\n       3.16904528e-05, 2.53388034e-05, 2.01934495e-05, 1.60397715e-05,\n       1.26982857e-05, 1.00195157e-05, 7.87948854e-06, 6.17580181e-06,\n       4.82421284e-06, 3.75569647e-06, 2.91392181e-06, 2.25309999e-06,\n       1.73615821e-06, 1.33319846e-06, 1.02020324e-06, 7.77954185e-07,\n       5.91132883e-07, 4.47576844e-07, 3.37666795e-07, 2.53824416e-07,\n       1.90102525e-07, 1.41852183e-07, 1.05453497e-07, 7.80988920e-08,\n       5.76193925e-08, 4.23459853e-08, 3.09994699e-08, 2.26033215e-08,\n       1.64150620e-08, 1.18724429e-08, 8.55142715e-09, 6.13352614e-09,\n       4.38051786e-09, 3.11496363e-09, 2.20525833e-09, 1.55420903e-09,\n       1.09034779e-09, 7.61353081e-10, 5.29090387e-10, 3.65890383e-10,\n       2.51768520e-10, 1.72357519e-10, 1.17377095e-10, 7.95066109e-11,\n       5.35584993e-11, 3.58750759e-11, 2.38905083e-11, 1.58142701e-11,\n       1.04035306e-11, 6.80032697e-12, 4.41568790e-12, 2.84761029e-12,\n       1.82331599e-12, 1.15882820e-12, 7.30833585e-13, 4.57209951e-13,\n       2.83630526e-13, 1.74404303e-13, 1.06251788e-13, 6.41025005e-14,\n       3.82763324e-14, 2.26061146e-14, 1.31961236e-14, 7.60731424e-15,\n       4.32683127e-15, 2.42546633e-15, 1.33837906e-15, 7.25984507e-16,\n       3.86522047e-16, 2.01640104e-16, 1.02874442e-16, 5.12204661e-17,\n       2.48287226e-17, 1.16864548e-17, 5.32499926e-18, 2.34082459e-18,\n       9.88782662e-19, 3.99471735e-19, 1.53498494e-19, 5.57202504e-20,\n       1.89477603e-20, 5.97146916e-21, 1.71976774e-21, 4.44029727e-22,\n       1.00024211e-22, 1.88714544e-23, 2.79008690e-24, 2.85847837e-25,\n       1.50798106e-26]), 12: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.38533279e-21,\n       2.43619271e-20, 2.35894613e-19, 1.76572026e-18, 1.12316803e-17,\n       6.25346330e-17, 3.13190723e-16, 1.43834459e-15, 6.12010719e-15,\n       2.43370556e-14, 9.11038310e-14, 3.22653157e-13, 1.08559751e-12,\n       3.48257368e-12, 1.06820458e-11, 3.14023204e-11, 8.86599786e-11,\n       2.40828968e-10, 6.30310514e-10, 1.59162382e-09, 3.88209812e-09,\n       9.15528199e-09, 2.08953695e-08, 4.61907672e-08, 9.89707724e-08,\n       2.05683876e-07, 4.14868361e-07, 8.12638746e-07, 1.54672415e-06,\n       2.86221924e-06, 5.15244983e-06, 9.02807538e-06, 1.54064997e-05,\n       2.56216533e-05, 4.15512284e-05, 6.57547191e-05, 1.01611577e-04,\n       1.53445093e-04, 2.26614953e-04, 3.27560463e-04, 4.63777514e-04,\n       6.43715661e-04, 8.76587026e-04, 1.17208597e-03, 1.54002680e-03,\n       1.98991549e-03, 2.53047881e-03, 3.16918011e-03, 3.91175327e-03,\n       4.76178567e-03, 5.72037698e-03, 6.78589395e-03, 7.95383298e-03,\n       9.21679442e-03, 1.05645649e-02, 1.19842984e-02, 1.34607850e-02,\n       1.49767916e-02, 1.65134628e-02, 1.80507680e-02, 1.95679817e-02,\n       2.10441834e-02, 2.24587644e-02, 2.37919236e-02, 2.50251393e-02,\n       2.61415973e-02, 2.71265631e-02, 2.79676833e-02, 2.86552090e-02,\n       2.91821363e-02, 2.95442636e-02, 2.97401703e-02, 2.97711237e-02,\n       2.96409246e-02, 2.93557001e-02, 2.89236559e-02, 2.83547970e-02,\n       2.76606279e-02, 2.68538394e-02, 2.59479928e-02, 2.49572080e-02,\n       2.38958629e-02, 2.27783124e-02, 2.16186307e-02, 2.04303841e-02,\n       1.92264347e-02, 1.80187799e-02, 1.68184262e-02, 1.56352970e-02,\n       1.44781739e-02, 1.33546669e-02, 1.22712123e-02, 1.12330938e-02,\n       1.02444845e-02, 9.30850444e-03, 8.42729320e-03, 7.60209112e-03,\n       6.83332844e-03, 6.12071837e-03, 5.46335165e-03, 4.85979042e-03,\n       4.30815926e-03, 3.80623185e-03, 3.35151186e-03, 2.94130729e-03,\n       2.57279751e-03, 2.24309269e-03, 1.94928570e-03, 1.68849631e-03,\n       1.45790829e-03, 1.25479951e-03, 1.07656574e-03, 9.20738622e-04,\n       7.84998350e-04, 6.67181807e-04, 5.65286639e-04, 4.77471941e-04,\n       4.02056124e-04, 3.37512485e-04, 2.82462988e-04, 2.35670696e-04,\n       1.96031248e-04, 1.62563727e-04, 1.34401190e-04, 1.10781130e-04,\n       9.10360340e-05, 7.45842233e-05, 6.09210723e-05, 4.96107107e-05,\n       4.02782614e-05, 3.26026541e-05, 2.63100328e-05, 2.11677567e-05,\n       1.69789843e-05, 1.35778185e-05, 1.08249847e-05, 8.60400636e-06,\n       6.81784300e-06, 5.38595064e-06, 4.24172642e-06, 3.33029889e-06,\n       2.60662740e-06, 2.03387539e-06, 1.58202506e-06, 1.22670328e-06,\n       9.48191081e-07, 7.30591969e-07, 5.61136590e-07, 4.29604057e-07,\n       3.27842386e-07, 2.49372769e-07, 1.89064418e-07, 1.42868489e-07,\n       1.07601263e-07, 8.07681788e-08, 6.04216081e-08, 4.50463592e-08,\n       3.34678764e-08, 2.47789271e-08, 1.82812851e-08, 1.34395260e-08,\n       9.84456153e-09, 7.18497427e-09, 5.22457134e-09, 3.78487770e-09,\n       2.73153524e-09, 1.96377813e-09, 1.40632067e-09, 1.00312957e-09,\n       7.12661797e-10, 5.04237657e-10, 3.55289537e-10, 2.49283299e-10,\n       1.74154221e-10, 1.21134912e-10, 8.38805923e-11, 5.78190003e-11,\n       3.96692805e-11, 2.70874389e-11, 1.84061944e-11, 1.24449228e-11,\n       8.37142051e-12, 5.60180588e-12, 3.72836419e-12, 2.46777297e-12,\n       1.62412419e-12, 1.06263910e-12, 6.91073979e-13, 4.46631065e-13,\n       2.86791081e-13, 1.82925433e-13, 1.15868612e-13, 7.28657989e-14,\n       4.54800942e-14, 2.81657643e-14, 1.73011512e-14, 1.05370333e-14,\n       6.36021294e-15, 3.80308019e-15, 2.25158054e-15, 1.31910268e-15,\n       7.64238556e-16, 4.37545839e-16, 2.47347852e-16, 1.37938289e-16,\n       7.58067831e-17, 4.10091232e-17, 2.18096494e-17, 1.13867183e-17,\n       5.82706542e-18, 2.91775862e-18, 1.42679591e-18, 6.79921440e-19,\n       3.14994035e-19, 1.41489837e-19, 6.14331479e-20, 2.56930623e-20,\n       1.03086390e-20, 3.94896889e-21, 1.43608750e-21, 4.92345757e-22,\n       1.57758738e-22, 4.67266441e-23, 1.26100067e-23, 3.04056678e-24,\n       6.37215894e-25, 1.11377398e-25, 1.51892401e-26, 1.42993046e-27,\n       6.91492272e-29]), 13: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       2.03645346e-23, 3.90570597e-22, 4.09294802e-21, 3.26740445e-20,\n       2.20074672e-19, 1.29571862e-18, 6.85013138e-18, 3.31566122e-17,\n       1.48626729e-16, 6.22488543e-16, 2.45384124e-15, 9.15296298e-15,\n       3.24449552e-14, 1.09697901e-13, 3.54815931e-13, 1.10062213e-12,\n       3.28124141e-12, 9.41881741e-12, 2.60732187e-11, 6.96999620e-11,\n       1.80149972e-10, 4.50671453e-10, 1.09224603e-09, 2.56674200e-09,\n       5.85294670e-09, 1.29597498e-08, 2.78818987e-08, 5.83183065e-08,\n       1.18653677e-07, 2.34950274e-07, 4.53007292e-07, 8.50902255e-07,\n       1.55778731e-06, 2.78099578e-06, 4.84361230e-06, 8.23444563e-06,\n       1.36716896e-05, 2.21803794e-05, 3.51820383e-05, 5.45927577e-05,\n       8.29235760e-05, 1.23374718e-04, 1.79913394e-04, 2.57323791e-04,\n       3.61217882e-04, 4.97996955e-04, 6.74756318e-04, 8.99129427e-04,\n       1.17907232e-03, 1.52259436e-03, 1.93744620e-03, 2.43078004e-03,\n       3.00880023e-03, 3.67642340e-03, 4.43696678e-03, 5.29188161e-03,\n       6.24054484e-03, 7.28011857e-03, 8.40548272e-03, 9.60924245e-03,\n       1.08818089e-02, 1.22115492e-02, 1.35850004e-02, 1.49871398e-02,\n       1.64017037e-02, 1.78115450e-02, 1.91990187e-02, 2.05463834e-02,\n       2.18362064e-02, 2.30517574e-02, 2.41773804e-02, 2.51988289e-02,\n       2.61035564e-02, 2.68809530e-02, 2.75225237e-02, 2.80220057e-02,\n       2.83754254e-02, 2.85810969e-02, 2.86395665e-02, 2.85535082e-02,\n       2.83275772e-02, 2.79682269e-02, 2.74834975e-02, 2.68827832e-02,\n       2.61765847e-02, 2.53762548e-02, 2.44937443e-02, 2.35413532e-02,\n       2.25314954e-02, 2.14764786e-02, 2.03883069e-02, 1.92785061e-02,\n       1.81579752e-02, 1.70368643e-02, 1.59244796e-02, 1.48292141e-02,\n       1.37585028e-02, 1.27188014e-02, 1.17155851e-02, 1.07533666e-02,\n       9.83572956e-03, 8.96537577e-03, 8.14418283e-03, 7.37327025e-03,\n       6.65307123e-03, 5.98340796e-03, 5.36356835e-03, 4.79238239e-03,\n       4.26829659e-03, 3.78944521e-03, 3.35371724e-03, 2.95881844e-03,\n       2.60232781e-03, 2.28174828e-03, 1.99455137e-03, 1.73821588e-03,\n       1.51026076e-03, 1.30827242e-03, 1.12992673e-03, 9.73006219e-04,\n       8.35412848e-04, 7.15176828e-04, 6.10461977e-04, 5.19568078e-04,\n       4.40930698e-04, 3.73118896e-04, 3.14831237e-04, 2.64890461e-04,\n       2.22237151e-04, 1.85922688e-04, 1.55101754e-04, 1.29024586e-04,\n       1.07029181e-04, 8.85335907e-05, 7.30284279e-05, 6.00696842e-05,\n       4.92719185e-05, 4.03018702e-05, 3.28725265e-05, 2.67376575e-05,\n       2.16868220e-05, 1.75408381e-05, 1.41477010e-05, 1.13789303e-05,\n       9.12631847e-06, 7.29905568e-06, 5.82120022e-06, 4.62946488e-06,\n       3.67129011e-06, 2.90317479e-06, 2.28923723e-06, 1.79998035e-06,\n       1.41123691e-06, 1.10327243e-06, 8.60025616e-07, 6.68467821e-07,\n       5.18065235e-07, 4.00329085e-07, 3.08441005e-07, 2.36942219e-07,\n       1.81476689e-07, 1.38579672e-07, 1.05504331e-07, 8.00800664e-08,\n       6.05972291e-08, 4.57136211e-08, 3.43789641e-08, 2.57740992e-08,\n       1.92622241e-08, 1.43499271e-08, 1.06561612e-08, 7.88763062e-09,\n       5.81933376e-09, 4.27923792e-09, 3.13625162e-09, 2.29081884e-09,\n       1.66758995e-09, 1.20973136e-09, 8.74523210e-10, 6.29966057e-10,\n       4.52174510e-10, 3.23382730e-10, 2.30423640e-10, 1.63573609e-10,\n       1.15678006e-10, 8.14917832e-11, 5.71840769e-11, 3.99674147e-11,\n       2.78212422e-11, 1.92865588e-11, 1.33139603e-11, 9.15163534e-12,\n       6.26313499e-12, 4.26723955e-12, 2.89416167e-12, 1.95377701e-12,\n       1.31267441e-12, 8.77646204e-13, 5.83861729e-13, 3.86431923e-13,\n       2.54418840e-13, 1.66600288e-13, 1.08488839e-13, 7.02433363e-14,\n       4.52125195e-14, 2.89243051e-14, 1.83877597e-14, 1.16134358e-14,\n       7.28543963e-15, 4.53840352e-15, 2.80661707e-15, 1.72252901e-15,\n       1.04884869e-15, 6.33386867e-16, 3.79199511e-16, 2.24970184e-16,\n       1.32201848e-16, 7.69095869e-17, 4.42694345e-17, 2.51959161e-17,\n       1.41693488e-17, 7.86718814e-18, 4.30881262e-18, 2.32563469e-18,\n       1.23567436e-18, 6.45549862e-19, 3.31169953e-19, 1.66587416e-19,\n       8.20379532e-20, 3.94828675e-20, 1.85345609e-20, 8.46836776e-21,\n       3.75676043e-21, 1.61377338e-21, 6.69179758e-22, 2.66912316e-22,\n       1.01981446e-22, 3.71431235e-23, 1.28203130e-23, 4.16374487e-24,\n       1.26120113e-24, 3.52291636e-25, 8.94211806e-26, 2.02192077e-26,\n       3.96034426e-27, 6.44642384e-28, 8.15757445e-29, 7.10343593e-30,\n       3.17087248e-31]), 14: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 2.99360754e-25, 6.21841341e-24, 7.01183368e-23,\n       5.94989411e-22, 4.23058835e-21, 2.62435430e-20, 1.45935430e-19,\n       7.41866492e-19, 3.49030578e-18, 1.53373245e-17, 6.34160189e-17,\n       2.48109289e-16, 9.22616758e-16, 3.27314531e-15, 1.11125563e-14,\n       3.61981591e-14, 1.13382635e-13, 3.42151905e-13, 9.96355740e-13,\n       2.80385611e-12, 7.63464938e-12, 2.01370304e-11, 5.14994184e-11,\n       1.27817863e-10, 3.08109602e-10, 7.21858855e-10, 1.64480116e-09,\n       3.64707854e-09, 7.87379025e-09, 1.65595844e-08, 3.39428473e-08,\n       6.78384953e-08, 1.32257813e-07, 2.51632393e-07, 4.67403404e-07,\n       8.47962659e-07, 1.50314879e-06, 2.60466399e-06, 4.41382276e-06,\n       7.31790297e-06, 1.18759748e-05, 1.88743864e-05, 2.93910777e-05,\n       4.48666168e-05, 6.71784048e-05, 9.87130316e-05, 1.42430469e-04,\n       2.01912872e-04, 2.81390383e-04, 3.85736704e-04, 5.20428277e-04,\n       6.91462824e-04, 9.05235498e-04, 1.16837384e-03, 1.48753586e-03,\n       1.86917838e-03, 2.31930533e-03, 2.84320733e-03, 3.44520463e-03,\n       4.12840561e-03, 4.89449186e-03, 5.74353970e-03, 6.67388582e-03,\n       7.68204260e-03, 8.76266694e-03, 9.90858389e-03, 1.11108650e-02,\n       1.23589596e-02, 1.36408751e-02, 1.49434012e-02, 1.62523728e-02,\n       1.75529609e-02, 1.88299855e-02, 2.00682387e-02, 2.12528080e-02,\n       2.23693904e-02, 2.34045868e-02, 2.43461685e-02, 2.51833096e-02,\n       2.59067780e-02, 2.65090839e-02, 2.69845816e-02, 2.73295251e-02,\n       2.75420797e-02, 2.76222894e-02, 2.75720057e-02, 2.73947806e-02,\n       2.70957290e-02, 2.66813655e-02, 2.61594215e-02, 2.55386483e-02,\n       2.48286118e-02, 2.40394848e-02, 2.31818417e-02, 2.22664599e-02,\n       2.13041342e-02, 2.03055036e-02, 1.92808973e-02, 1.82401994e-02,\n       1.71927329e-02, 1.61471667e-02, 1.51114412e-02, 1.40927164e-02,\n       1.30973375e-02, 1.21308199e-02, 1.11978503e-02, 1.03023017e-02,\n       9.44726203e-03, 8.63507317e-03, 7.86737809e-03, 7.14517512e-03,\n       6.46887667e-03, 5.83837087e-03, 5.25308460e-03, 4.71204638e-03,\n       4.21394791e-03, 3.75720335e-03, 3.34000531e-03, 2.96037712e-03,\n       2.61622077e-03, 2.30536025e-03, 2.02558015e-03, 1.77465941e-03,\n       1.55040044e-03, 1.35065354e-03, 1.17333708e-03, 1.01645360e-03,\n       8.78102207e-04, 7.56487542e-04, 6.49925848e-04, 5.56848348e-04,\n       4.75802381e-04, 4.05450614e-04, 3.44568684e-04, 2.92041546e-04,\n       2.46858830e-04, 2.08109443e-04, 1.74975648e-04, 1.46726803e-04,\n       1.22712940e-04, 1.02358304e-04, 8.51549905e-05, 7.06567464e-05,\n       5.84730314e-05, 4.82633759e-05, 3.97320795e-05, 3.26232737e-05,\n       2.67163607e-05, 2.18218302e-05, 1.77774517e-05, 1.44448282e-05,\n       1.17062989e-05, 9.46217007e-06, 7.62825311e-06, 6.13368788e-06,\n       4.91902746e-06, 3.93456127e-06, 3.13885385e-06, 2.49747728e-06,\n       1.98191645e-06, 1.56862771e-06, 1.23823273e-06, 9.74831092e-07,\n       7.65416287e-07, 5.99381744e-07, 4.68104439e-07, 3.64595324e-07,\n       2.83206914e-07, 2.19389608e-07, 1.69489341e-07, 1.30580171e-07,\n       1.00326254e-07, 7.68684556e-08, 5.87315180e-08, 4.47483221e-08,\n       3.39983087e-08, 2.57575816e-08, 1.94586116e-08, 1.46578064e-08,\n       1.10094956e-08, 8.24513308e-09, 6.15672516e-09, 4.58366931e-09,\n       3.40233656e-09, 2.51785263e-09, 1.85763509e-09, 1.36632824e-09,\n       1.00184634e-09, 7.32293064e-10, 5.33570898e-10, 3.87532186e-10,\n       2.80553823e-10, 2.02442174e-10, 1.45594526e-10, 1.04359126e-10,\n       7.45484110e-11, 5.30700243e-11, 3.76480570e-11, 2.66131766e-11,\n       1.87451619e-11, 1.31551680e-11, 9.19800390e-12, 6.40700150e-12,\n       4.44583046e-12, 3.07297649e-12, 2.11565008e-12, 1.45069177e-12,\n       9.90649384e-13, 6.73664043e-13, 4.56150875e-13, 3.07522287e-13,\n       2.06398568e-13, 1.37897231e-13, 9.17017330e-14, 6.06910139e-14,\n       3.99709976e-14, 2.61929945e-14, 1.70760483e-14, 1.10736429e-14,\n       7.14215819e-15, 4.58073114e-15, 2.92100564e-15, 1.85158215e-15,\n       1.16649193e-15, 7.30226752e-16, 4.54122949e-16, 2.80494314e-16,\n       1.72027058e-16, 1.04729702e-16, 6.32720314e-17, 3.79209977e-17,\n       2.25381618e-17, 1.32787886e-17, 7.75200435e-18, 4.48209791e-18,\n       2.56528853e-18, 1.45255173e-18, 8.13195877e-19, 4.49807523e-19,\n       2.45638031e-19, 1.32323836e-19, 7.02513212e-20, 3.67203122e-20,\n       1.88761369e-20, 9.53121690e-21, 4.72101486e-21, 2.29056012e-21,\n       1.08685663e-21, 5.03455084e-22, 2.27226245e-22, 9.97058283e-23,\n       4.24314042e-23, 1.74647230e-23, 6.93071117e-24, 2.64217713e-24,\n       9.63561022e-25, 3.34473987e-25, 1.09853384e-25, 3.38896067e-26,\n       9.73171705e-27, 2.57152104e-27, 6.15975592e-28, 1.31087492e-28,\n       2.40954239e-29, 3.66928849e-30, 4.33068881e-31, 3.50787893e-32,\n       1.45401947e-33]), 15: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 4.40063388e-27, 9.84230522e-26,\n       1.18820814e-24, 1.06840872e-23, 7.99818888e-23, 5.21153410e-22,\n       3.03900125e-21, 1.61767174e-20, 7.96307097e-20, 3.65945216e-19,\n       1.58185640e-18, 6.46926910e-18, 2.51470582e-17, 9.32681765e-17,\n       3.31113519e-16, 1.12817152e-15, 3.69760479e-15, 1.16806112e-14,\n       3.56243476e-14, 1.05053151e-13, 2.99929020e-13, 8.29993749e-13,\n       2.22854946e-12, 5.81108890e-12, 1.47277385e-11, 3.63059944e-11,\n       8.71113126e-11, 2.03558291e-10, 4.63513829e-10, 1.02900804e-09,\n       2.22824649e-09, 4.70856604e-09, 9.71351537e-09, 1.95703635e-08,\n       3.85231233e-08, 7.41147589e-08, 1.39413829e-07, 2.56496155e-07,\n       4.61727520e-07, 8.13538707e-07, 1.40352065e-06, 2.37176753e-06,\n       3.92742342e-06, 6.37530347e-06, 1.01492256e-05, 1.58522737e-05,\n       2.43036119e-05, 3.65906917e-05, 5.41247975e-05, 7.86969242e-05,\n       1.12530092e-04, 1.58323476e-04, 2.19283284e-04, 2.99135278e-04,\n       4.02114198e-04, 5.32926232e-04, 6.96681979e-04, 8.98798983e-04,\n       1.14487481e-03, 1.44053354e-03, 1.79125036e-03, 2.20216048e-03,\n       2.67785970e-03, 3.22220465e-03, 3.83812087e-03, 4.52742668e-03,\n       5.29068010e-03, 6.12705521e-03, 7.03425316e-03, 8.00845190e-03,\n       9.04429720e-03, 1.01349363e-02, 1.12720944e-02, 1.24461915e-02,\n       1.36464983e-02, 1.48613255e-02, 1.60782414e-02, 1.72843121e-02,\n       1.84663558e-02, 1.96112047e-02, 2.07059659e-02, 2.17382742e-02,\n       2.26965297e-02, 2.35701139e-02, 2.43495792e-02, 2.50268074e-02,\n       2.55951352e-02, 2.60494434e-02, 2.63862103e-02, 2.66035296e-02,\n       2.67010927e-02, 2.66801396e-02, 2.65433801e-02, 2.62948883e-02,\n       2.59399759e-02, 2.54850476e-02, 2.49374431e-02, 2.43052707e-02,\n       2.35972369e-02, 2.28224758e-02, 2.19903822e-02, 2.11104526e-02,\n       2.01921355e-02, 1.92446947e-02, 1.82770872e-02, 1.72978559e-02,\n       1.63150398e-02, 1.53361003e-02, 1.43678642e-02, 1.34164838e-02,\n       1.24874113e-02, 1.15853884e-02, 1.07144489e-02, 9.87793230e-03,\n       9.07850848e-03, 8.31821010e-03, 7.59847229e-03, 6.92017745e-03,\n       6.28370408e-03, 5.68897792e-03, 5.13552431e-03, 4.62252064e-03,\n       4.14884786e-03, 3.71314022e-03, 3.31383256e-03, 2.94920465e-03,\n       2.61742209e-03, 2.31657360e-03, 2.04470440e-03, 1.79984578e-03,\n       1.58004073e-03, 1.38336583e-03, 1.20794956e-03, 1.05198718e-03,\n       9.13752484e-04, 7.91606674e-04, 6.84004655e-04, 5.89499025e-04,\n       5.06742063e-04, 4.34485990e-04, 3.71581782e-04, 3.16976783e-04,\n       2.69711354e-04, 2.28914771e-04, 1.93800564e-04, 1.63661479e-04,\n       1.37864183e-04, 1.15843876e-04, 9.70988781e-05, 8.11853147e-05,\n       6.77119432e-05, 5.63351921e-05, 4.67544477e-05, 3.87076187e-05,\n       3.19669978e-05, 2.63354294e-05, 2.16427865e-05, 1.77427533e-05,\n       1.45099044e-05, 1.18370696e-05, 9.63296909e-06, 7.82010219e-06,\n       6.33287267e-06, 5.11593129e-06, 4.12271776e-06, 3.31418371e-06,\n       2.65767901e-06, 2.12598467e-06, 1.69647648e-06, 1.35040461e-06,\n       1.07227539e-06, 8.49323065e-07, 6.71059764e-07, 5.28893837e-07,\n       4.15807123e-07, 3.26083108e-07, 2.55078726e-07, 1.99033460e-07,\n       1.54910184e-07, 1.20262912e-07, 9.31272793e-08, 7.19301382e-08,\n       5.54151738e-08, 4.25819065e-08, 3.26358243e-08, 2.49477479e-08,\n       1.90208216e-08, 1.44637849e-08, 1.09693945e-08, 8.29706166e-09,\n       6.25892220e-09, 4.70869568e-09, 3.53280312e-09, 2.64330654e-09,\n       1.97231406e-09, 1.46755987e-09, 1.08892298e-09, 8.05693798e-10,\n       5.94434362e-10, 4.37308455e-10, 3.20782379e-10, 2.34617222e-10,\n       1.71089600e-10, 1.24390933e-10, 9.01657782e-11, 6.51581226e-11,\n       4.69412375e-11, 3.37119867e-11, 2.41347075e-11, 1.72230856e-11,\n       1.22510619e-11, 8.68584800e-12, 6.13772606e-12, 4.32254765e-12,\n       3.03381041e-12, 2.12193395e-12, 1.47892961e-12, 1.02709774e-12,\n       7.10722382e-13, 4.89988996e-13, 3.36545451e-13, 2.30273433e-13,\n       1.56948414e-13, 1.06549599e-13, 7.20436558e-14, 4.85125701e-14,\n       3.25305384e-14, 2.17204374e-14, 1.44392998e-14, 9.55612234e-15,\n       6.29550690e-15, 4.12806095e-15, 2.69387958e-15, 1.74934046e-15,\n       1.13026136e-15, 7.26495128e-16, 4.64486470e-16, 2.95347460e-16,\n       1.86742075e-16, 1.17388122e-16, 7.33496986e-17, 4.55489478e-17,\n       2.81042361e-17, 1.72258087e-17, 1.04856553e-17, 6.33731630e-18,\n       3.80177071e-18, 2.26310248e-18, 1.33633806e-18, 7.82467061e-19,\n       4.54133433e-19, 2.61145985e-19, 1.48717971e-19, 8.38306191e-20,\n       4.67475783e-20, 2.57731849e-20, 1.40391242e-20, 7.55019737e-21,\n       4.00568797e-21, 2.09468628e-21, 1.07862940e-21, 5.46371646e-22,\n       2.71942742e-22, 1.32833174e-22, 6.35905288e-23, 2.97918106e-23,\n       1.36370044e-23, 6.08815427e-24, 2.64569659e-24, 1.11667439e-24,\n       4.56637911e-25, 1.80410222e-25, 6.86445109e-26, 2.50613105e-26,\n       8.74147953e-27, 2.89827076e-27, 9.07854219e-28, 2.66679095e-28,\n       7.27869991e-29, 1.82447229e-29, 4.13662275e-30, 8.31267578e-31,\n       1.43910718e-31, 2.05852169e-32, 2.27620243e-33, 1.72345229e-34,\n       6.66747916e-36]), 16: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.46897709e-29,\n       1.54990222e-27, 1.99457116e-26, 1.89506071e-25, 1.49005213e-24,\n       1.01716332e-23, 6.20355569e-23, 3.44883078e-22, 1.77155938e-21,\n       8.49078097e-21, 3.82633511e-20, 1.63102574e-19, 6.60770657e-19,\n       2.55425337e-18, 9.45197345e-18, 3.35752493e-17, 1.14755677e-16,\n       3.78150912e-16, 1.20351672e-15, 3.70509964e-15, 1.10482465e-14,\n       3.19484217e-14, 8.96866346e-14, 2.44646546e-13, 6.49010824e-13,\n       1.67570783e-12, 4.21384582e-12, 1.03268043e-11, 2.46779623e-11,\n       5.75356512e-11, 1.30936121e-10, 2.90985510e-10, 6.31762918e-10,\n       1.34053411e-09, 2.78101425e-09, 5.64264932e-09, 1.12011905e-08,\n       2.17614955e-08, 4.13900262e-08, 7.70942861e-08, 1.40671050e-07,\n       2.51524559e-07, 4.40847003e-07, 7.57649743e-07, 1.27722323e-06,\n       2.11266958e-06, 3.43017340e-06, 5.46862949e-06, 8.56410822e-06,\n       1.31793922e-05, 1.99384523e-05, 2.96652552e-05, 4.34257238e-05,\n       6.25710567e-05, 8.87799930e-05, 1.24097066e-04, 1.70963481e-04,\n       2.32237047e-04, 3.11197648e-04, 4.11535080e-04, 5.37316689e-04,\n       6.92933158e-04, 8.83021854e-04, 1.11236836e-03, 1.38578807e-03,\n       1.70799091e-03, 2.08343323e-03, 2.51616186e-03, 3.00965566e-03,\n       3.56667047e-03, 4.18909326e-03, 4.87781089e-03, 5.63259893e-03,\n       6.45203477e-03, 7.33343914e-03, 8.27284860e-03, 9.26502117e-03,\n       1.03034757e-02, 1.13805650e-02, 1.24875806e-02, 1.36148876e-02,\n       1.47520852e-02, 1.58881887e-02, 1.70118284e-02, 1.81114586e-02,\n       1.91755720e-02, 2.01929133e-02, 2.11526855e-02, 2.20447449e-02,\n       2.28597794e-02, 2.35894654e-02, 2.42266017e-02, 2.47652160e-02,\n       2.52006437e-02, 2.55295779e-02, 2.57500896e-02, 2.58616211e-02,\n       2.58649514e-02, 2.57621373e-02, 2.55564337e-02, 2.52521927e-02,\n       2.48547496e-02, 2.43702948e-02, 2.38057386e-02, 2.31685698e-02,\n       2.24667138e-02, 2.17083916e-02, 2.09019833e-02, 2.00558980e-02,\n       1.91784540e-02, 1.82777681e-02, 1.73616581e-02, 1.64375578e-02,\n       1.55124455e-02, 1.45927866e-02, 1.36844890e-02, 1.27928726e-02,\n       1.19226503e-02, 1.10779214e-02, 1.02621746e-02, 9.47830177e-03,\n       8.72861795e-03, 8.01488991e-03, 7.33836934e-03, 6.69983068e-03,\n       6.09961207e-03, 5.53765833e-03, 5.01356505e-03, 4.52662273e-03,\n       4.07586029e-03, 3.66008720e-03, 3.27793377e-03, 2.92788892e-03,\n       2.60833542e-03, 2.31758197e-03, 2.05389230e-03, 1.81551103e-03,\n       1.60068634e-03, 1.40768947e-03, 1.23483133e-03, 1.08047608e-03,\n       9.43052206e-04, 8.21060998e-04, 7.13082885e-04, 6.17781704e-04,\n       5.33907230e-04, 4.60296150e-04, 3.95871716e-04, 3.39642306e-04,\n       2.90699053e-04, 2.48212767e-04, 2.11430284e-04, 1.79670407e-04,\n       1.52319562e-04, 1.28827290e-04, 1.08701665e-04, 9.15047293e-05,\n       7.68480033e-05, 6.43881319e-05, 5.38227082e-05, 4.48863051e-05,\n       3.73467379e-05, 3.10015726e-05, 2.56748877e-05, 2.12142909e-05,\n       1.74881875e-05, 1.43832952e-05, 1.18023942e-05, 9.66230175e-06,\n       7.89205846e-06, 6.43131059e-06, 5.22887505e-06, 4.24147149e-06,\n       3.43260704e-06, 2.77159923e-06, 2.23272360e-06, 1.79447281e-06,\n       1.43891522e-06, 1.15114166e-06, 9.18789941e-07, 7.31637658e-07,\n       5.81254742e-07, 4.60707942e-07, 3.64310359e-07, 2.87409874e-07,\n       2.26210991e-07, 1.77625328e-07, 1.39146527e-07, 1.08745940e-07,\n       8.47859009e-08, 6.59478484e-08, 5.11729329e-08, 3.96130917e-08,\n       3.05908654e-08, 2.35664952e-08, 1.81110583e-08, 1.38846010e-08,\n       1.06183889e-08, 8.10054360e-09, 6.16445113e-09, 4.67943613e-09,\n       3.54327918e-09, 2.67623078e-09, 2.01623622e-09, 1.51513718e-09,\n       1.13565894e-09, 8.49027461e-10, 6.33090073e-10, 4.70837450e-10,\n       3.49244570e-10, 2.58364347e-10, 1.90620887e-10, 1.40259963e-10,\n       1.02922957e-10, 7.53174554e-11, 5.49633277e-11, 3.99975231e-11,\n       2.90244586e-11, 2.10016730e-11, 1.51526880e-11, 1.09007977e-11,\n       7.81890507e-12, 5.59162910e-12, 3.98676508e-12, 2.83385300e-12,\n       2.00813198e-12, 1.41856310e-12, 9.98916200e-13, 7.01156923e-13,\n       4.90555544e-13, 3.42080369e-13, 2.37746693e-13, 1.64674235e-13,\n       1.13668256e-13, 7.81864786e-14, 5.35893540e-14, 3.65977336e-14,\n       2.49018656e-14, 1.68804330e-14, 1.13993465e-14, 7.66814410e-15,\n       5.13786047e-15, 3.42864311e-15, 2.27863477e-15, 1.50800354e-15,\n       9.93724574e-16, 6.51965358e-16, 4.25828220e-16, 2.76853527e-16,\n       1.79152612e-16, 1.15372620e-16, 7.39324417e-17, 4.71371198e-17,\n       2.98969139e-17, 1.88608372e-17, 1.18331087e-17, 7.38189249e-18,\n       4.57815607e-18, 2.82218493e-18, 1.72887989e-18, 1.05228928e-18,\n       6.36203972e-19, 3.81980575e-19, 2.27695642e-19, 1.34714040e-19,\n       7.90828398e-20, 4.60488523e-20, 2.65868362e-20, 1.52144734e-20,\n       8.62593853e-21, 4.84301614e-21, 2.69134409e-21, 1.47955460e-21,\n       8.04165361e-22, 4.31851211e-22, 2.28978679e-22, 1.19784257e-22,\n       6.17720215e-23, 3.13750509e-23, 1.56804252e-23, 7.70293500e-24,\n       3.71521821e-24, 1.75712630e-24, 8.13811801e-25, 3.68556133e-25,\n       1.62942661e-25, 7.01999792e-26, 2.94133175e-26, 1.19588265e-26,\n       4.70633254e-27, 1.78769138e-27, 6.53291877e-28, 2.28821390e-28,\n       7.64815805e-29, 2.42681910e-29, 7.26509413e-30, 2.03650757e-30,\n       5.29548366e-31, 1.26228579e-31, 2.71628780e-32, 5.16951242e-33,\n       8.45651374e-34, 1.14032180e-34, 1.18598160e-35, 8.42984199e-37,\n       3.05740599e-38]), 17: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       9.50946288e-31, 2.42989092e-29, 3.32058753e-28, 3.32488995e-27,\n       2.73993616e-26, 1.95504111e-25, 1.24421038e-24, 7.20801230e-24,\n       3.85469914e-23, 1.92225333e-22, 9.00912533e-22, 3.99277684e-21,\n       1.68157578e-20, 6.75707852e-20, 2.59932709e-19, 9.59948372e-19,\n       3.41166326e-18, 1.16927614e-17, 3.87152529e-17, 1.24035164e-16,\n       3.85041232e-16, 1.15958341e-15, 3.39158835e-15, 9.64349765e-15,\n       2.66794531e-14, 7.18742448e-14, 1.88683647e-13, 4.82994211e-13,\n       1.20629481e-12, 2.94106223e-12, 7.00342308e-12, 1.62956350e-11,\n       3.70656547e-11, 8.24486257e-11, 1.79418549e-10, 3.82097990e-10,\n       7.96615832e-10, 1.62639664e-09, 3.25265895e-09, 6.37400001e-09,\n       1.22425225e-08, 2.30535015e-08, 4.25726612e-08, 7.71211135e-08,\n       1.37083700e-07, 2.39161553e-07, 4.09652095e-07, 6.89104942e-07,\n       1.13876310e-06, 1.84924502e-06, 2.95194200e-06, 4.63358206e-06,\n       7.15433264e-06, 1.08696667e-05, 1.62559948e-05, 2.39397691e-05,\n       3.47294020e-05, 4.96489363e-05, 6.99719786e-05, 9.72540072e-05,\n       1.33360825e-04, 1.80490696e-04, 2.41187602e-04, 3.18343159e-04,\n       4.15184949e-04, 5.35249510e-04, 6.82338793e-04, 8.60459640e-04,\n       1.07374663e-03, 1.32636952e-03, 1.62242718e-03, 1.96583097e-03,\n       2.36018066e-03, 2.80863696e-03, 3.31379479e-03, 3.87756151e-03,\n       4.50104455e-03, 5.18445260e-03, 5.92701407e-03, 6.72691622e-03,\n       7.58126777e-03, 8.48608690e-03, 9.43631598e-03, 1.04258634e-02,\n       1.14476720e-02, 1.24938127e-02, 1.35556011e-02, 1.46237345e-02,\n       1.56884450e-02, 1.67396654e-02, 1.77672034e-02, 1.87609191e-02,\n       1.97109017e-02, 2.06076408e-02, 2.14421888e-02, 2.22063089e-02,\n       2.28926081e-02, 2.34946500e-02, 2.40070471e-02, 2.44255297e-02,\n       2.47469921e-02, 2.49695145e-02, 2.50923625e-02, 2.51159636e-02,\n       2.50418640e-02, 2.48726658e-02, 2.46119489e-02, 2.42641787e-02,\n       2.38346021e-02, 2.33291367e-02, 2.27542537e-02, 2.21168580e-02,\n       2.14241693e-02, 2.06836042e-02, 1.99026640e-02, 1.90888283e-02,\n       1.82494565e-02, 1.73916988e-02, 1.65224176e-02, 1.56481191e-02,\n       1.47748967e-02, 1.39083853e-02, 1.30537273e-02, 1.22155481e-02,\n       1.13979430e-02, 1.06044730e-02, 9.83816903e-03, 9.10154358e-03,\n       8.39660960e-03, 7.72490437e-03, 7.08751820e-03, 6.48512659e-03,\n       5.91802505e-03, 5.38616563e-03, 4.88919432e-03, 4.42648860e-03,\n       3.99719453e-03, 3.60026271e-03, 3.23448278e-03, 2.89851596e-03,\n       2.59092538e-03, 2.31020402e-03, 2.05480004e-03, 1.82313949e-03,\n       1.61364638e-03, 1.42476012e-03, 1.25495042e-03, 1.10272977e-03,\n       9.66663616e-04, 8.45378493e-04, 7.37568124e-04, 6.41997824e-04,\n       5.57507327e-04, 4.83012234e-04, 4.17504274e-04, 3.60050546e-04,\n       3.09791922e-04, 2.65940750e-04, 2.27778013e-04, 1.94650069e-04,\n       1.65965083e-04, 1.41189264e-04, 1.19842980e-04, 1.01496840e-04,\n       8.57678045e-05, 7.23153664e-05, 6.08378598e-05, 5.10689172e-05,\n       4.27741060e-05, 3.57477591e-05, 2.98100123e-05, 2.48040525e-05,\n       2.05935791e-05, 1.70604747e-05, 1.41026822e-05, 1.16322771e-05,\n       9.57372830e-06, 7.86233555e-06, 6.44283184e-06, 5.26813915e-06,\n       4.29826537e-06, 3.49933025e-06, 2.84270886e-06, 2.30428108e-06,\n       1.86377665e-06, 1.50420558e-06, 1.21136455e-06, 9.73410743e-07,\n       7.80495015e-07, 6.24447343e-07, 4.98507861e-07, 3.97097684e-07,\n       3.15624241e-07, 2.50316421e-07, 1.98085418e-07, 1.56407606e-07,\n       1.23226264e-07, 9.68693619e-08, 7.59809758e-08, 5.94642467e-08,\n       4.64340738e-08, 3.61779932e-08, 2.81239173e-08, 2.18136057e-08,\n       1.68809110e-08, 1.30339893e-08, 1.00407925e-08, 7.71726958e-09,\n       5.91779750e-09, 4.52744074e-09, 3.45570758e-09, 2.63152688e-09,\n       1.99921780e-09, 1.51526477e-09, 1.14574368e-09, 8.64273337e-10,\n       6.50389323e-10, 4.88256489e-10, 3.65652388e-10, 2.73166696e-10,\n       2.03572419e-10, 1.51333337e-10, 1.12219184e-10, 8.30058082e-11,\n       6.12421572e-11, 4.50696858e-11, 3.30827604e-11, 2.42210450e-11,\n       1.76867633e-11, 1.28812574e-11, 9.35647467e-12, 6.77796974e-12,\n       4.89676530e-12, 3.52800921e-12, 2.53483052e-12, 1.81616176e-12,\n       1.29757843e-12, 9.24427424e-13, 6.56686736e-13, 4.65131185e-13,\n       3.28480410e-13, 2.31283537e-13, 1.62354754e-13, 1.13619669e-13,\n       7.92670609e-14, 5.51270196e-14, 3.82164072e-14, 2.64076083e-14,\n       1.81878610e-14, 1.24849308e-14, 8.54122810e-15, 5.82318961e-15,\n       3.95625002e-15, 2.67832587e-15, 1.80664810e-15, 1.21418981e-15,\n       8.12968290e-16, 5.42256096e-16, 3.60286091e-16, 2.38434816e-16,\n       1.57157920e-16, 1.03159902e-16, 6.74303517e-17, 4.38863710e-17,\n       2.84375048e-17, 1.83441043e-17, 1.17787178e-17, 7.52743065e-18,\n       4.78730163e-18, 3.02952980e-18, 1.90740125e-18, 1.19462032e-18,\n       7.44172621e-19, 4.61003734e-19, 2.83954604e-19, 1.73871837e-19,\n       1.05818734e-19, 6.39971420e-20, 3.84529001e-20, 2.29491961e-20,\n       1.36009120e-20, 8.00230985e-21, 4.67289078e-21, 2.70735811e-21,\n       1.55579465e-21, 8.86443068e-22, 5.00581383e-22, 2.80055229e-22,\n       1.55154042e-22, 8.50789862e-23, 4.61523150e-23, 2.47531338e-23,\n       1.31179464e-23, 6.86455315e-24, 3.54452395e-24, 1.80453825e-24,\n       9.05050733e-25, 4.46771041e-25, 2.16858658e-25, 1.03392062e-25,\n       4.83633253e-26, 2.21676535e-26, 9.94270767e-27, 4.35734176e-27,\n       1.86275924e-27, 7.75391995e-28, 3.13645554e-28, 1.23007167e-28,\n       4.66543157e-29, 1.70636178e-29, 5.99838975e-30, 2.01894987e-30,\n       6.47751072e-31, 1.97058331e-31, 5.64866230e-32, 1.51401263e-32,\n       3.75860006e-33, 8.53954288e-34, 1.74835083e-34, 3.15966827e-35,\n       4.89827288e-36, 6.24664191e-37, 6.13215684e-38, 4.10714294e-39,\n       1.40198884e-40]), 18: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 1.39790083e-32, 3.79469872e-31, 5.48795578e-30,\n       5.77713609e-29, 4.97970796e-28, 3.70657549e-27, 2.45652040e-26,\n       1.48001784e-25, 8.22347688e-25, 4.25801669e-24, 2.07111394e-23,\n       9.52310419e-23, 4.16020561e-22, 1.73382549e-21, 6.91740158e-21,\n       2.64961976e-20, 9.76784329e-20, 3.47305548e-19, 1.19322961e-18,\n       3.96768180e-18, 1.27869805e-17, 3.99912294e-17, 1.21510677e-16,\n       3.59048573e-16, 1.03269708e-15, 2.89352507e-15, 7.90380621e-15,\n       2.10615822e-14, 5.47843633e-14, 1.39179663e-13, 3.45518355e-13,\n       8.38586048e-13, 1.99064902e-12, 4.62368158e-12, 1.05121313e-11,\n       2.34021682e-11, 5.10302152e-11, 1.09028532e-10, 2.28308974e-10,\n       4.68703964e-10, 9.43593806e-10, 1.86335880e-09, 3.61030635e-09,\n       6.86494249e-09, 1.28139458e-08, 2.34849331e-08, 4.22730679e-08,\n       7.47505823e-08, 1.29882785e-07, 2.21812801e-07, 3.72420744e-07,\n       6.14908399e-07, 9.98703266e-07, 1.59600962e-06, 2.51035112e-06,\n       3.88744071e-06, 5.92866929e-06, 8.90741804e-06, 1.31882636e-05,\n       1.92489593e-05, 2.77048445e-05, 3.93350629e-05, 5.51096821e-05,\n       7.62165137e-05, 1.04086166e-04, 1.40413647e-04, 1.87174686e-04,\n       2.46634921e-04, 3.21350127e-04, 4.14155910e-04, 5.28145529e-04,\n       6.66634986e-04, 8.33114966e-04, 1.03118981e-03, 1.26450425e-03,\n       1.53665924e-03, 1.85111877e-03, 2.21110998e-03, 2.61951943e-03,\n       3.07878847e-03, 3.59081119e-03, 4.15683802e-03, 4.77738861e-03,\n       5.45217682e-03, 6.18005099e-03, 6.95895167e-03, 7.78588901e-03,\n       8.65694106e-03, 9.56727385e-03, 1.05111833e-02, 1.14821584e-02,\n       1.24729645e-02, 1.34757444e-02, 1.44821359e-02, 1.54834018e-02,\n       1.64705697e-02, 1.74345782e-02, 1.83664261e-02, 1.92573200e-02,\n       2.00988185e-02, 2.08829681e-02, 2.16024291e-02, 2.22505876e-02,\n       2.28216526e-02, 2.33107357e-02, 2.37139120e-02, 2.40282626e-02,\n       2.42518970e-02, 2.43839562e-02, 2.44245984e-02, 2.43749660e-02,\n       2.42371376e-02, 2.40140654e-02, 2.37095013e-02, 2.33279118e-02,\n       2.28743863e-02, 2.23545393e-02, 2.17744095e-02, 2.11403583e-02,\n       2.04589684e-02, 1.97369463e-02, 1.89810281e-02, 1.81978921e-02,\n       1.73940782e-02, 1.65759149e-02, 1.57494557e-02, 1.49204242e-02,\n       1.40941685e-02, 1.32756252e-02, 1.24692924e-02, 1.16792116e-02,\n       1.09089577e-02, 1.01616373e-02, 9.43989302e-03, 8.74591506e-03,\n       8.08145729e-03, 7.44785854e-03, 6.84606727e-03, 6.27666935e-03,\n       5.73991792e-03, 5.23576468e-03, 4.76389198e-03, 4.32374500e-03,\n       3.91456359e-03, 3.53541325e-03, 3.18521483e-03, 2.86277271e-03,\n       2.56680115e-03, 2.29594859e-03, 2.04881991e-03, 1.82399637e-03,\n       1.62005348e-03, 1.43557646e-03, 1.26917376e-03, 1.11948835e-03,\n       9.85207182e-04, 8.65068692e-04, 7.57868750e-04, 6.62464988e-04,\n       5.77779780e-04, 5.02801997e-04, 4.36587680e-04, 3.78259800e-04,\n       3.27007234e-04, 2.82083084e-04, 2.42802483e-04, 2.08539978e-04,\n       1.78726602e-04, 1.52846729e-04, 1.30434782e-04, 1.11071870e-04,\n       9.43824164e-05, 8.00308119e-05, 6.77181547e-05, 5.71790931e-05,\n       4.81788042e-05, 4.05101250e-05, 3.39908506e-05, 2.84612058e-05,\n       2.37814957e-05, 1.98299354e-05, 1.65006564e-05, 1.37018852e-05,\n       1.13542870e-05, 9.38946775e-06, 7.74862507e-06, 6.38133805e-06,\n       5.24448717e-06, 4.30129357e-06, 3.52046803e-06, 2.87546009e-06,\n       2.34379773e-06, 1.90650899e-06, 1.54761705e-06, 1.25370083e-06,\n       1.01351412e-06, 8.17656245e-07, 6.58288464e-07, 5.28890288e-07,\n       4.24050916e-07, 3.39291169e-07, 2.70911966e-07, 2.15865735e-07,\n       1.71647627e-07, 1.36203733e-07, 1.07853873e-07, 8.52268178e-08,\n       6.72061067e-08, 5.28848325e-08, 4.15280289e-08, 3.25414578e-08,\n       2.54457797e-08, 1.98552344e-08, 1.54600909e-08, 1.20122390e-08,\n       9.31338911e-09, 7.20543513e-09, 5.56260233e-09, 4.28506729e-09,\n       3.29378645e-09, 2.52631532e-09, 1.93343683e-09, 1.47644934e-09,\n       1.12499057e-09, 8.55295989e-10, 6.48808428e-10, 4.91070786e-10,\n       3.70846483e-10, 2.79422491e-10, 2.10058452e-10, 1.57552329e-10,\n       1.17898807e-10, 8.80212896e-11, 6.55621781e-11, 4.87191504e-11,\n       3.61176795e-11, 2.67120143e-11, 1.97084608e-11, 1.45060907e-11,\n       1.06510334e-11, 7.80132836e-12, 5.69996667e-12, 4.15426508e-12,\n       3.02012624e-12, 2.19005760e-12, 1.58407499e-12, 1.14281401e-12,\n       8.22326905e-13, 5.90162607e-13, 4.22421350e-13, 3.01547229e-13,\n       2.14678248e-13, 1.52416307e-13, 1.07912692e-13, 7.61899806e-14,\n       5.36405819e-14, 3.76569295e-14, 2.63594971e-14, 1.83973193e-14,\n       1.28020940e-14, 8.88177424e-15, 6.14318031e-15, 4.23587853e-15,\n       2.91159933e-15, 1.99497763e-15, 1.36251849e-15, 9.27520582e-16,\n       6.29302473e-16, 4.25526978e-16, 2.86749468e-16, 1.92557781e-16,\n       1.28847636e-16, 8.59056323e-17, 5.70647996e-17, 3.77647693e-17,\n       2.48969602e-17, 1.63498739e-17, 1.06944197e-17, 6.96689557e-18,\n       4.51984427e-18, 2.91991862e-18, 1.87819296e-18, 1.20278740e-18,\n       7.66781344e-19, 4.86564775e-19, 3.07288404e-19, 1.93123567e-19,\n       1.20768112e-19, 7.51343193e-20, 4.64976852e-20, 2.86197217e-20,\n       1.75174496e-20, 1.06604081e-20, 6.44905098e-21, 3.87751458e-21,\n       2.31663711e-21, 1.37503902e-21, 8.10631901e-22, 4.74543886e-22,\n       2.75776974e-22, 1.59054265e-22, 9.10135866e-23, 5.16534053e-23,\n       2.90650581e-23, 1.62091101e-23, 8.95543496e-24, 4.89963871e-24,\n       2.65330424e-24, 1.42146355e-24, 7.52962300e-25, 3.94134569e-25,\n       2.03739403e-25, 1.03936747e-25, 5.22887820e-26, 2.59209244e-26,\n       1.26510238e-26, 6.07345439e-27, 2.86517180e-27, 1.32679875e-27,\n       6.02413146e-28, 2.67836838e-28, 1.16448597e-28, 4.94345859e-29,\n       2.04568691e-29, 8.23685974e-30, 3.22041303e-30, 1.21982151e-30,\n       4.46474920e-31, 1.57450224e-31, 5.33187024e-32, 1.72712367e-32,\n       5.32733137e-33, 1.55638364e-33, 4.27923127e-34, 1.09870942e-34,\n       2.60915945e-35, 5.66198570e-36, 1.10538008e-36, 1.90159795e-37,\n       2.80110439e-38, 3.38808001e-39, 3.14915798e-40, 1.99413634e-41,\n       6.42889012e-43]), 19: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 2.05492860e-34, 5.90566752e-33,\n       9.01131445e-32, 9.95092543e-31, 8.95563376e-30, 6.94128025e-29,\n       4.78206788e-28, 2.99100465e-27, 1.72362654e-26, 9.24990675e-26,\n       4.66076197e-25, 2.21919981e-24, 1.00367157e-23, 4.32986966e-23,\n       1.78801660e-22, 7.08869701e-22, 2.70492453e-21, 9.95593355e-21,\n       3.54133452e-20, 1.21934854e-19, 4.07002819e-19, 1.31867088e-18,\n       4.15187821e-18, 1.27165561e-17, 3.79239508e-17, 1.10214851e-16,\n       3.12376511e-16, 8.64027672e-16, 2.33378564e-15, 6.15925323e-15,\n       1.58912515e-14, 4.01016243e-14, 9.90225873e-14, 2.39361983e-13,\n       5.66620088e-13, 1.31401554e-12, 2.98625224e-12, 6.65283390e-12,\n       1.45334911e-11, 3.11414116e-11, 6.54678025e-11, 1.35067026e-10,\n       2.73533005e-10, 5.43891420e-10, 1.06208005e-09, 2.03724525e-09,\n       3.83943621e-09, 7.11092291e-09, 1.29453849e-08, 2.31702611e-08,\n       4.07822512e-08, 7.06048367e-08, 1.20259978e-07, 2.01573625e-07,\n       3.32565441e-07, 5.40205349e-07, 8.64150345e-07, 1.36170050e-06,\n       2.11422818e-06, 3.23533356e-06, 4.88095668e-06, 7.26162553e-06,\n       1.06569379e-05, 1.54322581e-05, 2.20574603e-05, 3.11273733e-05,\n       4.33833794e-05, 5.97354148e-05, 8.12834133e-05, 1.09337052e-04,\n       1.45432519e-04, 1.91344918e-04, 2.49094936e-04, 3.20948402e-04,\n       4.09407559e-04, 5.17193036e-04, 6.47215824e-04, 8.02538899e-04,\n       9.86328524e-04, 1.20179568e-03, 1.45212853e-03, 1.74041719e-03,\n       2.06957248e-03, 2.44224076e-03, 2.86071698e-03, 3.32685866e-03,\n       3.84200315e-03, 4.40689109e-03, 5.02159836e-03, 5.68547920e-03,\n       6.39712234e-03, 7.15432230e-03, 7.95406702e-03, 8.79254286e-03,\n       9.66515750e-03, 1.05665805e-02, 1.14908011e-02, 1.24312023e-02,\n       1.33806488e-02, 1.43315886e-02, 1.52761640e-02, 1.62063308e-02,\n       1.71139819e-02, 1.79910740e-02, 1.88297525e-02, 1.96224738e-02,\n       2.03621203e-02, 2.10421079e-02, 2.16564820e-02, 2.22000013e-02,\n       2.26682068e-02, 2.30574766e-02, 2.33650642e-02, 2.35891207e-02,\n       2.37287015e-02, 2.37837567e-02, 2.37551077e-02, 2.36444091e-02,\n       2.34540996e-02, 2.31873412e-02, 2.28479502e-02, 2.24403200e-02,\n       2.19693399e-02, 2.14403093e-02, 2.08588506e-02, 2.02308223e-02,\n       1.95622333e-02, 1.88591606e-02, 1.81276707e-02, 1.73737474e-02,\n       1.66032246e-02, 1.58217271e-02, 1.50346183e-02, 1.42469560e-02,\n       1.34634554e-02, 1.26884608e-02, 1.19259243e-02, 1.11793921e-02,\n       1.04519975e-02, 9.74646054e-03, 9.06509301e-03, 8.40980897e-03,\n       7.78213946e-03, 7.18325113e-03, 6.61396785e-03, 6.07479483e-03,\n       5.56594452e-03, 5.08736362e-03, 4.63876080e-03, 4.21963457e-03,\n       3.82930074e-03, 3.46691929e-03, 3.13152017e-03, 2.82202775e-03,\n       2.53728389e-03, 2.27606917e-03, 2.03712249e-03, 1.81915869e-03,\n       1.62088439e-03, 1.44101186e-03, 1.27827114e-03, 1.13142036e-03,\n       9.99254326e-04, 8.80611633e-04, 7.74380200e-04, 6.79501526e-04,\n       5.94973700e-04, 5.19853333e-04, 4.53256519e-04, 3.94358968e-04,\n       3.42395409e-04, 2.96658404e-04, 2.56496653e-04, 2.21312903e-04,\n       1.90561550e-04, 1.63746000e-04, 1.40415887e-04, 1.20164177e-04,\n       1.02624246e-04, 8.74669453e-05, 7.43977270e-05, 6.31538272e-05,\n       5.35015580e-05, 4.52337145e-05, 3.81671159e-05, 3.21402891e-05,\n       2.70113018e-05, 2.26557471e-05, 1.89648809e-05, 1.58439078e-05,\n       1.32104144e-05, 1.09929409e-05, 9.12968759e-06, 7.56734722e-06,\n       6.26005515e-06, 5.16845013e-06, 4.25883668e-06, 3.50244097e-06,\n       2.87475235e-06, 2.35494248e-06, 1.92535490e-06, 1.57105783e-06,\n       1.27945374e-06, 1.03993953e-06, 8.43611715e-07, 6.83011414e-07,\n       5.51904431e-07, 4.45092182e-07, 3.58249602e-07, 2.87786567e-07,\n       2.30729778e-07, 1.84622349e-07, 1.47438684e-07, 1.17512511e-07,\n       9.34762075e-08, 7.42097714e-08, 5.87980245e-08, 4.64948112e-08,\n       3.66931269e-08, 2.89002556e-08, 2.27171319e-08, 1.78212506e-08,\n       1.39525505e-08, 1.09017830e-08, 8.50095280e-09, 6.61547944e-09,\n       5.13778668e-09, 3.98207177e-09, 3.08004797e-09, 2.37748748e-09,\n       1.83142102e-09, 1.40787483e-09, 1.08004623e-09, 8.26836238e-10,\n       6.31672219e-10, 4.81565400e-10, 3.66358229e-10, 2.78124723e-10,\n       2.10693841e-10, 1.59271530e-10, 1.20141715e-10, 9.04303031e-11,\n       6.79193584e-11, 5.09011218e-11, 3.80636032e-11, 2.84011279e-11,\n       2.11445580e-11, 1.57069894e-11, 1.16415920e-11, 8.60895525e-12,\n       6.35185407e-12, 4.67579726e-12, 3.43406735e-12, 2.51624287e-12,\n       1.83941323e-12, 1.34147068e-12, 9.76000540e-13, 7.08398312e-13,\n       5.12926185e-13, 3.70487135e-13, 2.66945750e-13, 1.91864624e-13,\n       1.37555795e-13, 9.83704581e-14, 7.01684208e-14, 4.99228001e-14,\n       3.54262382e-14, 2.50731131e-14, 1.76984992e-14, 1.24593965e-14,\n       8.74735851e-15, 6.12438836e-15, 4.27602692e-15, 2.97711485e-15,\n       2.06687024e-15, 1.43079617e-15, 9.87581989e-16, 6.79645886e-16,\n       4.66325370e-16, 3.18987924e-16, 2.17530236e-16, 1.47878772e-16,\n       1.00210385e-16, 6.76892023e-17, 4.55726289e-17, 3.05804707e-17,\n       2.04510732e-17, 1.36299850e-17, 9.05224835e-18, 5.99063324e-18,\n       3.95017595e-18, 2.59512708e-18, 1.69851374e-18, 1.10742971e-18,\n       7.19228572e-19, 4.65250478e-19, 2.99736563e-19, 1.92303758e-19,\n       1.22854568e-19, 7.81463565e-20, 4.94875986e-20, 3.11966798e-20,\n       1.95747621e-20, 1.22239057e-20, 7.59618312e-21, 4.69673951e-21,\n       2.88904102e-21, 1.76768298e-21, 1.07567769e-21, 6.50903922e-22,\n       3.91592398e-22, 2.34183064e-22, 1.39186463e-22, 8.21996562e-23,\n       4.82258697e-23, 2.81013172e-23, 1.62593317e-23, 9.33885873e-24,\n       5.32326323e-24, 3.01040267e-24, 1.68847295e-24, 9.38938098e-25,\n       5.17479247e-25, 2.82546731e-25, 1.52772377e-25, 8.17634196e-26,\n       4.32933328e-26, 2.26674909e-26, 1.17290410e-26, 5.99427429e-27,\n       3.02374485e-27, 1.50448182e-27, 7.37800096e-28, 3.56330570e-28,\n       1.69338814e-28, 7.91127934e-29, 3.62985857e-29, 1.63386522e-29,\n       7.20638733e-30, 3.11057452e-30, 1.31214385e-30, 5.40105196e-31,\n       2.16572182e-31, 8.44399428e-32, 3.19459971e-32, 1.17004548e-32,\n       4.13783189e-33, 1.40876405e-33, 4.60174823e-34, 1.43654799e-34,\n       4.26616371e-35, 1.19873235e-35, 3.16636598e-36, 7.80085192e-37,\n       1.77524006e-37, 3.68649971e-38, 6.87697503e-39, 1.12865716e-39,\n       1.58353019e-40, 1.82139354e-41, 1.60745346e-42, 9.65222392e-44,\n       2.94799979e-45]), 20: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.02076618e-36,\n       9.16270478e-35, 1.47110501e-33, 1.70059544e-32, 1.59532681e-31,\n       1.28547716e-30, 9.19113239e-30, 5.95847198e-29, 3.55554680e-28,\n       1.97442902e-27, 1.02890013e-26, 5.06471457e-26, 2.36740161e-25,\n       1.05534611e-24, 4.50278346e-24, 1.84434544e-23, 7.27105366e-23,\n       2.76509753e-22, 1.01629377e-21, 3.61624010e-21, 1.24758787e-20,\n       4.17863512e-20, 1.36037467e-19, 4.30924884e-19, 1.32946173e-18,\n       3.99810119e-18, 1.17293272e-17, 3.35923981e-17, 9.39805218e-17,\n       2.56992361e-16, 6.87263987e-16, 1.79831050e-15, 4.60620695e-15,\n       1.15543327e-14, 2.83949118e-14, 6.83895899e-14, 1.61488701e-13,\n       3.73969518e-13, 8.49577268e-13, 1.89393583e-12, 4.14419028e-12,\n       8.90300448e-12, 1.87828391e-11, 3.89237286e-11, 7.92488948e-11,\n       1.58559204e-10, 3.11817507e-10, 6.02850595e-10, 1.14605903e-09,\n       2.14278891e-09, 3.94106412e-09, 7.13174725e-09, 1.27002949e-08,\n       2.22615312e-08, 3.84157027e-08, 6.52778355e-08, 1.09249241e-07,\n       1.80119770e-07, 2.92611496e-07, 4.68497819e-07, 7.39454631e-07,\n       1.15081978e-06, 1.76645034e-06, 2.67487045e-06, 3.99689194e-06,\n       5.89486151e-06, 8.58363895e-06, 1.23433385e-05, 1.75337698e-05,\n       2.46103961e-05, 3.41414932e-05, 4.68260419e-05, 6.35117385e-05,\n       8.52123587e-05, 1.13123586e-04, 1.48636314e-04, 1.93346365e-04,\n       2.49059577e-04, 3.17791206e-04, 4.01758737e-04, 5.03367310e-04,\n       6.25187192e-04, 7.69922959e-04, 9.40374352e-04, 1.13938907e-03,\n       1.36980810e-03, 1.63440444e-03, 1.93581651e-03, 2.27647767e-03,\n       2.65854357e-03, 3.08381931e-03, 3.55368838e-03, 4.06904547e-03,\n       4.63023529e-03, 5.23699942e-03, 5.88843292e-03, 6.58295248e-03,\n       7.31827732e-03, 8.09142402e-03, 8.89871576e-03, 9.73580631e-03,\n       1.05977186e-02, 1.14788974e-02, 1.23732750e-02, 1.32743484e-02,\n       1.41752674e-02, 1.50689304e-02, 1.59480862e-02, 1.68054404e-02,\n       1.76337632e-02, 1.84259962e-02, 1.91753566e-02, 1.98754366e-02,\n       2.05202947e-02, 2.11045393e-02, 2.16234008e-02, 2.20727930e-02,\n       2.24493615e-02, 2.27505183e-02, 2.29744645e-02, 2.31201974e-02,\n       2.31875069e-02, 2.31769568e-02, 2.30898566e-02, 2.29282213e-02,\n       2.26947222e-02, 2.23926298e-02, 2.20257496e-02, 2.15983532e-02,\n       2.11151056e-02, 2.05809906e-02, 2.00012353e-02, 1.93812352e-02,\n       1.87264820e-02, 1.80424931e-02, 1.73347466e-02, 1.66086206e-02,\n       1.58693372e-02, 1.51219145e-02, 1.43711228e-02, 1.36214492e-02,\n       1.28770677e-02, 1.21418165e-02, 1.14191815e-02, 1.07122860e-02,\n       1.00238858e-02, 9.35637032e-03, 8.71176746e-03, 8.09175379e-03,\n       7.49766775e-03, 6.93052620e-03, 6.39104350e-03, 5.87965264e-03,\n       5.39652781e-03, 4.94160798e-03, 4.51462102e-03, 4.11510787e-03,\n       3.74244657e-03, 3.39587558e-03, 3.07451635e-03, 2.77739470e-03,\n       2.50346100e-03, 2.25160895e-03, 2.02069277e-03, 1.80954288e-03,\n       1.61697997e-03, 1.44182745e-03, 1.28292235e-03, 1.13912464e-03,\n       1.00932522e-03, 8.92452350e-04, 7.87476971e-04, 6.93416735e-04,\n       6.09338998e-04, 5.34362836e-04, 4.67660194e-04, 4.08456282e-04,\n       3.56029313e-04, 3.09709685e-04, 2.68878692e-04, 2.32966856e-04,\n       2.01451960e-04, 1.73856844e-04, 1.49747031e-04, 1.28728251e-04,\n       1.10443889e-04, 9.45724255e-05, 8.08248870e-05, 6.89423421e-05,\n       5.86934725e-05, 4.98722320e-05, 4.22956116e-05, 3.58015213e-05,\n       3.02467962e-05, 2.55053306e-05, 2.14663429e-05, 1.80327697e-05,\n       1.51197888e-05, 1.26534649e-05, 1.05695159e-05, 8.81219220e-06,\n       7.33326364e-06, 6.09110734e-06, 5.04988943e-06, 4.17883377e-06,\n       3.45157081e-06, 2.84555968e-06, 2.34157727e-06, 1.92326770e-06,\n       1.57674660e-06, 1.29025445e-06, 1.05385392e-06, 8.59166299e-07,\n       6.99142852e-07, 5.67866803e-07, 4.60382512e-07, 3.72548440e-07,\n       3.00910950e-07, 2.42596300e-07, 1.95218433e-07, 1.56800477e-07,\n       1.25708076e-07, 1.00592933e-07, 8.03451011e-08, 6.40527859e-08,\n       5.09685515e-08, 4.04809840e-08, 3.20909880e-08, 2.53920072e-08,\n       2.00535585e-08, 1.58075584e-08, 1.24369939e-08, 9.76655901e-09,\n       7.65493326e-09, 5.98842964e-09, 4.67578071e-09, 3.64386923e-09,\n       2.83423988e-09, 2.20025593e-09, 1.70478672e-09, 1.31833122e-09,\n       1.01749879e-09, 7.83781994e-10, 6.02567481e-10, 4.62340582e-10,\n       3.54047083e-10, 2.70582274e-10, 2.06382793e-10, 1.57101316e-10,\n       1.19347847e-10, 9.04844359e-11, 6.84626431e-11, 5.16951424e-11,\n       3.89545122e-11, 2.92936357e-11, 2.19832354e-11, 1.64629620e-11,\n       1.23031807e-11, 9.17518367e-12, 6.82801967e-12, 5.07051319e-12,\n       3.75734064e-12, 2.77827276e-12, 2.04988179e-12, 1.50916302e-12,\n       1.10863979e-12, 8.12615505e-13, 5.94310268e-13, 4.33678389e-13,\n       3.15748613e-13, 2.29364773e-13, 1.66232451e-13, 1.20198959e-13,\n       8.67107893e-14, 6.24057437e-14, 4.48070306e-14, 3.20943690e-14,\n       2.29331231e-14, 1.63470560e-14, 1.16237930e-14, 8.24475622e-15,\n       5.83335921e-15, 4.11679785e-15, 2.89793663e-15, 2.03467463e-15,\n       1.42483845e-15, 9.95149362e-16, 6.93186168e-16, 4.81545165e-16,\n       3.33607469e-16, 2.30479180e-16, 1.58785164e-16, 1.09082478e-16,\n       7.47224217e-17, 5.10365361e-17, 3.47559041e-17, 2.35980083e-17,\n       1.59736079e-17, 1.07793472e-17, 7.25143259e-18, 4.86268857e-18,\n       3.25034133e-18, 2.16550454e-18, 1.43794974e-18, 9.51609415e-19,\n       6.27594502e-19, 4.12457153e-19, 2.70103806e-19, 1.76240788e-19,\n       1.14571474e-19, 7.42010644e-20, 4.78712973e-20, 3.07636676e-20,\n       1.96908192e-20, 1.25520748e-20, 7.96810225e-21, 5.03664910e-21,\n       3.16981374e-21, 1.98603465e-21, 1.23866684e-21, 7.68932209e-22,\n       4.75046575e-22, 2.92041786e-22, 1.78631351e-22, 1.08696212e-22,\n       6.57888137e-23, 3.96008023e-23, 2.37028077e-23, 1.41047378e-23,\n       8.34297312e-24, 4.90437599e-24, 2.86460795e-24, 1.66215350e-24,\n       9.57859186e-25, 5.48088338e-25, 3.11318344e-25, 1.75486464e-25,\n       9.81383687e-26, 5.44318732e-26, 2.99323382e-26, 1.63134064e-26,\n       8.80842695e-27, 4.71002611e-27, 2.49303748e-27, 1.30560244e-27,\n       6.76163586e-28, 3.46113248e-28, 1.75009273e-28, 8.73602202e-29,\n       4.30220352e-29, 2.08875431e-29, 9.99023495e-30, 4.70332461e-30,\n       2.17769994e-30, 9.90716031e-31, 4.42405823e-31, 1.93704585e-31,\n       8.30602893e-32, 3.48356071e-32, 1.42698785e-32, 5.70053613e-33,\n       2.21703812e-33, 8.37870540e-34, 3.07056575e-34, 1.08862767e-34,\n       3.72401149e-35, 1.22548416e-35, 3.86610475e-36, 1.16460832e-36,\n       3.33433071e-37, 9.02358339e-38, 2.29322604e-38, 5.42958479e-39,\n       1.18602916e-39, 2.36105349e-40, 4.21647181e-41, 6.61537149e-42,\n       8.85983133e-43, 9.71368199e-44, 8.16044046e-45, 4.65902701e-46,\n       1.35182008e-47]), 21: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       4.44055737e-38, 1.41768050e-36, 2.38907027e-35, 2.88565701e-34,\n       2.81732320e-33, 2.35658731e-32, 1.74616117e-31, 1.17163380e-30,\n       7.22914218e-30, 4.14796307e-29, 2.23225412e-28, 1.13428841e-27,\n       5.47150371e-27, 2.51652598e-26, 1.10763171e-25, 4.67979175e-25,\n       1.90298718e-24, 7.46460107e-24, 2.83004429e-23, 1.03882913e-22,\n       3.69759423e-22, 1.27792149e-21, 4.29359608e-21, 1.40390742e-20,\n       4.47175021e-20, 1.38873501e-19, 4.20832881e-19, 1.24526850e-18,\n       3.60053191e-18, 1.01784983e-17, 2.81485260e-17, 7.61912080e-17,\n       2.01946574e-16, 5.24373035e-16, 1.33441967e-15, 3.32932600e-15,\n       8.14675045e-15, 1.95577575e-14, 4.60779929e-14, 1.06569537e-13,\n       2.42022370e-13, 5.39848895e-13, 1.18301094e-12, 2.54744943e-12,\n       5.39161113e-12, 1.12181107e-11, 2.29507913e-11, 4.61783230e-11,\n       9.13954600e-11, 1.77966641e-10, 3.41004592e-10, 6.43085360e-10,\n       1.19382961e-09, 2.18202516e-09, 3.92734789e-09, 6.96209971e-09,\n       1.21580018e-08, 2.09192559e-08, 3.54710985e-08, 5.92831564e-08,\n       9.76791639e-08, 1.58698950e-07, 2.54294676e-07, 4.01960390e-07,\n       6.26910903e-07, 9.64941231e-07, 1.46610927e-06, 2.19938963e-06,\n       3.25844304e-06, 4.76863050e-06, 6.89537270e-06, 9.85391035e-06,\n       1.39204597e-05, 1.94446806e-05, 2.68632800e-05, 3.67144737e-05,\n       4.96529128e-05, 6.64645739e-05, 8.80810043e-05, 1.15592220e-04,\n       1.50257480e-04, 1.93513131e-04, 2.46976669e-04, 3.12446247e-04,\n       3.91894872e-04, 4.87458671e-04, 6.01418745e-04, 7.36176320e-04,\n       8.94221082e-04, 1.07809287e-03, 1.29033709e-03, 1.53345446e-03,\n       1.80984608e-03, 2.12175469e-03, 2.47120375e-03, 2.85993547e-03,\n       3.28934966e-03, 3.76044489e-03, 4.27376371e-03, 4.82934367e-03,\n       5.42667558e-03, 6.06467049e-03, 6.74163671e-03, 7.45526780e-03,\n       8.20264221e-03, 8.98023517e-03, 9.78394280e-03, 1.06091183e-02,\n       1.14506199e-02, 1.23028689e-02, 1.31599185e-02, 1.40155299e-02,\n       1.48632553e-02, 1.56965267e-02, 1.65087471e-02, 1.72933829e-02,\n       1.80440569e-02, 1.87546371e-02, 1.94193228e-02, 2.00327240e-02,\n       2.05899334e-02, 2.10865900e-02, 2.15189332e-02, 2.18838456e-02,\n       2.21788856e-02, 2.24023082e-02, 2.25530744e-02, 2.26308494e-02,\n       2.26359903e-02, 2.25695232e-02, 2.24331117e-02, 2.22290160e-02,\n       2.19600460e-02, 2.16295072e-02, 2.12411427e-02, 2.07990708e-02,\n       2.03077207e-02, 1.97717674e-02, 1.91960659e-02, 1.85855868e-02,\n       1.79453549e-02, 1.72803893e-02, 1.65956486e-02, 1.58959797e-02,\n       1.51860721e-02, 1.44704168e-02, 1.37532717e-02, 1.30386314e-02,\n       1.23302039e-02, 1.16313925e-02, 1.09452822e-02, 1.02746328e-02,\n       9.62187584e-03, 8.98911581e-03, 8.37813608e-03, 7.79040788e-03,\n       7.22710252e-03, 6.68910621e-03, 6.17703697e-03, 5.69126329e-03,\n       5.23192396e-03, 4.79894878e-03, 4.39207963e-03, 4.01089173e-03,\n       3.65481458e-03, 3.32315248e-03, 3.01510427e-03, 2.72978220e-03,\n       2.46622966e-03, 2.22343774e-03, 2.00036051e-03, 1.79592895e-03,\n       1.60906347e-03, 1.43868513e-03, 1.28372539e-03, 1.14313469e-03,\n       1.01588959e-03, 9.00998868e-04, 7.97508392e-04, 7.04504983e-04,\n       6.21119324e-04, 5.46527997e-04, 4.79954753e-04, 4.20671090e-04,\n       3.67996234e-04, 3.21296615e-04, 2.79984893e-04, 2.43518640e-04,\n       2.11398721e-04, 1.83167447e-04, 1.58406561e-04, 1.36735100e-04,\n       1.17807178e-04, 1.01309743e-04, 8.69603151e-05, 7.45047632e-05,\n       6.37151229e-05, 5.43874847e-05, 4.63399643e-05, 3.94107684e-05,\n       3.34563618e-05, 2.83497444e-05, 2.39788382e-05, 2.02449877e-05,\n       1.70615715e-05, 1.43527239e-05, 1.20521627e-05, 1.01021187e-05,\n       8.45236352e-06, 7.05932833e-06, 5.88530977e-06, 4.89775584e-06,\n       4.06862663e-06, 3.37382385e-06, 2.79268342e-06, 2.30752564e-06,\n       1.90325772e-06, 1.56702355e-06, 1.28789616e-06, 1.05660835e-06,\n       8.65317463e-07, 7.07400621e-07, 5.77276873e-07, 4.70253209e-07,\n       3.82391576e-07, 3.10394327e-07, 2.51505816e-07, 2.03428079e-07,\n       1.64248758e-07, 1.32379662e-07, 1.06504505e-07, 8.55345762e-08,\n       6.85712161e-08, 5.48741394e-08, 4.38347517e-08, 3.49537264e-08,\n       2.78222071e-08, 2.21060841e-08, 1.75328730e-08, 1.38807903e-08,\n       1.09696773e-08, 8.65347796e-09, 6.81401768e-09, 5.35586960e-09,\n       4.20212790e-09, 3.29093530e-09, 2.57263634e-09, 2.00744899e-09,\n       1.56356409e-09, 1.21559750e-09, 9.43332170e-10, 7.30698008e-10,\n       5.64946377e-10, 4.35983498e-10, 3.35833320e-10, 2.58205631e-10,\n       1.98149511e-10, 1.51775874e-10, 1.16035767e-10, 8.85436157e-11,\n       6.74365902e-11, 5.12629436e-11, 3.88935476e-11, 2.94519483e-11,\n       2.22591821e-11, 1.67903286e-11, 1.26403763e-11, 9.49746021e-12,\n       7.12192435e-12, 5.32997545e-12, 3.98094779e-12, 2.96740259e-12,\n       2.20744722e-12, 1.63878901e-12, 1.21414193e-12, 8.97685574e-13,\n       6.62341433e-13, 4.87682118e-13, 3.58329975e-13, 2.62733129e-13,\n       1.92232021e-13, 1.40349038e-13, 1.02249074e-13, 7.43307958e-14,\n       5.39176125e-14, 3.90245404e-14, 2.81827129e-14, 2.03075722e-14,\n       1.46000906e-14, 1.04729084e-14, 7.49522901e-15, 5.35179816e-15,\n       3.81243869e-15, 2.70947511e-15, 1.92104334e-15, 1.35877990e-15,\n       9.58762316e-16, 6.74857875e-16, 4.73851764e-16, 3.31887164e-16,\n       2.31870120e-16, 1.61582277e-16, 1.12311730e-16, 7.78621555e-17,\n       5.38374740e-17, 3.71267115e-17, 2.55339502e-17, 1.75131770e-17,\n       1.19787769e-17, 8.17043769e-18, 5.55709266e-18, 3.76879952e-18,\n       2.54855814e-18, 1.71832217e-18, 1.15508773e-18, 7.74117358e-19,\n       5.17202403e-19, 3.44473533e-19, 2.28702927e-19, 1.51351337e-19,\n       9.98336096e-20, 6.56326091e-20, 4.30021754e-20, 2.80778303e-20,\n       1.82689038e-20, 1.18443065e-20, 7.65114122e-21, 4.92416104e-21,\n       3.15715907e-21, 2.01644437e-21, 1.28282538e-21, 8.12839483e-22,\n       5.12933201e-22, 3.22327027e-22, 2.01684180e-22, 1.25644513e-22,\n       7.79232658e-23, 4.81056236e-23, 2.95583699e-23, 1.80746298e-23,\n       1.09978648e-23, 6.65794638e-24, 4.00963717e-24, 2.40181424e-24,\n       1.43079220e-24, 8.47512449e-25, 4.99083936e-25, 2.92132887e-25,\n       1.69935254e-25, 9.82187999e-26, 5.63923962e-26, 3.21560203e-26,\n       1.82060121e-26, 1.02321429e-26, 5.70688390e-27, 3.15781054e-27,\n       1.73297995e-27, 9.42928227e-28, 5.08498046e-28, 2.71683649e-28,\n       1.43756895e-28, 7.53010288e-29, 3.90287066e-29, 2.00064244e-29,\n       1.01375754e-29, 5.07505144e-30, 2.50862132e-30, 1.22362290e-30,\n       5.88557675e-31, 2.78965569e-31, 1.30197262e-31, 5.97844994e-32,\n       2.69855094e-32, 1.19624159e-32, 5.20250323e-33, 2.21734910e-33,\n       9.25053228e-34, 3.77265600e-34, 1.50196640e-34, 5.82814726e-35,\n       2.20046071e-35, 8.06834571e-36, 2.86697422e-36, 9.84919624e-37,\n       3.26251408e-37, 1.03885909e-37, 3.16883210e-38, 9.22211409e-39,\n       2.54864554e-39, 6.65165425e-40, 1.62861878e-40, 3.71111060e-41,\n       7.79309411e-42, 1.48963754e-42, 2.55117602e-43, 3.83352119e-44,\n       4.91076342e-45, 5.14310568e-46, 4.12239382e-47, 2.24324120e-48,\n       6.19883875e-50]), 22: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 6.52766502e-40, 2.18801325e-38, 3.86153259e-37,\n       4.86487333e-36, 4.93607282e-35, 4.28030703e-34, 3.28244029e-33,\n       2.27656805e-32, 1.45056144e-31, 8.58877239e-31, 4.76700481e-30,\n       2.49715410e-29, 1.24138844e-28, 5.88270452e-28, 2.66729256e-27,\n       1.16078440e-26, 4.86163220e-26, 1.96410102e-25, 7.66950415e-25,\n       2.89971338e-24, 1.06316296e-23, 3.78528451e-23, 1.31033941e-22,\n       4.41502647e-22, 1.44936332e-21, 4.63985839e-21, 1.44966888e-20,\n       4.42375567e-20, 1.31936655e-19, 3.84822966e-19, 1.09830998e-18,\n       3.06891611e-18, 8.39946154e-18, 2.25277960e-17, 5.92334659e-17,\n       1.52744073e-16, 3.86426109e-16, 9.59442857e-16, 2.33861429e-15,\n       5.59773949e-15, 1.31613802e-14, 3.04045080e-14, 6.90286189e-14,\n       1.54055174e-13, 3.38045766e-13, 7.29488662e-13, 1.54843573e-12,\n       3.23358061e-12, 6.64463819e-12, 1.34380052e-11, 2.67516529e-11,\n       5.24316522e-11, 1.01189849e-10, 1.92332730e-10, 3.60092406e-10,\n       6.64187319e-10, 1.20713082e-09, 2.16210503e-09, 3.81706887e-09,\n       6.64334503e-09, 1.14004259e-08, 1.92933592e-08, 3.22050199e-08,\n       5.30330015e-08, 8.61698589e-08, 1.38175950e-07, 2.18705952e-07,\n       3.41762817e-07, 5.27365723e-07, 8.03730548e-07, 1.21007105e-06,\n       1.80013489e-06, 2.64658891e-06, 3.84636092e-06, 5.52702898e-06,\n       7.85432202e-06, 1.10407568e-05, 1.53553854e-05, 2.11345656e-05,\n       2.87935923e-05, 3.88389510e-05, 5.18808663e-05, 6.86457377e-05,\n       8.99879733e-05, 1.16900664e-04, 1.50524485e-04, 1.92154182e-04,\n       2.43241981e-04, 3.05397296e-04, 3.80382124e-04, 4.70101642e-04,\n       5.76589573e-04, 7.01988068e-04, 8.48521979e-04, 1.01846758e-03,\n       1.21411602e-03, 1.43773182e-03, 1.69150732e-03, 1.97751352e-03,\n       2.29764870e-03, 2.65358557e-03, 3.04671855e-03, 3.47811225e-03,\n       3.94845263e-03, 4.45800224e-03, 5.00656080e-03, 5.59343241e-03,\n       6.21740051e-03, 6.87671145e-03, 7.56906762e-03, 8.29163049e-03,\n       9.04103392e-03, 9.81340780e-03, 1.06044118e-02, 1.14092787e-02,\n       1.22228666e-02, 1.30397193e-02, 1.38541334e-02, 1.46602306e-02,\n       1.54520351e-02, 1.62235522e-02, 1.69688496e-02, 1.76821365e-02,\n       1.83578421e-02, 1.89906893e-02, 1.95757646e-02, 2.01085807e-02,\n       2.05851328e-02, 2.10019463e-02, 2.13561156e-02, 2.16453335e-02,\n       2.18679116e-02, 2.20227896e-02, 2.21095370e-02, 2.21283433e-02,\n       2.20800012e-02, 2.19658806e-02, 2.17878958e-02, 2.15484657e-02,\n       2.12504687e-02, 2.08971929e-02, 2.04922836e-02, 2.00396867e-02,\n       1.95435927e-02, 1.90083785e-02, 1.84385513e-02, 1.78386924e-02,\n       1.72134049e-02, 1.65672626e-02, 1.59047635e-02, 1.52302872e-02,\n       1.45480562e-02, 1.38621021e-02, 1.31762365e-02, 1.24940271e-02,\n       1.18187785e-02, 1.11535171e-02, 1.05009821e-02, 9.86361884e-03,\n       9.24357838e-03, 8.64271900e-03, 8.06261205e-03, 7.50455052e-03,\n       6.96956017e-03, 6.45841294e-03, 5.97164200e-03, 5.50955835e-03,\n       5.07226838e-03, 4.65969211e-03, 4.27158177e-03, 3.90754053e-03,\n       3.56704097e-03, 3.24944308e-03, 2.95401177e-03, 2.67993342e-03,\n       2.42633168e-03, 2.19228208e-03, 1.97682562e-03, 1.77898121e-03,\n       1.59775687e-03, 1.43215979e-03, 1.28120514e-03, 1.14392387e-03,\n       1.01936922e-03, 9.06622353e-04, 8.04796859e-04, 7.13042432e-04,\n       6.30547649e-04, 5.56541999e-04, 4.90297202e-04, 4.31127923e-04,\n       3.78391932e-04, 3.31489794e-04, 2.89864163e-04, 2.52998731e-04,\n       2.20416901e-04, 1.91680242e-04, 1.66386768e-04, 1.44169097e-04,\n       1.24692519e-04, 1.07653023e-04, 9.27752967e-05, 7.98107438e-05,\n       6.85355256e-05, 5.87486550e-05, 5.02701544e-05, 4.29392894e-05,\n       3.66128868e-05, 3.11637447e-05, 2.64791369e-05, 2.24594141e-05,\n       1.90167038e-05, 1.60737057e-05, 1.35625820e-05, 1.14239397e-05,\n       9.60590049e-06, 8.06325373e-06, 6.75668955e-06, 5.65210545e-06,\n       4.71998242e-06, 3.93482520e-06, 3.27466197e-06, 2.72059836e-06,\n       2.25642133e-06, 1.86824821e-06, 1.54421691e-06, 1.27421305e-06,\n       1.04963039e-06, 8.63161112e-07, 7.08612658e-07, 5.80748223e-07,\n       4.75148236e-07, 3.88090340e-07, 3.16445690e-07, 2.57589566e-07,\n       2.09324517e-07, 1.69814443e-07, 1.37528189e-07, 1.11191401e-07,\n       8.97455219e-08, 7.23129612e-08, 5.81675628e-08, 4.67096344e-08,\n       3.74448759e-08, 2.99666380e-08, 2.39410198e-08, 1.90943772e-08,\n       1.52028751e-08, 1.20837690e-08, 9.58814434e-09, 7.59488327e-09,\n       6.00566201e-09, 4.74081153e-09, 3.73589974e-09, 2.93891534e-09,\n       2.30795227e-09, 1.80930972e-09, 1.41593637e-09, 1.10615909e-09,\n       8.62646165e-10, 6.71563659e-10, 5.21890169e-10, 4.04861472e-10,\n       3.13521314e-10, 2.42358785e-10, 1.87016207e-10, 1.44054264e-10,\n       1.10763559e-10, 8.50137221e-11, 6.51328128e-11, 4.98111477e-11,\n       3.80247453e-11, 2.89745144e-11, 2.20380439e-11, 1.67314577e-11,\n       1.26792949e-11, 9.59077339e-12, 7.24112214e-12, 5.45692809e-12,\n       4.10465808e-12, 3.08168543e-12, 2.30928873e-12, 1.72720030e-12,\n       1.28936985e-12, 9.60679065e-13, 7.14398765e-13, 5.30224784e-13,\n       3.92763918e-13, 2.90369171e-13, 2.14245532e-13, 1.57764843e-13,\n       1.15941939e-13, 8.50349177e-14, 6.22407485e-14, 4.54639643e-14,\n       3.31412449e-14, 2.41086683e-14, 1.75014568e-14, 1.26784234e-14,\n       9.16515248e-15, 6.61135755e-15, 4.75894867e-15, 3.41816902e-15,\n       2.44980029e-15, 1.75192190e-15, 1.25007988e-15, 8.90003193e-16,\n       6.32219253e-16, 4.48082047e-16, 3.16848831e-16, 2.23533289e-16,\n       1.57332470e-16, 1.10476726e-16, 7.73908207e-17, 5.40833960e-17,\n       3.77036684e-17, 2.62202838e-17, 1.81892138e-17, 1.25863992e-17,\n       8.68736394e-18, 5.98082348e-18, 4.10683758e-18, 2.81264127e-18,\n       1.92117844e-18, 1.30874013e-18, 8.89112745e-19, 6.02369266e-19,\n       4.06963696e-19, 2.74169560e-19, 1.84177575e-19, 1.23364693e-19,\n       8.23879476e-20, 5.48575715e-20, 3.64158384e-20, 2.40993285e-20,\n       1.58986330e-20, 1.04552253e-20, 6.85335955e-21, 4.47761813e-21,\n       2.91568104e-21, 1.89215834e-21, 1.22369599e-21, 7.88608135e-22,\n       5.06398717e-22, 3.23995061e-22, 2.06522912e-22, 1.31144620e-22,\n       8.29568175e-23, 5.22683274e-23, 3.28000176e-23, 2.04984463e-23,\n       1.27567471e-23, 7.90478437e-24, 4.87672455e-24, 2.99508776e-24,\n       1.83099376e-24, 1.11406552e-24, 6.74573518e-25, 4.06432163e-25,\n       2.43629485e-25, 1.45276192e-25, 8.61625497e-26, 5.08200922e-26,\n       2.98040230e-26, 1.73765177e-26, 1.00697989e-26, 5.79917766e-27,\n       3.31827420e-27, 1.88610556e-27, 1.06470628e-27, 5.96760657e-28,\n       3.32022376e-28, 1.83322158e-28, 1.00419848e-28, 5.45569547e-29,\n       2.93878313e-29, 1.56900406e-29, 8.29970690e-30, 4.34827332e-30,\n       2.25532465e-30, 1.15758013e-30, 5.87682184e-31, 2.94964982e-31,\n       1.46287859e-31, 7.16497798e-32, 3.46364531e-32, 1.65154463e-32,\n       7.76235860e-33, 3.59361796e-33, 1.63746349e-33, 7.33763047e-34,\n       3.23073511e-34, 1.39635537e-34, 5.91827421e-35, 2.45707185e-35,\n       9.98027390e-36, 3.96096153e-36, 1.53380821e-36, 5.78590907e-37,\n       2.12251017e-37, 7.55738154e-38, 2.60619183e-38, 8.68384609e-39,\n       2.78812198e-39, 8.59939586e-40, 2.53892010e-40, 7.14638104e-41,\n       1.90861005e-41, 4.80964198e-42, 1.13599514e-42, 2.49463966e-43,\n       5.04321743e-44, 9.27031092e-45, 1.52500211e-45, 2.19851465e-46,\n       2.69875076e-47, 2.70529566e-48, 2.07321187e-49, 1.07763281e-50,\n       2.84250858e-52])}\nN = 22\nT = 20\nd = 5\nmax_s = 20\nq = 0.2\nw = 0.1\nl = 10\nnum_schedules = 100000\nconvolutions = {1: [0.2, 0.011760082311389614, 0.018737887669852717, 0.03156447505670982, 0.13360091965816184, 0.13550492742489204, 0.1108511697139353, 0.07226954243956286, 0.07010973464572853, 0.041775869017845114, 0.04038774488928362, 0.023224990933043196, 0.02024011958205141, 0.017249748058332817, 0.016605178815719657, 0.015371018725734827, 0.012441116717360218, 0.011080147347236016, 0.007235275846378654, 0.00632161104533464, 0.003668440101954738], 2: array([0.00000000e+00, 2.94002058e-03, 4.85734634e-03, 8.44201652e-03,\n       3.47671175e-02, 3.92827554e-02, 3.92005578e-02, 3.82167303e-02,\n       5.78493269e-02, 6.98970091e-02, 8.02888289e-02, 7.61734696e-02,\n       7.41903730e-02, 6.69141946e-02, 6.10389588e-02, 5.24194843e-02,\n       4.52138495e-02, 3.88397799e-02, 3.43857713e-02, 3.07791506e-02,\n       2.74092159e-02, 2.36324898e-02, 2.04956521e-02, 1.75156273e-02,\n       1.43499891e-02, 1.09322432e-02, 7.94496249e-03, 5.86144073e-03,\n       4.31414707e-03, 3.17678814e-03, 2.39318264e-03, 1.78294201e-03,\n       1.37785690e-03, 1.04328529e-03, 7.73711124e-04, 5.38008712e-04,\n       3.54646204e-04, 2.15963641e-04, 1.16308898e-04, 5.79761287e-05,\n       1.68218160e-05]), 3: array([0.00000000e+00, 0.00000000e+00, 4.32186050e-05, 1.40265710e-04,\n       3.53869282e-04, 1.39144845e-03, 3.03403976e-03, 5.50805464e-03,\n       1.12045966e-02, 1.76075704e-02, 2.32499285e-02, 2.78477994e-02,\n       3.46910124e-02, 4.22505513e-02, 5.01159446e-02, 5.53915078e-02,\n       5.89758642e-02, 6.01215563e-02, 5.99423610e-02, 5.78632533e-02,\n       5.48655440e-02, 5.11004377e-02, 4.73564348e-02, 4.37070119e-02,\n       4.02402424e-02, 3.67137428e-02, 3.32503637e-02, 2.98707447e-02,\n       2.64939306e-02, 2.30340039e-02, 1.96059983e-02, 1.64060310e-02,\n       1.35696836e-02, 1.11162642e-02, 9.04724056e-03, 7.32634799e-03,\n       5.91852188e-03, 4.76814798e-03, 3.82017054e-03, 3.02750310e-03,\n       2.36485488e-03, 1.81485519e-03, 1.36839365e-03, 1.01155073e-03,\n       7.33111978e-04, 5.22631425e-04, 3.70472319e-04, 2.62868968e-04,\n       1.85973042e-04, 1.31237358e-04, 9.18363665e-05, 6.33417856e-05,\n       4.27658922e-05, 2.78349940e-05, 1.72697010e-05, 1.00584007e-05,\n       5.44928710e-06, 2.66671347e-06, 1.14360655e-06, 3.98778666e-07,\n       7.71372804e-08]), 4: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.35317940e-07,\n       3.07420208e-06, 1.01924845e-05, 4.14947126e-05, 1.21898778e-04,\n       2.95777252e-04, 7.29082488e-04, 1.54646029e-03, 2.86935326e-03,\n       5.03941842e-03, 8.10395568e-03, 1.18092601e-02, 1.58618976e-02,\n       2.04536739e-02, 2.55735385e-02, 3.10991933e-02, 3.64557423e-02,\n       4.12982386e-02, 4.52422233e-02, 4.82244237e-02, 5.00743660e-02,\n       5.08758176e-02, 5.06943477e-02, 4.97767772e-02, 4.82960629e-02,\n       4.64338380e-02, 4.42464571e-02, 4.18080229e-02, 3.91687504e-02,\n       3.63660273e-02, 3.34056615e-02, 3.03217052e-02, 2.71859440e-02,\n       2.40944965e-02, 2.11312208e-02, 1.83600898e-02, 1.58216111e-02,\n       1.35384972e-02, 1.15129032e-02, 9.73236987e-03, 8.17407196e-03,\n       6.81474447e-03, 5.63364260e-03, 4.61465608e-03, 3.74301056e-03,\n       3.00528177e-03, 2.38892841e-03, 1.88199499e-03, 1.47133129e-03,\n       1.14265141e-03, 8.81920749e-04, 6.76492739e-04, 5.15447656e-04,\n       3.89711426e-04, 2.91929513e-04, 2.16272111e-04, 1.58230534e-04,\n       1.14237711e-04, 8.13841253e-05, 5.72513050e-05, 3.98126390e-05,\n       2.74131488e-05, 1.87228096e-05, 1.26989339e-05, 8.53965213e-06,\n       5.67352874e-06, 3.70846579e-06, 2.37078715e-06, 1.47278678e-06,\n       8.81826178e-07, 5.03931537e-07, 2.71938862e-07, 1.36824477e-07,\n       6.31260223e-08, 2.59401007e-08, 9.09285656e-09, 2.43815942e-09,\n       3.53716866e-10]), 5: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       9.33923909e-09, 6.00717321e-08, 2.46902484e-07, 1.07610188e-06,\n       3.78698535e-06, 1.11512123e-05, 3.15944232e-05, 8.06113857e-05,\n       1.84183437e-04, 3.95885341e-04, 7.88467975e-04, 1.44458464e-03,\n       2.47203728e-03, 3.96941560e-03, 5.97657199e-03, 8.47242036e-03,\n       1.14461984e-02, 1.48794592e-02, 1.87230630e-02, 2.28366330e-02,\n       2.70364139e-02, 3.11077427e-02, 3.48702212e-02, 3.81571729e-02,\n       4.08581843e-02, 4.29024392e-02, 4.42869926e-02, 4.50429779e-02,\n       4.52336186e-02, 4.49162765e-02, 4.41490428e-02, 4.29821229e-02,\n       4.14631235e-02, 3.96294961e-02, 3.75191619e-02, 3.51774463e-02,\n       3.26629391e-02, 3.00419527e-02, 2.73820229e-02, 2.47453736e-02,\n       2.21856209e-02, 1.97446030e-02, 1.74513841e-02, 1.53226008e-02,\n       1.33653504e-02, 1.15802823e-02, 9.96465391e-03, 8.51356896e-03,\n       7.22081280e-03, 6.07917252e-03, 5.08067041e-03, 4.21619591e-03,\n       3.47527054e-03, 2.84619162e-03, 2.31662030e-03, 1.87419846e-03,\n       1.50708097e-03, 1.20430932e-03, 9.56050851e-04, 7.53703510e-04,\n       5.89859326e-04, 4.58170017e-04, 3.53185533e-04, 2.70214236e-04,\n       2.05223691e-04, 1.54767320e-04, 1.15924450e-04, 8.62487918e-05,\n       6.37294755e-05, 4.67470535e-05, 3.40192154e-05, 2.45424688e-05,\n       1.75382796e-05, 1.24053920e-05, 8.68073979e-06, 6.00804632e-06,\n       4.11318185e-06, 2.78627230e-06, 1.86818843e-06, 1.24005563e-06,\n       8.14650295e-07, 5.29162647e-07, 3.39183124e-07, 2.13861735e-07,\n       1.32118911e-07, 7.95975920e-08, 4.65104419e-08, 2.61928904e-08,\n       1.41105789e-08, 7.20777590e-09, 3.45396586e-09, 1.53149368e-09,\n       6.15952978e-10, 2.17751499e-10, 6.41611678e-11, 1.39753778e-11,\n       1.62198642e-12]), 6: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 1.37287775e-10, 1.10180766e-09, 5.40499885e-09,\n       2.55316766e-08, 1.02229543e-07, 3.47784439e-07, 1.10574507e-06,\n       3.22014854e-06, 8.52307587e-06, 2.11264440e-05, 4.89416545e-05,\n       1.05523845e-04, 2.13856975e-04, 4.08363978e-04, 7.34079216e-04,\n       1.24607635e-03, 2.00521331e-03, 3.06713884e-03, 4.47206830e-03,\n       6.24535758e-03, 8.39787265e-03, 1.09223889e-02, 1.37826874e-02,\n       1.69112845e-02, 2.02119297e-02, 2.35725940e-02, 2.68738686e-02,\n       3.00018540e-02, 3.28554743e-02, 3.53567448e-02, 3.74522177e-02,\n       3.91136858e-02, 4.03309189e-02, 4.11073798e-02, 4.14547538e-02,\n       4.13910230e-02, 4.09372197e-02, 4.01175990e-02, 3.89606711e-02,\n       3.75016933e-02, 3.57831259e-02, 3.38536058e-02, 3.17652874e-02,\n       2.95710087e-02, 2.73212957e-02, 2.50618484e-02, 2.28316953e-02,\n       2.06624890e-02, 1.85787536e-02, 1.65988553e-02, 1.47360638e-02,\n       1.29995281e-02, 1.13950216e-02, 9.92552138e-03, 8.59151109e-03,\n       7.39113288e-03, 6.32030752e-03, 5.37298875e-03, 4.54154197e-03,\n       3.81720641e-03, 3.19056551e-03, 2.65198600e-03, 2.19198636e-03,\n       1.80150953e-03, 1.47208951e-03, 1.19592787e-03, 9.65909979e-04,\n       7.75591871e-04, 6.19175625e-04, 4.91481166e-04, 3.87917772e-04,\n       3.04457667e-04, 2.37608519e-04, 1.84380001e-04, 1.42242049e-04,\n       1.09076944e-04, 8.31283342e-05, 6.29506788e-05, 4.73615618e-05,\n       3.53986572e-05, 2.62824219e-05, 1.93846973e-05, 1.42025740e-05,\n       1.03365475e-05, 7.47207578e-06, 5.36386711e-06, 3.82251455e-06,\n       2.70317029e-06, 1.89600968e-06, 1.31835177e-06, 9.08318477e-07,\n       6.19847121e-07, 4.18829190e-07, 2.80160067e-07, 1.85494460e-07,\n       1.21545372e-07, 7.87940292e-08, 5.05053384e-08, 3.19765210e-08,\n       1.99666483e-08, 1.22694135e-08, 7.39890897e-09, 4.36362584e-09,\n       2.50689903e-09, 1.39653646e-09, 7.50429849e-10, 3.86592194e-10,\n       1.89547068e-10, 8.76711109e-11, 3.78268355e-11, 1.49965203e-11,\n       5.34422400e-12, 1.65437230e-12, 4.19317279e-13, 7.69017545e-14,\n       7.43770003e-15]), 7: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 2.01814443e-12, 1.94122896e-11,\n       1.10677745e-10, 5.68315791e-10, 2.52131146e-09, 9.62258123e-09,\n       3.37784230e-08, 1.09215255e-07, 3.23867327e-07, 8.97823079e-07,\n       2.33562731e-06, 5.69512765e-06, 1.31015280e-05, 2.85202882e-05,\n       5.87647118e-05, 1.14886007e-04, 2.13592919e-04, 3.78099858e-04,\n       6.38267972e-04, 1.02976473e-03, 1.59153260e-03, 2.36191864e-03,\n       3.37514137e-03, 4.65842798e-03, 6.22917692e-03, 8.09127374e-03,\n       1.02319121e-02, 1.26199283e-02, 1.52069905e-02, 1.79305412e-02,\n       2.07185288e-02, 2.34945935e-02, 2.61838704e-02, 2.87177237e-02,\n       3.10373936e-02, 3.30953529e-02, 3.48554065e-02, 3.62916083e-02,\n       3.73871334e-02, 3.81328730e-02, 3.85265399e-02, 3.85722140e-02,\n       3.82805832e-02, 3.76692112e-02, 3.67625370e-02, 3.55912089e-02,\n       3.41908886e-02, 3.26005883e-02, 3.08608023e-02, 2.90116297e-02,\n       2.70911761e-02, 2.51343913e-02, 2.31724208e-02, 2.12323728e-02,\n       1.93373718e-02, 1.75067593e-02, 1.57563580e-02, 1.40987155e-02,\n       1.25432996e-02, 1.10966504e-02, 9.76254184e-03, 8.54219148e-03,\n       7.43453823e-03, 6.43657977e-03, 5.54374959e-03, 4.75030505e-03,\n       4.04969802e-03, 3.43490184e-03, 2.89867980e-03, 2.43379187e-03,\n       2.03314748e-03, 1.68991563e-03, 1.39760359e-03, 1.15011281e-03,\n       9.41778896e-04, 7.67399068e-04, 6.22248209e-04, 5.02082802e-04,\n       4.03132871e-04, 3.22082980e-04, 2.56044463e-04, 2.02521485e-04,\n       1.59373647e-04, 1.24777626e-04, 9.71898468e-05, 7.53114956e-05,\n       5.80564865e-05, 4.45225142e-05, 3.39650595e-05, 2.57741424e-05,\n       1.94536127e-05, 1.46027894e-05, 1.09003105e-05, 8.09009527e-06,\n       5.96931593e-06, 4.37824165e-06, 3.19177865e-06, 2.31250396e-06,\n       1.66498270e-06, 1.19116477e-06, 8.46673402e-07, 5.97822283e-07,\n       4.19226268e-07, 2.91896462e-07, 2.01731534e-07, 1.38333127e-07,\n       9.40847869e-08, 6.34434018e-08, 4.24001446e-08, 2.80745183e-08,\n       1.84110832e-08, 1.19542864e-08, 7.68208172e-09, 4.88348501e-09,\n       3.06887791e-09, 1.90465539e-09, 1.16595979e-09, 7.02839620e-10,\n       4.16318897e-10, 2.41709572e-10, 1.37140565e-10, 7.57799027e-11,\n       4.06220920e-11, 2.10304456e-11, 1.04607490e-11, 4.96879733e-12,\n       2.23721674e-12, 9.46117936e-13, 3.71359512e-13, 1.33106185e-13,\n       4.25521951e-14, 1.16981783e-14, 2.59774639e-15, 4.11409659e-16,\n       3.41059463e-17]), 8: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.96669307e-14,\n       3.32632359e-13, 2.16128295e-12, 1.20495904e-11, 5.83254011e-11,\n       2.44982264e-10, 9.37937964e-10, 3.31090086e-09, 1.07763075e-08,\n       3.27754187e-08, 9.37197103e-08, 2.52240817e-07, 6.42127344e-07,\n       1.55130357e-06, 3.56106697e-06, 7.78403657e-06, 1.62339430e-05,\n       3.23405268e-05, 6.16207471e-05, 1.12455479e-04, 1.96819590e-04,\n       3.30791101e-04, 5.34679044e-04, 8.32571530e-04, 1.25119762e-03,\n       1.81825202e-03, 2.56041648e-03, 3.50119906e-03, 4.65858915e-03,\n       6.04270414e-03, 7.65376161e-03, 9.48083281e-03, 1.15015825e-02,\n       1.36830855e-02, 1.59835591e-02, 1.83548561e-02, 2.07453258e-02,\n       2.31027057e-02, 2.53765994e-02, 2.75203688e-02, 2.94923504e-02,\n       3.12565581e-02, 3.27829693e-02, 3.40476137e-02, 3.50325988e-02,\n       3.57262235e-02, 3.61231503e-02, 3.62245560e-02, 3.60380999e-02,\n       3.55776239e-02, 3.48625294e-02, 3.39168622e-02, 3.27681720e-02,\n       3.14462686e-02, 2.99820016e-02, 2.84061785e-02, 2.67486884e-02,\n       2.50378470e-02, 2.32999409e-02, 2.15589337e-02, 1.98362846e-02,\n       1.81508401e-02, 1.65187689e-02, 1.49535343e-02, 1.34659095e-02,\n       1.20640461e-02, 1.07536041e-02, 9.53794025e-03, 8.41834816e-03,\n       7.39433321e-03, 6.46390441e-03, 5.62386379e-03, 4.87007810e-03,\n       4.19772307e-03, 3.60149645e-03, 3.07579985e-03, 2.61489219e-03,\n       2.21301827e-03, 1.86451598e-03, 1.56390469e-03, 1.30595630e-03,\n       1.08574960e-03, 8.98708674e-04, 7.40626363e-04, 6.07674253e-04,\n       4.96401246e-04, 4.03722969e-04, 3.26904421e-04, 2.63538065e-04,\n       2.11519238e-04, 1.69020315e-04, 1.34464629e-04, 1.06500865e-04,\n       8.39783503e-05, 6.59235857e-05, 5.15181907e-05, 4.00784542e-05,\n       3.10366016e-05, 2.39238636e-05, 1.83553737e-05, 1.40168654e-05,\n       1.06530900e-05, 8.05783422e-06, 6.06539235e-06, 4.54333360e-06,\n       3.38640636e-06, 2.51142976e-06, 1.85303697e-06, 1.36014968e-06,\n       9.93077528e-07, 7.21148556e-07, 5.20788255e-07, 3.73974252e-07,\n       2.67002539e-07, 1.89509349e-07, 1.33700650e-07, 9.37486958e-08,\n       6.53219310e-08, 4.52206751e-08, 3.10962522e-08, 2.12356780e-08,\n       1.43976318e-08, 9.68835673e-09, 6.46846181e-09, 4.28346429e-09,\n       2.81241920e-09, 1.83020494e-09, 1.18002634e-09, 7.53494695e-10,\n       4.76282755e-10, 2.97855405e-10, 1.84163557e-10, 1.12482006e-10,\n       6.77906759e-11, 4.02603155e-11, 2.35229019e-11, 1.34946492e-11,\n       7.58398118e-12, 4.16444181e-12, 2.22761842e-12, 1.15684434e-12,\n       5.81004596e-13, 2.80944221e-13, 1.30116794e-13, 5.73611648e-14,\n       2.38874283e-14, 9.30725023e-15, 3.35057381e-15, 1.09544511e-15,\n       3.17287149e-16, 7.83632125e-17, 1.54715185e-17, 2.15604527e-18,\n       1.56394527e-19]), 9: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       4.36106934e-16, 5.58459942e-15, 4.07326429e-14, 2.45831184e-13,\n       1.28546894e-12, 5.86419590e-12, 2.42542575e-11, 9.24187318e-11,\n       3.25655966e-10, 1.07235283e-09, 3.32274707e-09, 9.71469186e-09,\n       2.69127134e-08, 7.08902611e-08, 1.77886163e-07, 4.26123735e-07,\n       9.76353953e-07, 2.14259186e-06, 4.50900354e-06, 9.11105535e-06,\n       1.76955279e-05, 3.30670919e-05, 5.95131680e-05, 1.03269265e-04,\n       1.72957683e-04, 2.79915266e-04, 4.38314619e-04, 6.64990292e-04,\n       9.78924118e-04, 1.40039907e-03, 1.94986351e-03, 2.64655749e-03,\n       3.50698038e-03, 4.54332647e-03, 5.76206543e-03, 7.16284454e-03,\n       8.73785756e-03, 1.04717562e-02, 1.23421193e-02, 1.43204134e-02,\n       1.63733229e-02, 1.84642744e-02, 2.05549865e-02, 2.26069022e-02,\n       2.45824294e-02, 2.64459583e-02, 2.81646782e-02, 2.97092332e-02,\n       3.10542773e-02, 3.21789621e-02, 3.30673634e-02, 3.37088165e-02,\n       3.40981135e-02, 3.42355178e-02, 3.41265678e-02, 3.37816677e-02,\n       3.32154897e-02, 3.24462393e-02, 3.14948475e-02, 3.03841545e-02,\n       2.91381379e-02, 2.77812197e-02, 2.63376676e-02, 2.48310927e-02,\n       2.32840335e-02, 2.17176142e-02, 2.01512676e-02, 1.86025159e-02,\n       1.70868100e-02, 1.56174291e-02, 1.42054432e-02, 1.28597366e-02,\n       1.15870896e-02, 1.03923083e-02, 9.27839283e-03, 8.24672966e-03,\n       7.29729655e-03, 6.42886945e-03, 5.63922367e-03, 4.92532407e-03,\n       4.28350161e-03, 3.70961470e-03, 3.19919499e-03, 2.74757743e-03,\n       2.35001450e-03, 2.00177438e-03, 1.69822309e-03, 1.43489086e-03,\n       1.20752339e-03, 1.01211905e-03, 8.44953614e-04, 7.02594104e-04,\n       5.81903678e-04, 4.80039306e-04, 3.94443845e-04, 3.22833915e-04,\n       2.63184726e-04, 2.13712835e-04, 1.72857587e-04, 1.39261912e-04,\n       1.11752988e-04, 8.93232395e-05, 7.11120177e-05, 5.63882612e-05,\n       4.45343334e-05, 3.50311706e-05, 2.74448025e-05, 2.14142522e-05,\n       1.66407775e-05, 1.28783861e-05, 9.92553753e-06, 7.61793536e-06,\n       5.82230962e-06, 4.43108959e-06, 3.35787095e-06, 2.53358544e-06,\n       1.90328611e-06, 1.42346769e-06, 1.05984722e-06, 7.85537509e-07,\n       5.79552589e-07, 4.25591632e-07, 3.11054811e-07, 2.26251005e-07,\n       1.63763307e-07, 1.17943638e-07, 8.45124073e-08, 6.02431816e-08,\n       4.27157331e-08, 3.01237682e-08, 2.11260799e-08, 1.47319667e-08,\n       1.02135109e-08, 7.03877683e-09, 4.82120769e-09, 3.28149304e-09,\n       2.21898886e-09, 1.49041558e-09, 9.94073210e-10, 6.58215380e-10,\n       4.32540642e-10, 2.82005147e-10, 1.82352631e-10, 1.16905891e-10,\n       7.42784526e-11, 4.67528004e-11, 2.91382447e-11, 1.79717279e-11,\n       1.09623232e-11, 6.60786250e-12, 3.93238099e-12, 2.30779160e-12,\n       1.33384003e-12, 7.58050253e-13, 4.22857896e-13, 2.31044572e-13,\n       1.23362864e-13, 6.41965572e-14, 3.24624261e-14, 1.58972403e-14,\n       7.51018843e-15, 3.40733926e-15, 1.47676419e-15, 6.07524219e-16,\n       2.35369535e-16, 8.50209857e-17, 2.82606422e-17, 8.48996806e-18,\n       2.24638297e-18, 5.03260163e-19, 8.93969701e-20, 1.11224854e-20,\n       7.17154941e-22]), 10: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 6.41081679e-18, 9.23088394e-17, 7.46785395e-16,\n       4.86097235e-15, 2.72681056e-14, 1.33821167e-13, 5.93378980e-13,\n       2.42053289e-12, 9.14412398e-12, 3.22857479e-11, 1.07305613e-10,\n       3.37001018e-10, 1.00409751e-09, 2.84826926e-09, 7.71010932e-09,\n       1.99596188e-08, 4.95120014e-08, 1.17866285e-07, 2.69629248e-07,\n       5.93439977e-07, 1.25798181e-06, 2.57079664e-06, 5.06927180e-06,\n       9.65328668e-06, 1.77668521e-05, 3.16306961e-05, 5.45179106e-05,\n       9.10515099e-05, 1.47489422e-04, 2.31951454e-04, 3.54536947e-04,\n       5.27285221e-04, 7.63944251e-04, 1.07953145e-03, 1.48968920e-03,\n       2.00985770e-03, 2.65431146e-03, 3.43513054e-03, 4.36119672e-03,\n       5.43731097e-03, 6.66351902e-03, 8.03471129e-03, 9.54053146e-03,\n       1.11655932e-02, 1.28899689e-02, 1.46898879e-02, 1.65385709e-02,\n       1.84071274e-02, 2.02654584e-02, 2.20831247e-02, 2.38301614e-02,\n       2.54778310e-02, 2.69993212e-02, 2.83703842e-02, 2.95699139e-02,\n       3.05804397e-02, 3.13885169e-02, 3.19849851e-02, 3.23650781e-02,\n       3.25283755e-02, 3.24786013e-02, 3.22232899e-02, 3.17733470e-02,\n       3.11425420e-02, 3.03469637e-02, 2.94044696e-02, 2.83341512e-02,\n       2.71558277e-02, 2.58895793e-02, 2.45553213e-02, 2.31724233e-02,\n       2.17593747e-02, 2.03334993e-02, 1.89107236e-02, 1.75053990e-02,\n       1.61301818e-02, 1.47959682e-02, 1.35118814e-02, 1.22853051e-02,\n       1.11219559e-02, 1.00259851e-02, 9.00010389e-03, 8.04572215e-03,\n       7.16309602e-03, 6.35147847e-03, 5.60926896e-03, 4.93415921e-03,\n       4.32327241e-03, 3.77329405e-03, 3.28059249e-03, 2.84132801e-03,\n       2.45154952e-03, 2.10727818e-03, 1.80457807e-03, 1.53961416e-03,\n       1.30869838e-03, 1.10832467e-03, 9.35194382e-04, 7.86233024e-04,\n       6.58599786e-04, 5.49690857e-04, 4.57137689e-04, 3.78801151e-04,\n       3.12762470e-04, 2.57311722e-04, 2.10934601e-04, 1.72298064e-04,\n       1.40235389e-04, 1.13731103e-04, 9.19061280e-05, 7.40034399e-05,\n       5.93744522e-05, 4.74662583e-05, 3.78098316e-05, 3.00092222e-05,\n       2.37317646e-05, 1.86992761e-05, 1.46802120e-05, 1.14827291e-05,\n       8.94859567e-06, 6.94788498e-06, 5.37438330e-06, 4.14164200e-06,\n       3.17960559e-06, 2.43174910e-06, 1.85266191e-06, 1.40601993e-06,\n       1.06289284e-06, 8.00338501e-07, 6.00242011e-07, 4.48361645e-07,\n       3.33548966e-07, 2.47114555e-07, 1.82314821e-07, 1.33938890e-07,\n       9.79777251e-08, 7.13604119e-08, 5.17449992e-08, 3.73534035e-08,\n       2.68417109e-08, 1.91987696e-08, 1.36672803e-08, 9.68268688e-09,\n       6.82608385e-09, 4.78810285e-09, 3.34135764e-09, 2.31952409e-09,\n       1.60153746e-09, 1.09971486e-09, 7.50872793e-10, 5.09717580e-10,\n       3.43951949e-10, 2.30670528e-10, 1.53718568e-10, 1.01766754e-10,\n       6.69156534e-11, 4.36897630e-11, 2.83165783e-11, 1.82129674e-11,\n       1.16214266e-11, 7.35403839e-12, 4.61334294e-12, 2.86779455e-12,\n       1.76571434e-12, 1.07622530e-12, 6.48980865e-13, 3.86900717e-13,\n       2.27849582e-13, 1.32422273e-13, 7.58672388e-14, 4.27928002e-14,\n       2.37286641e-14, 1.29133611e-14, 6.88420719e-15, 3.58758708e-15,\n       1.82330531e-15, 9.01308195e-16, 4.32060783e-16, 2.00168371e-16,\n       8.92736583e-17, 3.81541282e-17, 1.55414177e-17, 5.99394710e-18,\n       2.17103280e-18, 7.30871249e-19, 2.25584021e-19, 6.26585699e-20,\n       1.52513864e-20, 3.12466633e-21, 5.04310338e-22, 5.66696825e-23,\n       3.28854993e-24]), 11: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 9.42396665e-20, 1.50710589e-18,\n       1.33928556e-17, 9.36609836e-17, 5.60665815e-16, 2.93889856e-15,\n       1.38846680e-14, 6.02499524e-14, 2.42242710e-13, 9.10334187e-13,\n       3.22061373e-12, 1.07752195e-11, 3.42305257e-11, 1.03619756e-10,\n       2.99675454e-10, 8.29892326e-10, 2.20511958e-09, 5.63110907e-09,\n       1.38395209e-08, 3.27767058e-08, 7.48862603e-08, 1.65215358e-07,\n       3.52283917e-07, 7.26570469e-07, 1.45052961e-06, 2.80508104e-06,\n       5.25812919e-06, 9.56042703e-06, 1.68725107e-05, 2.89230295e-05,\n       4.81934418e-05, 7.81172832e-05, 1.23275071e-04, 1.89559679e-04,\n       2.84283253e-04, 4.16196774e-04, 5.95397532e-04, 8.33107416e-04,\n       1.14131544e-03, 1.53229078e-03, 2.01798730e-03, 2.60937477e-03,\n       3.31574388e-03, 4.14403820e-03, 5.09826661e-03, 6.17904292e-03,\n       7.38328666e-03, 8.70410317e-03, 1.01308432e-02, 1.16493273e-02,\n       1.32422082e-02, 1.48894418e-02, 1.65688330e-02, 1.82566314e-02,\n       1.99281534e-02, 2.15584147e-02, 2.31227614e-02, 2.45974855e-02,\n       2.59604125e-02, 2.71914428e-02, 2.82730294e-02, 2.91905721e-02,\n       2.99327108e-02, 3.04915090e-02, 3.08625206e-02, 3.10447452e-02,\n       3.10404822e-02, 3.08550980e-02, 3.04967263e-02, 2.99759196e-02,\n       2.93052686e-02, 2.84990056e-02, 2.75726034e-02, 2.65423799e-02,\n       2.54251171e-02, 2.42377003e-02, 2.29967863e-02, 2.17185045e-02,\n       2.04181972e-02, 1.91102028e-02, 1.78076838e-02, 1.65225009e-02,\n       1.52651304e-02, 1.40446237e-02, 1.28686027e-02, 1.17432882e-02,\n       1.06735534e-02, 9.66300042e-03, 8.71405177e-03, 7.82805490e-03,\n       7.00539420e-03, 6.24560759e-03, 5.54750440e-03, 4.90928169e-03,\n       4.32863665e-03, 3.80287298e-03, 3.32899958e-03, 2.90382053e-03,\n       2.52401530e-03, 2.18620910e-03, 1.88703318e-03, 1.62317544e-03,\n       1.39142183e-03, 1.18868915e-03, 1.01205013e-03, 8.58751431e-04,\n       7.26225523e-04, 6.12097152e-04, 5.14185281e-04, 4.30501191e-04,\n       3.59243512e-04, 2.98790810e-04, 2.47692356e-04, 2.04657597e-04,\n       1.68544806e-04, 1.38349297e-04, 1.13191540e-04, 9.23054277e-05,\n       7.50269101e-05, 6.07831472e-05, 4.90822873e-05, 3.95039498e-05,\n       3.16904528e-05, 2.53388034e-05, 2.01934495e-05, 1.60397715e-05,\n       1.26982857e-05, 1.00195157e-05, 7.87948854e-06, 6.17580181e-06,\n       4.82421284e-06, 3.75569647e-06, 2.91392181e-06, 2.25309999e-06,\n       1.73615821e-06, 1.33319846e-06, 1.02020324e-06, 7.77954185e-07,\n       5.91132883e-07, 4.47576844e-07, 3.37666795e-07, 2.53824416e-07,\n       1.90102525e-07, 1.41852183e-07, 1.05453497e-07, 7.80988920e-08,\n       5.76193925e-08, 4.23459853e-08, 3.09994699e-08, 2.26033215e-08,\n       1.64150620e-08, 1.18724429e-08, 8.55142715e-09, 6.13352614e-09,\n       4.38051786e-09, 3.11496363e-09, 2.20525833e-09, 1.55420903e-09,\n       1.09034779e-09, 7.61353081e-10, 5.29090387e-10, 3.65890383e-10,\n       2.51768520e-10, 1.72357519e-10, 1.17377095e-10, 7.95066109e-11,\n       5.35584993e-11, 3.58750759e-11, 2.38905083e-11, 1.58142701e-11,\n       1.04035306e-11, 6.80032697e-12, 4.41568790e-12, 2.84761029e-12,\n       1.82331599e-12, 1.15882820e-12, 7.30833585e-13, 4.57209951e-13,\n       2.83630526e-13, 1.74404303e-13, 1.06251788e-13, 6.41025005e-14,\n       3.82763324e-14, 2.26061146e-14, 1.31961236e-14, 7.60731424e-15,\n       4.32683127e-15, 2.42546633e-15, 1.33837906e-15, 7.25984507e-16,\n       3.86522047e-16, 2.01640104e-16, 1.02874442e-16, 5.12204661e-17,\n       2.48287226e-17, 1.16864548e-17, 5.32499926e-18, 2.34082459e-18,\n       9.88782662e-19, 3.99471735e-19, 1.53498494e-19, 5.57202504e-20,\n       1.89477603e-20, 5.97146916e-21, 1.71976774e-21, 4.44029727e-22,\n       1.00024211e-22, 1.88714544e-23, 2.79008690e-24, 2.85847837e-25,\n       1.50798106e-26]), 12: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.38533279e-21,\n       2.43619271e-20, 2.35894613e-19, 1.76572026e-18, 1.12316803e-17,\n       6.25346330e-17, 3.13190723e-16, 1.43834459e-15, 6.12010719e-15,\n       2.43370556e-14, 9.11038310e-14, 3.22653157e-13, 1.08559751e-12,\n       3.48257368e-12, 1.06820458e-11, 3.14023204e-11, 8.86599786e-11,\n       2.40828968e-10, 6.30310514e-10, 1.59162382e-09, 3.88209812e-09,\n       9.15528199e-09, 2.08953695e-08, 4.61907672e-08, 9.89707724e-08,\n       2.05683876e-07, 4.14868361e-07, 8.12638746e-07, 1.54672415e-06,\n       2.86221924e-06, 5.15244983e-06, 9.02807538e-06, 1.54064997e-05,\n       2.56216533e-05, 4.15512284e-05, 6.57547191e-05, 1.01611577e-04,\n       1.53445093e-04, 2.26614953e-04, 3.27560463e-04, 4.63777514e-04,\n       6.43715661e-04, 8.76587026e-04, 1.17208597e-03, 1.54002680e-03,\n       1.98991549e-03, 2.53047881e-03, 3.16918011e-03, 3.91175327e-03,\n       4.76178567e-03, 5.72037698e-03, 6.78589395e-03, 7.95383298e-03,\n       9.21679442e-03, 1.05645649e-02, 1.19842984e-02, 1.34607850e-02,\n       1.49767916e-02, 1.65134628e-02, 1.80507680e-02, 1.95679817e-02,\n       2.10441834e-02, 2.24587644e-02, 2.37919236e-02, 2.50251393e-02,\n       2.61415973e-02, 2.71265631e-02, 2.79676833e-02, 2.86552090e-02,\n       2.91821363e-02, 2.95442636e-02, 2.97401703e-02, 2.97711237e-02,\n       2.96409246e-02, 2.93557001e-02, 2.89236559e-02, 2.83547970e-02,\n       2.76606279e-02, 2.68538394e-02, 2.59479928e-02, 2.49572080e-02,\n       2.38958629e-02, 2.27783124e-02, 2.16186307e-02, 2.04303841e-02,\n       1.92264347e-02, 1.80187799e-02, 1.68184262e-02, 1.56352970e-02,\n       1.44781739e-02, 1.33546669e-02, 1.22712123e-02, 1.12330938e-02,\n       1.02444845e-02, 9.30850444e-03, 8.42729320e-03, 7.60209112e-03,\n       6.83332844e-03, 6.12071837e-03, 5.46335165e-03, 4.85979042e-03,\n       4.30815926e-03, 3.80623185e-03, 3.35151186e-03, 2.94130729e-03,\n       2.57279751e-03, 2.24309269e-03, 1.94928570e-03, 1.68849631e-03,\n       1.45790829e-03, 1.25479951e-03, 1.07656574e-03, 9.20738622e-04,\n       7.84998350e-04, 6.67181807e-04, 5.65286639e-04, 4.77471941e-04,\n       4.02056124e-04, 3.37512485e-04, 2.82462988e-04, 2.35670696e-04,\n       1.96031248e-04, 1.62563727e-04, 1.34401190e-04, 1.10781130e-04,\n       9.10360340e-05, 7.45842233e-05, 6.09210723e-05, 4.96107107e-05,\n       4.02782614e-05, 3.26026541e-05, 2.63100328e-05, 2.11677567e-05,\n       1.69789843e-05, 1.35778185e-05, 1.08249847e-05, 8.60400636e-06,\n       6.81784300e-06, 5.38595064e-06, 4.24172642e-06, 3.33029889e-06,\n       2.60662740e-06, 2.03387539e-06, 1.58202506e-06, 1.22670328e-06,\n       9.48191081e-07, 7.30591969e-07, 5.61136590e-07, 4.29604057e-07,\n       3.27842386e-07, 2.49372769e-07, 1.89064418e-07, 1.42868489e-07,\n       1.07601263e-07, 8.07681788e-08, 6.04216081e-08, 4.50463592e-08,\n       3.34678764e-08, 2.47789271e-08, 1.82812851e-08, 1.34395260e-08,\n       9.84456153e-09, 7.18497427e-09, 5.22457134e-09, 3.78487770e-09,\n       2.73153524e-09, 1.96377813e-09, 1.40632067e-09, 1.00312957e-09,\n       7.12661797e-10, 5.04237657e-10, 3.55289537e-10, 2.49283299e-10,\n       1.74154221e-10, 1.21134912e-10, 8.38805923e-11, 5.78190003e-11,\n       3.96692805e-11, 2.70874389e-11, 1.84061944e-11, 1.24449228e-11,\n       8.37142051e-12, 5.60180588e-12, 3.72836419e-12, 2.46777297e-12,\n       1.62412419e-12, 1.06263910e-12, 6.91073979e-13, 4.46631065e-13,\n       2.86791081e-13, 1.82925433e-13, 1.15868612e-13, 7.28657989e-14,\n       4.54800942e-14, 2.81657643e-14, 1.73011512e-14, 1.05370333e-14,\n       6.36021294e-15, 3.80308019e-15, 2.25158054e-15, 1.31910268e-15,\n       7.64238556e-16, 4.37545839e-16, 2.47347852e-16, 1.37938289e-16,\n       7.58067831e-17, 4.10091232e-17, 2.18096494e-17, 1.13867183e-17,\n       5.82706542e-18, 2.91775862e-18, 1.42679591e-18, 6.79921440e-19,\n       3.14994035e-19, 1.41489837e-19, 6.14331479e-20, 2.56930623e-20,\n       1.03086390e-20, 3.94896889e-21, 1.43608750e-21, 4.92345757e-22,\n       1.57758738e-22, 4.67266441e-23, 1.26100067e-23, 3.04056678e-24,\n       6.37215894e-25, 1.11377398e-25, 1.51892401e-26, 1.42993046e-27,\n       6.91492272e-29]), 13: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       2.03645346e-23, 3.90570597e-22, 4.09294802e-21, 3.26740445e-20,\n       2.20074672e-19, 1.29571862e-18, 6.85013138e-18, 3.31566122e-17,\n       1.48626729e-16, 6.22488543e-16, 2.45384124e-15, 9.15296298e-15,\n       3.24449552e-14, 1.09697901e-13, 3.54815931e-13, 1.10062213e-12,\n       3.28124141e-12, 9.41881741e-12, 2.60732187e-11, 6.96999620e-11,\n       1.80149972e-10, 4.50671453e-10, 1.09224603e-09, 2.56674200e-09,\n       5.85294670e-09, 1.29597498e-08, 2.78818987e-08, 5.83183065e-08,\n       1.18653677e-07, 2.34950274e-07, 4.53007292e-07, 8.50902255e-07,\n       1.55778731e-06, 2.78099578e-06, 4.84361230e-06, 8.23444563e-06,\n       1.36716896e-05, 2.21803794e-05, 3.51820383e-05, 5.45927577e-05,\n       8.29235760e-05, 1.23374718e-04, 1.79913394e-04, 2.57323791e-04,\n       3.61217882e-04, 4.97996955e-04, 6.74756318e-04, 8.99129427e-04,\n       1.17907232e-03, 1.52259436e-03, 1.93744620e-03, 2.43078004e-03,\n       3.00880023e-03, 3.67642340e-03, 4.43696678e-03, 5.29188161e-03,\n       6.24054484e-03, 7.28011857e-03, 8.40548272e-03, 9.60924245e-03,\n       1.08818089e-02, 1.22115492e-02, 1.35850004e-02, 1.49871398e-02,\n       1.64017037e-02, 1.78115450e-02, 1.91990187e-02, 2.05463834e-02,\n       2.18362064e-02, 2.30517574e-02, 2.41773804e-02, 2.51988289e-02,\n       2.61035564e-02, 2.68809530e-02, 2.75225237e-02, 2.80220057e-02,\n       2.83754254e-02, 2.85810969e-02, 2.86395665e-02, 2.85535082e-02,\n       2.83275772e-02, 2.79682269e-02, 2.74834975e-02, 2.68827832e-02,\n       2.61765847e-02, 2.53762548e-02, 2.44937443e-02, 2.35413532e-02,\n       2.25314954e-02, 2.14764786e-02, 2.03883069e-02, 1.92785061e-02,\n       1.81579752e-02, 1.70368643e-02, 1.59244796e-02, 1.48292141e-02,\n       1.37585028e-02, 1.27188014e-02, 1.17155851e-02, 1.07533666e-02,\n       9.83572956e-03, 8.96537577e-03, 8.14418283e-03, 7.37327025e-03,\n       6.65307123e-03, 5.98340796e-03, 5.36356835e-03, 4.79238239e-03,\n       4.26829659e-03, 3.78944521e-03, 3.35371724e-03, 2.95881844e-03,\n       2.60232781e-03, 2.28174828e-03, 1.99455137e-03, 1.73821588e-03,\n       1.51026076e-03, 1.30827242e-03, 1.12992673e-03, 9.73006219e-04,\n       8.35412848e-04, 7.15176828e-04, 6.10461977e-04, 5.19568078e-04,\n       4.40930698e-04, 3.73118896e-04, 3.14831237e-04, 2.64890461e-04,\n       2.22237151e-04, 1.85922688e-04, 1.55101754e-04, 1.29024586e-04,\n       1.07029181e-04, 8.85335907e-05, 7.30284279e-05, 6.00696842e-05,\n       4.92719185e-05, 4.03018702e-05, 3.28725265e-05, 2.67376575e-05,\n       2.16868220e-05, 1.75408381e-05, 1.41477010e-05, 1.13789303e-05,\n       9.12631847e-06, 7.29905568e-06, 5.82120022e-06, 4.62946488e-06,\n       3.67129011e-06, 2.90317479e-06, 2.28923723e-06, 1.79998035e-06,\n       1.41123691e-06, 1.10327243e-06, 8.60025616e-07, 6.68467821e-07,\n       5.18065235e-07, 4.00329085e-07, 3.08441005e-07, 2.36942219e-07,\n       1.81476689e-07, 1.38579672e-07, 1.05504331e-07, 8.00800664e-08,\n       6.05972291e-08, 4.57136211e-08, 3.43789641e-08, 2.57740992e-08,\n       1.92622241e-08, 1.43499271e-08, 1.06561612e-08, 7.88763062e-09,\n       5.81933376e-09, 4.27923792e-09, 3.13625162e-09, 2.29081884e-09,\n       1.66758995e-09, 1.20973136e-09, 8.74523210e-10, 6.29966057e-10,\n       4.52174510e-10, 3.23382730e-10, 2.30423640e-10, 1.63573609e-10,\n       1.15678006e-10, 8.14917832e-11, 5.71840769e-11, 3.99674147e-11,\n       2.78212422e-11, 1.92865588e-11, 1.33139603e-11, 9.15163534e-12,\n       6.26313499e-12, 4.26723955e-12, 2.89416167e-12, 1.95377701e-12,\n       1.31267441e-12, 8.77646204e-13, 5.83861729e-13, 3.86431923e-13,\n       2.54418840e-13, 1.66600288e-13, 1.08488839e-13, 7.02433363e-14,\n       4.52125195e-14, 2.89243051e-14, 1.83877597e-14, 1.16134358e-14,\n       7.28543963e-15, 4.53840352e-15, 2.80661707e-15, 1.72252901e-15,\n       1.04884869e-15, 6.33386867e-16, 3.79199511e-16, 2.24970184e-16,\n       1.32201848e-16, 7.69095869e-17, 4.42694345e-17, 2.51959161e-17,\n       1.41693488e-17, 7.86718814e-18, 4.30881262e-18, 2.32563469e-18,\n       1.23567436e-18, 6.45549862e-19, 3.31169953e-19, 1.66587416e-19,\n       8.20379532e-20, 3.94828675e-20, 1.85345609e-20, 8.46836776e-21,\n       3.75676043e-21, 1.61377338e-21, 6.69179758e-22, 2.66912316e-22,\n       1.01981446e-22, 3.71431235e-23, 1.28203130e-23, 4.16374487e-24,\n       1.26120113e-24, 3.52291636e-25, 8.94211806e-26, 2.02192077e-26,\n       3.96034426e-27, 6.44642384e-28, 8.15757445e-29, 7.10343593e-30,\n       3.17087248e-31]), 14: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 2.99360754e-25, 6.21841341e-24, 7.01183368e-23,\n       5.94989411e-22, 4.23058835e-21, 2.62435430e-20, 1.45935430e-19,\n       7.41866492e-19, 3.49030578e-18, 1.53373245e-17, 6.34160189e-17,\n       2.48109289e-16, 9.22616758e-16, 3.27314531e-15, 1.11125563e-14,\n       3.61981591e-14, 1.13382635e-13, 3.42151905e-13, 9.96355740e-13,\n       2.80385611e-12, 7.63464938e-12, 2.01370304e-11, 5.14994184e-11,\n       1.27817863e-10, 3.08109602e-10, 7.21858855e-10, 1.64480116e-09,\n       3.64707854e-09, 7.87379025e-09, 1.65595844e-08, 3.39428473e-08,\n       6.78384953e-08, 1.32257813e-07, 2.51632393e-07, 4.67403404e-07,\n       8.47962659e-07, 1.50314879e-06, 2.60466399e-06, 4.41382276e-06,\n       7.31790297e-06, 1.18759748e-05, 1.88743864e-05, 2.93910777e-05,\n       4.48666168e-05, 6.71784048e-05, 9.87130316e-05, 1.42430469e-04,\n       2.01912872e-04, 2.81390383e-04, 3.85736704e-04, 5.20428277e-04,\n       6.91462824e-04, 9.05235498e-04, 1.16837384e-03, 1.48753586e-03,\n       1.86917838e-03, 2.31930533e-03, 2.84320733e-03, 3.44520463e-03,\n       4.12840561e-03, 4.89449186e-03, 5.74353970e-03, 6.67388582e-03,\n       7.68204260e-03, 8.76266694e-03, 9.90858389e-03, 1.11108650e-02,\n       1.23589596e-02, 1.36408751e-02, 1.49434012e-02, 1.62523728e-02,\n       1.75529609e-02, 1.88299855e-02, 2.00682387e-02, 2.12528080e-02,\n       2.23693904e-02, 2.34045868e-02, 2.43461685e-02, 2.51833096e-02,\n       2.59067780e-02, 2.65090839e-02, 2.69845816e-02, 2.73295251e-02,\n       2.75420797e-02, 2.76222894e-02, 2.75720057e-02, 2.73947806e-02,\n       2.70957290e-02, 2.66813655e-02, 2.61594215e-02, 2.55386483e-02,\n       2.48286118e-02, 2.40394848e-02, 2.31818417e-02, 2.22664599e-02,\n       2.13041342e-02, 2.03055036e-02, 1.92808973e-02, 1.82401994e-02,\n       1.71927329e-02, 1.61471667e-02, 1.51114412e-02, 1.40927164e-02,\n       1.30973375e-02, 1.21308199e-02, 1.11978503e-02, 1.03023017e-02,\n       9.44726203e-03, 8.63507317e-03, 7.86737809e-03, 7.14517512e-03,\n       6.46887667e-03, 5.83837087e-03, 5.25308460e-03, 4.71204638e-03,\n       4.21394791e-03, 3.75720335e-03, 3.34000531e-03, 2.96037712e-03,\n       2.61622077e-03, 2.30536025e-03, 2.02558015e-03, 1.77465941e-03,\n       1.55040044e-03, 1.35065354e-03, 1.17333708e-03, 1.01645360e-03,\n       8.78102207e-04, 7.56487542e-04, 6.49925848e-04, 5.56848348e-04,\n       4.75802381e-04, 4.05450614e-04, 3.44568684e-04, 2.92041546e-04,\n       2.46858830e-04, 2.08109443e-04, 1.74975648e-04, 1.46726803e-04,\n       1.22712940e-04, 1.02358304e-04, 8.51549905e-05, 7.06567464e-05,\n       5.84730314e-05, 4.82633759e-05, 3.97320795e-05, 3.26232737e-05,\n       2.67163607e-05, 2.18218302e-05, 1.77774517e-05, 1.44448282e-05,\n       1.17062989e-05, 9.46217007e-06, 7.62825311e-06, 6.13368788e-06,\n       4.91902746e-06, 3.93456127e-06, 3.13885385e-06, 2.49747728e-06,\n       1.98191645e-06, 1.56862771e-06, 1.23823273e-06, 9.74831092e-07,\n       7.65416287e-07, 5.99381744e-07, 4.68104439e-07, 3.64595324e-07,\n       2.83206914e-07, 2.19389608e-07, 1.69489341e-07, 1.30580171e-07,\n       1.00326254e-07, 7.68684556e-08, 5.87315180e-08, 4.47483221e-08,\n       3.39983087e-08, 2.57575816e-08, 1.94586116e-08, 1.46578064e-08,\n       1.10094956e-08, 8.24513308e-09, 6.15672516e-09, 4.58366931e-09,\n       3.40233656e-09, 2.51785263e-09, 1.85763509e-09, 1.36632824e-09,\n       1.00184634e-09, 7.32293064e-10, 5.33570898e-10, 3.87532186e-10,\n       2.80553823e-10, 2.02442174e-10, 1.45594526e-10, 1.04359126e-10,\n       7.45484110e-11, 5.30700243e-11, 3.76480570e-11, 2.66131766e-11,\n       1.87451619e-11, 1.31551680e-11, 9.19800390e-12, 6.40700150e-12,\n       4.44583046e-12, 3.07297649e-12, 2.11565008e-12, 1.45069177e-12,\n       9.90649384e-13, 6.73664043e-13, 4.56150875e-13, 3.07522287e-13,\n       2.06398568e-13, 1.37897231e-13, 9.17017330e-14, 6.06910139e-14,\n       3.99709976e-14, 2.61929945e-14, 1.70760483e-14, 1.10736429e-14,\n       7.14215819e-15, 4.58073114e-15, 2.92100564e-15, 1.85158215e-15,\n       1.16649193e-15, 7.30226752e-16, 4.54122949e-16, 2.80494314e-16,\n       1.72027058e-16, 1.04729702e-16, 6.32720314e-17, 3.79209977e-17,\n       2.25381618e-17, 1.32787886e-17, 7.75200435e-18, 4.48209791e-18,\n       2.56528853e-18, 1.45255173e-18, 8.13195877e-19, 4.49807523e-19,\n       2.45638031e-19, 1.32323836e-19, 7.02513212e-20, 3.67203122e-20,\n       1.88761369e-20, 9.53121690e-21, 4.72101486e-21, 2.29056012e-21,\n       1.08685663e-21, 5.03455084e-22, 2.27226245e-22, 9.97058283e-23,\n       4.24314042e-23, 1.74647230e-23, 6.93071117e-24, 2.64217713e-24,\n       9.63561022e-25, 3.34473987e-25, 1.09853384e-25, 3.38896067e-26,\n       9.73171705e-27, 2.57152104e-27, 6.15975592e-28, 1.31087492e-28,\n       2.40954239e-29, 3.66928849e-30, 4.33068881e-31, 3.50787893e-32,\n       1.45401947e-33]), 15: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 4.40063388e-27, 9.84230522e-26,\n       1.18820814e-24, 1.06840872e-23, 7.99818888e-23, 5.21153410e-22,\n       3.03900125e-21, 1.61767174e-20, 7.96307097e-20, 3.65945216e-19,\n       1.58185640e-18, 6.46926910e-18, 2.51470582e-17, 9.32681765e-17,\n       3.31113519e-16, 1.12817152e-15, 3.69760479e-15, 1.16806112e-14,\n       3.56243476e-14, 1.05053151e-13, 2.99929020e-13, 8.29993749e-13,\n       2.22854946e-12, 5.81108890e-12, 1.47277385e-11, 3.63059944e-11,\n       8.71113126e-11, 2.03558291e-10, 4.63513829e-10, 1.02900804e-09,\n       2.22824649e-09, 4.70856604e-09, 9.71351537e-09, 1.95703635e-08,\n       3.85231233e-08, 7.41147589e-08, 1.39413829e-07, 2.56496155e-07,\n       4.61727520e-07, 8.13538707e-07, 1.40352065e-06, 2.37176753e-06,\n       3.92742342e-06, 6.37530347e-06, 1.01492256e-05, 1.58522737e-05,\n       2.43036119e-05, 3.65906917e-05, 5.41247975e-05, 7.86969242e-05,\n       1.12530092e-04, 1.58323476e-04, 2.19283284e-04, 2.99135278e-04,\n       4.02114198e-04, 5.32926232e-04, 6.96681979e-04, 8.98798983e-04,\n       1.14487481e-03, 1.44053354e-03, 1.79125036e-03, 2.20216048e-03,\n       2.67785970e-03, 3.22220465e-03, 3.83812087e-03, 4.52742668e-03,\n       5.29068010e-03, 6.12705521e-03, 7.03425316e-03, 8.00845190e-03,\n       9.04429720e-03, 1.01349363e-02, 1.12720944e-02, 1.24461915e-02,\n       1.36464983e-02, 1.48613255e-02, 1.60782414e-02, 1.72843121e-02,\n       1.84663558e-02, 1.96112047e-02, 2.07059659e-02, 2.17382742e-02,\n       2.26965297e-02, 2.35701139e-02, 2.43495792e-02, 2.50268074e-02,\n       2.55951352e-02, 2.60494434e-02, 2.63862103e-02, 2.66035296e-02,\n       2.67010927e-02, 2.66801396e-02, 2.65433801e-02, 2.62948883e-02,\n       2.59399759e-02, 2.54850476e-02, 2.49374431e-02, 2.43052707e-02,\n       2.35972369e-02, 2.28224758e-02, 2.19903822e-02, 2.11104526e-02,\n       2.01921355e-02, 1.92446947e-02, 1.82770872e-02, 1.72978559e-02,\n       1.63150398e-02, 1.53361003e-02, 1.43678642e-02, 1.34164838e-02,\n       1.24874113e-02, 1.15853884e-02, 1.07144489e-02, 9.87793230e-03,\n       9.07850848e-03, 8.31821010e-03, 7.59847229e-03, 6.92017745e-03,\n       6.28370408e-03, 5.68897792e-03, 5.13552431e-03, 4.62252064e-03,\n       4.14884786e-03, 3.71314022e-03, 3.31383256e-03, 2.94920465e-03,\n       2.61742209e-03, 2.31657360e-03, 2.04470440e-03, 1.79984578e-03,\n       1.58004073e-03, 1.38336583e-03, 1.20794956e-03, 1.05198718e-03,\n       9.13752484e-04, 7.91606674e-04, 6.84004655e-04, 5.89499025e-04,\n       5.06742063e-04, 4.34485990e-04, 3.71581782e-04, 3.16976783e-04,\n       2.69711354e-04, 2.28914771e-04, 1.93800564e-04, 1.63661479e-04,\n       1.37864183e-04, 1.15843876e-04, 9.70988781e-05, 8.11853147e-05,\n       6.77119432e-05, 5.63351921e-05, 4.67544477e-05, 3.87076187e-05,\n       3.19669978e-05, 2.63354294e-05, 2.16427865e-05, 1.77427533e-05,\n       1.45099044e-05, 1.18370696e-05, 9.63296909e-06, 7.82010219e-06,\n       6.33287267e-06, 5.11593129e-06, 4.12271776e-06, 3.31418371e-06,\n       2.65767901e-06, 2.12598467e-06, 1.69647648e-06, 1.35040461e-06,\n       1.07227539e-06, 8.49323065e-07, 6.71059764e-07, 5.28893837e-07,\n       4.15807123e-07, 3.26083108e-07, 2.55078726e-07, 1.99033460e-07,\n       1.54910184e-07, 1.20262912e-07, 9.31272793e-08, 7.19301382e-08,\n       5.54151738e-08, 4.25819065e-08, 3.26358243e-08, 2.49477479e-08,\n       1.90208216e-08, 1.44637849e-08, 1.09693945e-08, 8.29706166e-09,\n       6.25892220e-09, 4.70869568e-09, 3.53280312e-09, 2.64330654e-09,\n       1.97231406e-09, 1.46755987e-09, 1.08892298e-09, 8.05693798e-10,\n       5.94434362e-10, 4.37308455e-10, 3.20782379e-10, 2.34617222e-10,\n       1.71089600e-10, 1.24390933e-10, 9.01657782e-11, 6.51581226e-11,\n       4.69412375e-11, 3.37119867e-11, 2.41347075e-11, 1.72230856e-11,\n       1.22510619e-11, 8.68584800e-12, 6.13772606e-12, 4.32254765e-12,\n       3.03381041e-12, 2.12193395e-12, 1.47892961e-12, 1.02709774e-12,\n       7.10722382e-13, 4.89988996e-13, 3.36545451e-13, 2.30273433e-13,\n       1.56948414e-13, 1.06549599e-13, 7.20436558e-14, 4.85125701e-14,\n       3.25305384e-14, 2.17204374e-14, 1.44392998e-14, 9.55612234e-15,\n       6.29550690e-15, 4.12806095e-15, 2.69387958e-15, 1.74934046e-15,\n       1.13026136e-15, 7.26495128e-16, 4.64486470e-16, 2.95347460e-16,\n       1.86742075e-16, 1.17388122e-16, 7.33496986e-17, 4.55489478e-17,\n       2.81042361e-17, 1.72258087e-17, 1.04856553e-17, 6.33731630e-18,\n       3.80177071e-18, 2.26310248e-18, 1.33633806e-18, 7.82467061e-19,\n       4.54133433e-19, 2.61145985e-19, 1.48717971e-19, 8.38306191e-20,\n       4.67475783e-20, 2.57731849e-20, 1.40391242e-20, 7.55019737e-21,\n       4.00568797e-21, 2.09468628e-21, 1.07862940e-21, 5.46371646e-22,\n       2.71942742e-22, 1.32833174e-22, 6.35905288e-23, 2.97918106e-23,\n       1.36370044e-23, 6.08815427e-24, 2.64569659e-24, 1.11667439e-24,\n       4.56637911e-25, 1.80410222e-25, 6.86445109e-26, 2.50613105e-26,\n       8.74147953e-27, 2.89827076e-27, 9.07854219e-28, 2.66679095e-28,\n       7.27869991e-29, 1.82447229e-29, 4.13662275e-30, 8.31267578e-31,\n       1.43910718e-31, 2.05852169e-32, 2.27620243e-33, 1.72345229e-34,\n       6.66747916e-36]), 16: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.46897709e-29,\n       1.54990222e-27, 1.99457116e-26, 1.89506071e-25, 1.49005213e-24,\n       1.01716332e-23, 6.20355569e-23, 3.44883078e-22, 1.77155938e-21,\n       8.49078097e-21, 3.82633511e-20, 1.63102574e-19, 6.60770657e-19,\n       2.55425337e-18, 9.45197345e-18, 3.35752493e-17, 1.14755677e-16,\n       3.78150912e-16, 1.20351672e-15, 3.70509964e-15, 1.10482465e-14,\n       3.19484217e-14, 8.96866346e-14, 2.44646546e-13, 6.49010824e-13,\n       1.67570783e-12, 4.21384582e-12, 1.03268043e-11, 2.46779623e-11,\n       5.75356512e-11, 1.30936121e-10, 2.90985510e-10, 6.31762918e-10,\n       1.34053411e-09, 2.78101425e-09, 5.64264932e-09, 1.12011905e-08,\n       2.17614955e-08, 4.13900262e-08, 7.70942861e-08, 1.40671050e-07,\n       2.51524559e-07, 4.40847003e-07, 7.57649743e-07, 1.27722323e-06,\n       2.11266958e-06, 3.43017340e-06, 5.46862949e-06, 8.56410822e-06,\n       1.31793922e-05, 1.99384523e-05, 2.96652552e-05, 4.34257238e-05,\n       6.25710567e-05, 8.87799930e-05, 1.24097066e-04, 1.70963481e-04,\n       2.32237047e-04, 3.11197648e-04, 4.11535080e-04, 5.37316689e-04,\n       6.92933158e-04, 8.83021854e-04, 1.11236836e-03, 1.38578807e-03,\n       1.70799091e-03, 2.08343323e-03, 2.51616186e-03, 3.00965566e-03,\n       3.56667047e-03, 4.18909326e-03, 4.87781089e-03, 5.63259893e-03,\n       6.45203477e-03, 7.33343914e-03, 8.27284860e-03, 9.26502117e-03,\n       1.03034757e-02, 1.13805650e-02, 1.24875806e-02, 1.36148876e-02,\n       1.47520852e-02, 1.58881887e-02, 1.70118284e-02, 1.81114586e-02,\n       1.91755720e-02, 2.01929133e-02, 2.11526855e-02, 2.20447449e-02,\n       2.28597794e-02, 2.35894654e-02, 2.42266017e-02, 2.47652160e-02,\n       2.52006437e-02, 2.55295779e-02, 2.57500896e-02, 2.58616211e-02,\n       2.58649514e-02, 2.57621373e-02, 2.55564337e-02, 2.52521927e-02,\n       2.48547496e-02, 2.43702948e-02, 2.38057386e-02, 2.31685698e-02,\n       2.24667138e-02, 2.17083916e-02, 2.09019833e-02, 2.00558980e-02,\n       1.91784540e-02, 1.82777681e-02, 1.73616581e-02, 1.64375578e-02,\n       1.55124455e-02, 1.45927866e-02, 1.36844890e-02, 1.27928726e-02,\n       1.19226503e-02, 1.10779214e-02, 1.02621746e-02, 9.47830177e-03,\n       8.72861795e-03, 8.01488991e-03, 7.33836934e-03, 6.69983068e-03,\n       6.09961207e-03, 5.53765833e-03, 5.01356505e-03, 4.52662273e-03,\n       4.07586029e-03, 3.66008720e-03, 3.27793377e-03, 2.92788892e-03,\n       2.60833542e-03, 2.31758197e-03, 2.05389230e-03, 1.81551103e-03,\n       1.60068634e-03, 1.40768947e-03, 1.23483133e-03, 1.08047608e-03,\n       9.43052206e-04, 8.21060998e-04, 7.13082885e-04, 6.17781704e-04,\n       5.33907230e-04, 4.60296150e-04, 3.95871716e-04, 3.39642306e-04,\n       2.90699053e-04, 2.48212767e-04, 2.11430284e-04, 1.79670407e-04,\n       1.52319562e-04, 1.28827290e-04, 1.08701665e-04, 9.15047293e-05,\n       7.68480033e-05, 6.43881319e-05, 5.38227082e-05, 4.48863051e-05,\n       3.73467379e-05, 3.10015726e-05, 2.56748877e-05, 2.12142909e-05,\n       1.74881875e-05, 1.43832952e-05, 1.18023942e-05, 9.66230175e-06,\n       7.89205846e-06, 6.43131059e-06, 5.22887505e-06, 4.24147149e-06,\n       3.43260704e-06, 2.77159923e-06, 2.23272360e-06, 1.79447281e-06,\n       1.43891522e-06, 1.15114166e-06, 9.18789941e-07, 7.31637658e-07,\n       5.81254742e-07, 4.60707942e-07, 3.64310359e-07, 2.87409874e-07,\n       2.26210991e-07, 1.77625328e-07, 1.39146527e-07, 1.08745940e-07,\n       8.47859009e-08, 6.59478484e-08, 5.11729329e-08, 3.96130917e-08,\n       3.05908654e-08, 2.35664952e-08, 1.81110583e-08, 1.38846010e-08,\n       1.06183889e-08, 8.10054360e-09, 6.16445113e-09, 4.67943613e-09,\n       3.54327918e-09, 2.67623078e-09, 2.01623622e-09, 1.51513718e-09,\n       1.13565894e-09, 8.49027461e-10, 6.33090073e-10, 4.70837450e-10,\n       3.49244570e-10, 2.58364347e-10, 1.90620887e-10, 1.40259963e-10,\n       1.02922957e-10, 7.53174554e-11, 5.49633277e-11, 3.99975231e-11,\n       2.90244586e-11, 2.10016730e-11, 1.51526880e-11, 1.09007977e-11,\n       7.81890507e-12, 5.59162910e-12, 3.98676508e-12, 2.83385300e-12,\n       2.00813198e-12, 1.41856310e-12, 9.98916200e-13, 7.01156923e-13,\n       4.90555544e-13, 3.42080369e-13, 2.37746693e-13, 1.64674235e-13,\n       1.13668256e-13, 7.81864786e-14, 5.35893540e-14, 3.65977336e-14,\n       2.49018656e-14, 1.68804330e-14, 1.13993465e-14, 7.66814410e-15,\n       5.13786047e-15, 3.42864311e-15, 2.27863477e-15, 1.50800354e-15,\n       9.93724574e-16, 6.51965358e-16, 4.25828220e-16, 2.76853527e-16,\n       1.79152612e-16, 1.15372620e-16, 7.39324417e-17, 4.71371198e-17,\n       2.98969139e-17, 1.88608372e-17, 1.18331087e-17, 7.38189249e-18,\n       4.57815607e-18, 2.82218493e-18, 1.72887989e-18, 1.05228928e-18,\n       6.36203972e-19, 3.81980575e-19, 2.27695642e-19, 1.34714040e-19,\n       7.90828398e-20, 4.60488523e-20, 2.65868362e-20, 1.52144734e-20,\n       8.62593853e-21, 4.84301614e-21, 2.69134409e-21, 1.47955460e-21,\n       8.04165361e-22, 4.31851211e-22, 2.28978679e-22, 1.19784257e-22,\n       6.17720215e-23, 3.13750509e-23, 1.56804252e-23, 7.70293500e-24,\n       3.71521821e-24, 1.75712630e-24, 8.13811801e-25, 3.68556133e-25,\n       1.62942661e-25, 7.01999792e-26, 2.94133175e-26, 1.19588265e-26,\n       4.70633254e-27, 1.78769138e-27, 6.53291877e-28, 2.28821390e-28,\n       7.64815805e-29, 2.42681910e-29, 7.26509413e-30, 2.03650757e-30,\n       5.29548366e-31, 1.26228579e-31, 2.71628780e-32, 5.16951242e-33,\n       8.45651374e-34, 1.14032180e-34, 1.18598160e-35, 8.42984199e-37,\n       3.05740599e-38]), 17: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       9.50946288e-31, 2.42989092e-29, 3.32058753e-28, 3.32488995e-27,\n       2.73993616e-26, 1.95504111e-25, 1.24421038e-24, 7.20801230e-24,\n       3.85469914e-23, 1.92225333e-22, 9.00912533e-22, 3.99277684e-21,\n       1.68157578e-20, 6.75707852e-20, 2.59932709e-19, 9.59948372e-19,\n       3.41166326e-18, 1.16927614e-17, 3.87152529e-17, 1.24035164e-16,\n       3.85041232e-16, 1.15958341e-15, 3.39158835e-15, 9.64349765e-15,\n       2.66794531e-14, 7.18742448e-14, 1.88683647e-13, 4.82994211e-13,\n       1.20629481e-12, 2.94106223e-12, 7.00342308e-12, 1.62956350e-11,\n       3.70656547e-11, 8.24486257e-11, 1.79418549e-10, 3.82097990e-10,\n       7.96615832e-10, 1.62639664e-09, 3.25265895e-09, 6.37400001e-09,\n       1.22425225e-08, 2.30535015e-08, 4.25726612e-08, 7.71211135e-08,\n       1.37083700e-07, 2.39161553e-07, 4.09652095e-07, 6.89104942e-07,\n       1.13876310e-06, 1.84924502e-06, 2.95194200e-06, 4.63358206e-06,\n       7.15433264e-06, 1.08696667e-05, 1.62559948e-05, 2.39397691e-05,\n       3.47294020e-05, 4.96489363e-05, 6.99719786e-05, 9.72540072e-05,\n       1.33360825e-04, 1.80490696e-04, 2.41187602e-04, 3.18343159e-04,\n       4.15184949e-04, 5.35249510e-04, 6.82338793e-04, 8.60459640e-04,\n       1.07374663e-03, 1.32636952e-03, 1.62242718e-03, 1.96583097e-03,\n       2.36018066e-03, 2.80863696e-03, 3.31379479e-03, 3.87756151e-03,\n       4.50104455e-03, 5.18445260e-03, 5.92701407e-03, 6.72691622e-03,\n       7.58126777e-03, 8.48608690e-03, 9.43631598e-03, 1.04258634e-02,\n       1.14476720e-02, 1.24938127e-02, 1.35556011e-02, 1.46237345e-02,\n       1.56884450e-02, 1.67396654e-02, 1.77672034e-02, 1.87609191e-02,\n       1.97109017e-02, 2.06076408e-02, 2.14421888e-02, 2.22063089e-02,\n       2.28926081e-02, 2.34946500e-02, 2.40070471e-02, 2.44255297e-02,\n       2.47469921e-02, 2.49695145e-02, 2.50923625e-02, 2.51159636e-02,\n       2.50418640e-02, 2.48726658e-02, 2.46119489e-02, 2.42641787e-02,\n       2.38346021e-02, 2.33291367e-02, 2.27542537e-02, 2.21168580e-02,\n       2.14241693e-02, 2.06836042e-02, 1.99026640e-02, 1.90888283e-02,\n       1.82494565e-02, 1.73916988e-02, 1.65224176e-02, 1.56481191e-02,\n       1.47748967e-02, 1.39083853e-02, 1.30537273e-02, 1.22155481e-02,\n       1.13979430e-02, 1.06044730e-02, 9.83816903e-03, 9.10154358e-03,\n       8.39660960e-03, 7.72490437e-03, 7.08751820e-03, 6.48512659e-03,\n       5.91802505e-03, 5.38616563e-03, 4.88919432e-03, 4.42648860e-03,\n       3.99719453e-03, 3.60026271e-03, 3.23448278e-03, 2.89851596e-03,\n       2.59092538e-03, 2.31020402e-03, 2.05480004e-03, 1.82313949e-03,\n       1.61364638e-03, 1.42476012e-03, 1.25495042e-03, 1.10272977e-03,\n       9.66663616e-04, 8.45378493e-04, 7.37568124e-04, 6.41997824e-04,\n       5.57507327e-04, 4.83012234e-04, 4.17504274e-04, 3.60050546e-04,\n       3.09791922e-04, 2.65940750e-04, 2.27778013e-04, 1.94650069e-04,\n       1.65965083e-04, 1.41189264e-04, 1.19842980e-04, 1.01496840e-04,\n       8.57678045e-05, 7.23153664e-05, 6.08378598e-05, 5.10689172e-05,\n       4.27741060e-05, 3.57477591e-05, 2.98100123e-05, 2.48040525e-05,\n       2.05935791e-05, 1.70604747e-05, 1.41026822e-05, 1.16322771e-05,\n       9.57372830e-06, 7.86233555e-06, 6.44283184e-06, 5.26813915e-06,\n       4.29826537e-06, 3.49933025e-06, 2.84270886e-06, 2.30428108e-06,\n       1.86377665e-06, 1.50420558e-06, 1.21136455e-06, 9.73410743e-07,\n       7.80495015e-07, 6.24447343e-07, 4.98507861e-07, 3.97097684e-07,\n       3.15624241e-07, 2.50316421e-07, 1.98085418e-07, 1.56407606e-07,\n       1.23226264e-07, 9.68693619e-08, 7.59809758e-08, 5.94642467e-08,\n       4.64340738e-08, 3.61779932e-08, 2.81239173e-08, 2.18136057e-08,\n       1.68809110e-08, 1.30339893e-08, 1.00407925e-08, 7.71726958e-09,\n       5.91779750e-09, 4.52744074e-09, 3.45570758e-09, 2.63152688e-09,\n       1.99921780e-09, 1.51526477e-09, 1.14574368e-09, 8.64273337e-10,\n       6.50389323e-10, 4.88256489e-10, 3.65652388e-10, 2.73166696e-10,\n       2.03572419e-10, 1.51333337e-10, 1.12219184e-10, 8.30058082e-11,\n       6.12421572e-11, 4.50696858e-11, 3.30827604e-11, 2.42210450e-11,\n       1.76867633e-11, 1.28812574e-11, 9.35647467e-12, 6.77796974e-12,\n       4.89676530e-12, 3.52800921e-12, 2.53483052e-12, 1.81616176e-12,\n       1.29757843e-12, 9.24427424e-13, 6.56686736e-13, 4.65131185e-13,\n       3.28480410e-13, 2.31283537e-13, 1.62354754e-13, 1.13619669e-13,\n       7.92670609e-14, 5.51270196e-14, 3.82164072e-14, 2.64076083e-14,\n       1.81878610e-14, 1.24849308e-14, 8.54122810e-15, 5.82318961e-15,\n       3.95625002e-15, 2.67832587e-15, 1.80664810e-15, 1.21418981e-15,\n       8.12968290e-16, 5.42256096e-16, 3.60286091e-16, 2.38434816e-16,\n       1.57157920e-16, 1.03159902e-16, 6.74303517e-17, 4.38863710e-17,\n       2.84375048e-17, 1.83441043e-17, 1.17787178e-17, 7.52743065e-18,\n       4.78730163e-18, 3.02952980e-18, 1.90740125e-18, 1.19462032e-18,\n       7.44172621e-19, 4.61003734e-19, 2.83954604e-19, 1.73871837e-19,\n       1.05818734e-19, 6.39971420e-20, 3.84529001e-20, 2.29491961e-20,\n       1.36009120e-20, 8.00230985e-21, 4.67289078e-21, 2.70735811e-21,\n       1.55579465e-21, 8.86443068e-22, 5.00581383e-22, 2.80055229e-22,\n       1.55154042e-22, 8.50789862e-23, 4.61523150e-23, 2.47531338e-23,\n       1.31179464e-23, 6.86455315e-24, 3.54452395e-24, 1.80453825e-24,\n       9.05050733e-25, 4.46771041e-25, 2.16858658e-25, 1.03392062e-25,\n       4.83633253e-26, 2.21676535e-26, 9.94270767e-27, 4.35734176e-27,\n       1.86275924e-27, 7.75391995e-28, 3.13645554e-28, 1.23007167e-28,\n       4.66543157e-29, 1.70636178e-29, 5.99838975e-30, 2.01894987e-30,\n       6.47751072e-31, 1.97058331e-31, 5.64866230e-32, 1.51401263e-32,\n       3.75860006e-33, 8.53954288e-34, 1.74835083e-34, 3.15966827e-35,\n       4.89827288e-36, 6.24664191e-37, 6.13215684e-38, 4.10714294e-39,\n       1.40198884e-40]), 18: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 1.39790083e-32, 3.79469872e-31, 5.48795578e-30,\n       5.77713609e-29, 4.97970796e-28, 3.70657549e-27, 2.45652040e-26,\n       1.48001784e-25, 8.22347688e-25, 4.25801669e-24, 2.07111394e-23,\n       9.52310419e-23, 4.16020561e-22, 1.73382549e-21, 6.91740158e-21,\n       2.64961976e-20, 9.76784329e-20, 3.47305548e-19, 1.19322961e-18,\n       3.96768180e-18, 1.27869805e-17, 3.99912294e-17, 1.21510677e-16,\n       3.59048573e-16, 1.03269708e-15, 2.89352507e-15, 7.90380621e-15,\n       2.10615822e-14, 5.47843633e-14, 1.39179663e-13, 3.45518355e-13,\n       8.38586048e-13, 1.99064902e-12, 4.62368158e-12, 1.05121313e-11,\n       2.34021682e-11, 5.10302152e-11, 1.09028532e-10, 2.28308974e-10,\n       4.68703964e-10, 9.43593806e-10, 1.86335880e-09, 3.61030635e-09,\n       6.86494249e-09, 1.28139458e-08, 2.34849331e-08, 4.22730679e-08,\n       7.47505823e-08, 1.29882785e-07, 2.21812801e-07, 3.72420744e-07,\n       6.14908399e-07, 9.98703266e-07, 1.59600962e-06, 2.51035112e-06,\n       3.88744071e-06, 5.92866929e-06, 8.90741804e-06, 1.31882636e-05,\n       1.92489593e-05, 2.77048445e-05, 3.93350629e-05, 5.51096821e-05,\n       7.62165137e-05, 1.04086166e-04, 1.40413647e-04, 1.87174686e-04,\n       2.46634921e-04, 3.21350127e-04, 4.14155910e-04, 5.28145529e-04,\n       6.66634986e-04, 8.33114966e-04, 1.03118981e-03, 1.26450425e-03,\n       1.53665924e-03, 1.85111877e-03, 2.21110998e-03, 2.61951943e-03,\n       3.07878847e-03, 3.59081119e-03, 4.15683802e-03, 4.77738861e-03,\n       5.45217682e-03, 6.18005099e-03, 6.95895167e-03, 7.78588901e-03,\n       8.65694106e-03, 9.56727385e-03, 1.05111833e-02, 1.14821584e-02,\n       1.24729645e-02, 1.34757444e-02, 1.44821359e-02, 1.54834018e-02,\n       1.64705697e-02, 1.74345782e-02, 1.83664261e-02, 1.92573200e-02,\n       2.00988185e-02, 2.08829681e-02, 2.16024291e-02, 2.22505876e-02,\n       2.28216526e-02, 2.33107357e-02, 2.37139120e-02, 2.40282626e-02,\n       2.42518970e-02, 2.43839562e-02, 2.44245984e-02, 2.43749660e-02,\n       2.42371376e-02, 2.40140654e-02, 2.37095013e-02, 2.33279118e-02,\n       2.28743863e-02, 2.23545393e-02, 2.17744095e-02, 2.11403583e-02,\n       2.04589684e-02, 1.97369463e-02, 1.89810281e-02, 1.81978921e-02,\n       1.73940782e-02, 1.65759149e-02, 1.57494557e-02, 1.49204242e-02,\n       1.40941685e-02, 1.32756252e-02, 1.24692924e-02, 1.16792116e-02,\n       1.09089577e-02, 1.01616373e-02, 9.43989302e-03, 8.74591506e-03,\n       8.08145729e-03, 7.44785854e-03, 6.84606727e-03, 6.27666935e-03,\n       5.73991792e-03, 5.23576468e-03, 4.76389198e-03, 4.32374500e-03,\n       3.91456359e-03, 3.53541325e-03, 3.18521483e-03, 2.86277271e-03,\n       2.56680115e-03, 2.29594859e-03, 2.04881991e-03, 1.82399637e-03,\n       1.62005348e-03, 1.43557646e-03, 1.26917376e-03, 1.11948835e-03,\n       9.85207182e-04, 8.65068692e-04, 7.57868750e-04, 6.62464988e-04,\n       5.77779780e-04, 5.02801997e-04, 4.36587680e-04, 3.78259800e-04,\n       3.27007234e-04, 2.82083084e-04, 2.42802483e-04, 2.08539978e-04,\n       1.78726602e-04, 1.52846729e-04, 1.30434782e-04, 1.11071870e-04,\n       9.43824164e-05, 8.00308119e-05, 6.77181547e-05, 5.71790931e-05,\n       4.81788042e-05, 4.05101250e-05, 3.39908506e-05, 2.84612058e-05,\n       2.37814957e-05, 1.98299354e-05, 1.65006564e-05, 1.37018852e-05,\n       1.13542870e-05, 9.38946775e-06, 7.74862507e-06, 6.38133805e-06,\n       5.24448717e-06, 4.30129357e-06, 3.52046803e-06, 2.87546009e-06,\n       2.34379773e-06, 1.90650899e-06, 1.54761705e-06, 1.25370083e-06,\n       1.01351412e-06, 8.17656245e-07, 6.58288464e-07, 5.28890288e-07,\n       4.24050916e-07, 3.39291169e-07, 2.70911966e-07, 2.15865735e-07,\n       1.71647627e-07, 1.36203733e-07, 1.07853873e-07, 8.52268178e-08,\n       6.72061067e-08, 5.28848325e-08, 4.15280289e-08, 3.25414578e-08,\n       2.54457797e-08, 1.98552344e-08, 1.54600909e-08, 1.20122390e-08,\n       9.31338911e-09, 7.20543513e-09, 5.56260233e-09, 4.28506729e-09,\n       3.29378645e-09, 2.52631532e-09, 1.93343683e-09, 1.47644934e-09,\n       1.12499057e-09, 8.55295989e-10, 6.48808428e-10, 4.91070786e-10,\n       3.70846483e-10, 2.79422491e-10, 2.10058452e-10, 1.57552329e-10,\n       1.17898807e-10, 8.80212896e-11, 6.55621781e-11, 4.87191504e-11,\n       3.61176795e-11, 2.67120143e-11, 1.97084608e-11, 1.45060907e-11,\n       1.06510334e-11, 7.80132836e-12, 5.69996667e-12, 4.15426508e-12,\n       3.02012624e-12, 2.19005760e-12, 1.58407499e-12, 1.14281401e-12,\n       8.22326905e-13, 5.90162607e-13, 4.22421350e-13, 3.01547229e-13,\n       2.14678248e-13, 1.52416307e-13, 1.07912692e-13, 7.61899806e-14,\n       5.36405819e-14, 3.76569295e-14, 2.63594971e-14, 1.83973193e-14,\n       1.28020940e-14, 8.88177424e-15, 6.14318031e-15, 4.23587853e-15,\n       2.91159933e-15, 1.99497763e-15, 1.36251849e-15, 9.27520582e-16,\n       6.29302473e-16, 4.25526978e-16, 2.86749468e-16, 1.92557781e-16,\n       1.28847636e-16, 8.59056323e-17, 5.70647996e-17, 3.77647693e-17,\n       2.48969602e-17, 1.63498739e-17, 1.06944197e-17, 6.96689557e-18,\n       4.51984427e-18, 2.91991862e-18, 1.87819296e-18, 1.20278740e-18,\n       7.66781344e-19, 4.86564775e-19, 3.07288404e-19, 1.93123567e-19,\n       1.20768112e-19, 7.51343193e-20, 4.64976852e-20, 2.86197217e-20,\n       1.75174496e-20, 1.06604081e-20, 6.44905098e-21, 3.87751458e-21,\n       2.31663711e-21, 1.37503902e-21, 8.10631901e-22, 4.74543886e-22,\n       2.75776974e-22, 1.59054265e-22, 9.10135866e-23, 5.16534053e-23,\n       2.90650581e-23, 1.62091101e-23, 8.95543496e-24, 4.89963871e-24,\n       2.65330424e-24, 1.42146355e-24, 7.52962300e-25, 3.94134569e-25,\n       2.03739403e-25, 1.03936747e-25, 5.22887820e-26, 2.59209244e-26,\n       1.26510238e-26, 6.07345439e-27, 2.86517180e-27, 1.32679875e-27,\n       6.02413146e-28, 2.67836838e-28, 1.16448597e-28, 4.94345859e-29,\n       2.04568691e-29, 8.23685974e-30, 3.22041303e-30, 1.21982151e-30,\n       4.46474920e-31, 1.57450224e-31, 5.33187024e-32, 1.72712367e-32,\n       5.32733137e-33, 1.55638364e-33, 4.27923127e-34, 1.09870942e-34,\n       2.60915945e-35, 5.66198570e-36, 1.10538008e-36, 1.90159795e-37,\n       2.80110439e-38, 3.38808001e-39, 3.14915798e-40, 1.99413634e-41,\n       6.42889012e-43]), 19: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 2.05492860e-34, 5.90566752e-33,\n       9.01131445e-32, 9.95092543e-31, 8.95563376e-30, 6.94128025e-29,\n       4.78206788e-28, 2.99100465e-27, 1.72362654e-26, 9.24990675e-26,\n       4.66076197e-25, 2.21919981e-24, 1.00367157e-23, 4.32986966e-23,\n       1.78801660e-22, 7.08869701e-22, 2.70492453e-21, 9.95593355e-21,\n       3.54133452e-20, 1.21934854e-19, 4.07002819e-19, 1.31867088e-18,\n       4.15187821e-18, 1.27165561e-17, 3.79239508e-17, 1.10214851e-16,\n       3.12376511e-16, 8.64027672e-16, 2.33378564e-15, 6.15925323e-15,\n       1.58912515e-14, 4.01016243e-14, 9.90225873e-14, 2.39361983e-13,\n       5.66620088e-13, 1.31401554e-12, 2.98625224e-12, 6.65283390e-12,\n       1.45334911e-11, 3.11414116e-11, 6.54678025e-11, 1.35067026e-10,\n       2.73533005e-10, 5.43891420e-10, 1.06208005e-09, 2.03724525e-09,\n       3.83943621e-09, 7.11092291e-09, 1.29453849e-08, 2.31702611e-08,\n       4.07822512e-08, 7.06048367e-08, 1.20259978e-07, 2.01573625e-07,\n       3.32565441e-07, 5.40205349e-07, 8.64150345e-07, 1.36170050e-06,\n       2.11422818e-06, 3.23533356e-06, 4.88095668e-06, 7.26162553e-06,\n       1.06569379e-05, 1.54322581e-05, 2.20574603e-05, 3.11273733e-05,\n       4.33833794e-05, 5.97354148e-05, 8.12834133e-05, 1.09337052e-04,\n       1.45432519e-04, 1.91344918e-04, 2.49094936e-04, 3.20948402e-04,\n       4.09407559e-04, 5.17193036e-04, 6.47215824e-04, 8.02538899e-04,\n       9.86328524e-04, 1.20179568e-03, 1.45212853e-03, 1.74041719e-03,\n       2.06957248e-03, 2.44224076e-03, 2.86071698e-03, 3.32685866e-03,\n       3.84200315e-03, 4.40689109e-03, 5.02159836e-03, 5.68547920e-03,\n       6.39712234e-03, 7.15432230e-03, 7.95406702e-03, 8.79254286e-03,\n       9.66515750e-03, 1.05665805e-02, 1.14908011e-02, 1.24312023e-02,\n       1.33806488e-02, 1.43315886e-02, 1.52761640e-02, 1.62063308e-02,\n       1.71139819e-02, 1.79910740e-02, 1.88297525e-02, 1.96224738e-02,\n       2.03621203e-02, 2.10421079e-02, 2.16564820e-02, 2.22000013e-02,\n       2.26682068e-02, 2.30574766e-02, 2.33650642e-02, 2.35891207e-02,\n       2.37287015e-02, 2.37837567e-02, 2.37551077e-02, 2.36444091e-02,\n       2.34540996e-02, 2.31873412e-02, 2.28479502e-02, 2.24403200e-02,\n       2.19693399e-02, 2.14403093e-02, 2.08588506e-02, 2.02308223e-02,\n       1.95622333e-02, 1.88591606e-02, 1.81276707e-02, 1.73737474e-02,\n       1.66032246e-02, 1.58217271e-02, 1.50346183e-02, 1.42469560e-02,\n       1.34634554e-02, 1.26884608e-02, 1.19259243e-02, 1.11793921e-02,\n       1.04519975e-02, 9.74646054e-03, 9.06509301e-03, 8.40980897e-03,\n       7.78213946e-03, 7.18325113e-03, 6.61396785e-03, 6.07479483e-03,\n       5.56594452e-03, 5.08736362e-03, 4.63876080e-03, 4.21963457e-03,\n       3.82930074e-03, 3.46691929e-03, 3.13152017e-03, 2.82202775e-03,\n       2.53728389e-03, 2.27606917e-03, 2.03712249e-03, 1.81915869e-03,\n       1.62088439e-03, 1.44101186e-03, 1.27827114e-03, 1.13142036e-03,\n       9.99254326e-04, 8.80611633e-04, 7.74380200e-04, 6.79501526e-04,\n       5.94973700e-04, 5.19853333e-04, 4.53256519e-04, 3.94358968e-04,\n       3.42395409e-04, 2.96658404e-04, 2.56496653e-04, 2.21312903e-04,\n       1.90561550e-04, 1.63746000e-04, 1.40415887e-04, 1.20164177e-04,\n       1.02624246e-04, 8.74669453e-05, 7.43977270e-05, 6.31538272e-05,\n       5.35015580e-05, 4.52337145e-05, 3.81671159e-05, 3.21402891e-05,\n       2.70113018e-05, 2.26557471e-05, 1.89648809e-05, 1.58439078e-05,\n       1.32104144e-05, 1.09929409e-05, 9.12968759e-06, 7.56734722e-06,\n       6.26005515e-06, 5.16845013e-06, 4.25883668e-06, 3.50244097e-06,\n       2.87475235e-06, 2.35494248e-06, 1.92535490e-06, 1.57105783e-06,\n       1.27945374e-06, 1.03993953e-06, 8.43611715e-07, 6.83011414e-07,\n       5.51904431e-07, 4.45092182e-07, 3.58249602e-07, 2.87786567e-07,\n       2.30729778e-07, 1.84622349e-07, 1.47438684e-07, 1.17512511e-07,\n       9.34762075e-08, 7.42097714e-08, 5.87980245e-08, 4.64948112e-08,\n       3.66931269e-08, 2.89002556e-08, 2.27171319e-08, 1.78212506e-08,\n       1.39525505e-08, 1.09017830e-08, 8.50095280e-09, 6.61547944e-09,\n       5.13778668e-09, 3.98207177e-09, 3.08004797e-09, 2.37748748e-09,\n       1.83142102e-09, 1.40787483e-09, 1.08004623e-09, 8.26836238e-10,\n       6.31672219e-10, 4.81565400e-10, 3.66358229e-10, 2.78124723e-10,\n       2.10693841e-10, 1.59271530e-10, 1.20141715e-10, 9.04303031e-11,\n       6.79193584e-11, 5.09011218e-11, 3.80636032e-11, 2.84011279e-11,\n       2.11445580e-11, 1.57069894e-11, 1.16415920e-11, 8.60895525e-12,\n       6.35185407e-12, 4.67579726e-12, 3.43406735e-12, 2.51624287e-12,\n       1.83941323e-12, 1.34147068e-12, 9.76000540e-13, 7.08398312e-13,\n       5.12926185e-13, 3.70487135e-13, 2.66945750e-13, 1.91864624e-13,\n       1.37555795e-13, 9.83704581e-14, 7.01684208e-14, 4.99228001e-14,\n       3.54262382e-14, 2.50731131e-14, 1.76984992e-14, 1.24593965e-14,\n       8.74735851e-15, 6.12438836e-15, 4.27602692e-15, 2.97711485e-15,\n       2.06687024e-15, 1.43079617e-15, 9.87581989e-16, 6.79645886e-16,\n       4.66325370e-16, 3.18987924e-16, 2.17530236e-16, 1.47878772e-16,\n       1.00210385e-16, 6.76892023e-17, 4.55726289e-17, 3.05804707e-17,\n       2.04510732e-17, 1.36299850e-17, 9.05224835e-18, 5.99063324e-18,\n       3.95017595e-18, 2.59512708e-18, 1.69851374e-18, 1.10742971e-18,\n       7.19228572e-19, 4.65250478e-19, 2.99736563e-19, 1.92303758e-19,\n       1.22854568e-19, 7.81463565e-20, 4.94875986e-20, 3.11966798e-20,\n       1.95747621e-20, 1.22239057e-20, 7.59618312e-21, 4.69673951e-21,\n       2.88904102e-21, 1.76768298e-21, 1.07567769e-21, 6.50903922e-22,\n       3.91592398e-22, 2.34183064e-22, 1.39186463e-22, 8.21996562e-23,\n       4.82258697e-23, 2.81013172e-23, 1.62593317e-23, 9.33885873e-24,\n       5.32326323e-24, 3.01040267e-24, 1.68847295e-24, 9.38938098e-25,\n       5.17479247e-25, 2.82546731e-25, 1.52772377e-25, 8.17634196e-26,\n       4.32933328e-26, 2.26674909e-26, 1.17290410e-26, 5.99427429e-27,\n       3.02374485e-27, 1.50448182e-27, 7.37800096e-28, 3.56330570e-28,\n       1.69338814e-28, 7.91127934e-29, 3.62985857e-29, 1.63386522e-29,\n       7.20638733e-30, 3.11057452e-30, 1.31214385e-30, 5.40105196e-31,\n       2.16572182e-31, 8.44399428e-32, 3.19459971e-32, 1.17004548e-32,\n       4.13783189e-33, 1.40876405e-33, 4.60174823e-34, 1.43654799e-34,\n       4.26616371e-35, 1.19873235e-35, 3.16636598e-36, 7.80085192e-37,\n       1.77524006e-37, 3.68649971e-38, 6.87697503e-39, 1.12865716e-39,\n       1.58353019e-40, 1.82139354e-41, 1.60745346e-42, 9.65222392e-44,\n       2.94799979e-45]), 20: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.02076618e-36,\n       9.16270478e-35, 1.47110501e-33, 1.70059544e-32, 1.59532681e-31,\n       1.28547716e-30, 9.19113239e-30, 5.95847198e-29, 3.55554680e-28,\n       1.97442902e-27, 1.02890013e-26, 5.06471457e-26, 2.36740161e-25,\n       1.05534611e-24, 4.50278346e-24, 1.84434544e-23, 7.27105366e-23,\n       2.76509753e-22, 1.01629377e-21, 3.61624010e-21, 1.24758787e-20,\n       4.17863512e-20, 1.36037467e-19, 4.30924884e-19, 1.32946173e-18,\n       3.99810119e-18, 1.17293272e-17, 3.35923981e-17, 9.39805218e-17,\n       2.56992361e-16, 6.87263987e-16, 1.79831050e-15, 4.60620695e-15,\n       1.15543327e-14, 2.83949118e-14, 6.83895899e-14, 1.61488701e-13,\n       3.73969518e-13, 8.49577268e-13, 1.89393583e-12, 4.14419028e-12,\n       8.90300448e-12, 1.87828391e-11, 3.89237286e-11, 7.92488948e-11,\n       1.58559204e-10, 3.11817507e-10, 6.02850595e-10, 1.14605903e-09,\n       2.14278891e-09, 3.94106412e-09, 7.13174725e-09, 1.27002949e-08,\n       2.22615312e-08, 3.84157027e-08, 6.52778355e-08, 1.09249241e-07,\n       1.80119770e-07, 2.92611496e-07, 4.68497819e-07, 7.39454631e-07,\n       1.15081978e-06, 1.76645034e-06, 2.67487045e-06, 3.99689194e-06,\n       5.89486151e-06, 8.58363895e-06, 1.23433385e-05, 1.75337698e-05,\n       2.46103961e-05, 3.41414932e-05, 4.68260419e-05, 6.35117385e-05,\n       8.52123587e-05, 1.13123586e-04, 1.48636314e-04, 1.93346365e-04,\n       2.49059577e-04, 3.17791206e-04, 4.01758737e-04, 5.03367310e-04,\n       6.25187192e-04, 7.69922959e-04, 9.40374352e-04, 1.13938907e-03,\n       1.36980810e-03, 1.63440444e-03, 1.93581651e-03, 2.27647767e-03,\n       2.65854357e-03, 3.08381931e-03, 3.55368838e-03, 4.06904547e-03,\n       4.63023529e-03, 5.23699942e-03, 5.88843292e-03, 6.58295248e-03,\n       7.31827732e-03, 8.09142402e-03, 8.89871576e-03, 9.73580631e-03,\n       1.05977186e-02, 1.14788974e-02, 1.23732750e-02, 1.32743484e-02,\n       1.41752674e-02, 1.50689304e-02, 1.59480862e-02, 1.68054404e-02,\n       1.76337632e-02, 1.84259962e-02, 1.91753566e-02, 1.98754366e-02,\n       2.05202947e-02, 2.11045393e-02, 2.16234008e-02, 2.20727930e-02,\n       2.24493615e-02, 2.27505183e-02, 2.29744645e-02, 2.31201974e-02,\n       2.31875069e-02, 2.31769568e-02, 2.30898566e-02, 2.29282213e-02,\n       2.26947222e-02, 2.23926298e-02, 2.20257496e-02, 2.15983532e-02,\n       2.11151056e-02, 2.05809906e-02, 2.00012353e-02, 1.93812352e-02,\n       1.87264820e-02, 1.80424931e-02, 1.73347466e-02, 1.66086206e-02,\n       1.58693372e-02, 1.51219145e-02, 1.43711228e-02, 1.36214492e-02,\n       1.28770677e-02, 1.21418165e-02, 1.14191815e-02, 1.07122860e-02,\n       1.00238858e-02, 9.35637032e-03, 8.71176746e-03, 8.09175379e-03,\n       7.49766775e-03, 6.93052620e-03, 6.39104350e-03, 5.87965264e-03,\n       5.39652781e-03, 4.94160798e-03, 4.51462102e-03, 4.11510787e-03,\n       3.74244657e-03, 3.39587558e-03, 3.07451635e-03, 2.77739470e-03,\n       2.50346100e-03, 2.25160895e-03, 2.02069277e-03, 1.80954288e-03,\n       1.61697997e-03, 1.44182745e-03, 1.28292235e-03, 1.13912464e-03,\n       1.00932522e-03, 8.92452350e-04, 7.87476971e-04, 6.93416735e-04,\n       6.09338998e-04, 5.34362836e-04, 4.67660194e-04, 4.08456282e-04,\n       3.56029313e-04, 3.09709685e-04, 2.68878692e-04, 2.32966856e-04,\n       2.01451960e-04, 1.73856844e-04, 1.49747031e-04, 1.28728251e-04,\n       1.10443889e-04, 9.45724255e-05, 8.08248870e-05, 6.89423421e-05,\n       5.86934725e-05, 4.98722320e-05, 4.22956116e-05, 3.58015213e-05,\n       3.02467962e-05, 2.55053306e-05, 2.14663429e-05, 1.80327697e-05,\n       1.51197888e-05, 1.26534649e-05, 1.05695159e-05, 8.81219220e-06,\n       7.33326364e-06, 6.09110734e-06, 5.04988943e-06, 4.17883377e-06,\n       3.45157081e-06, 2.84555968e-06, 2.34157727e-06, 1.92326770e-06,\n       1.57674660e-06, 1.29025445e-06, 1.05385392e-06, 8.59166299e-07,\n       6.99142852e-07, 5.67866803e-07, 4.60382512e-07, 3.72548440e-07,\n       3.00910950e-07, 2.42596300e-07, 1.95218433e-07, 1.56800477e-07,\n       1.25708076e-07, 1.00592933e-07, 8.03451011e-08, 6.40527859e-08,\n       5.09685515e-08, 4.04809840e-08, 3.20909880e-08, 2.53920072e-08,\n       2.00535585e-08, 1.58075584e-08, 1.24369939e-08, 9.76655901e-09,\n       7.65493326e-09, 5.98842964e-09, 4.67578071e-09, 3.64386923e-09,\n       2.83423988e-09, 2.20025593e-09, 1.70478672e-09, 1.31833122e-09,\n       1.01749879e-09, 7.83781994e-10, 6.02567481e-10, 4.62340582e-10,\n       3.54047083e-10, 2.70582274e-10, 2.06382793e-10, 1.57101316e-10,\n       1.19347847e-10, 9.04844359e-11, 6.84626431e-11, 5.16951424e-11,\n       3.89545122e-11, 2.92936357e-11, 2.19832354e-11, 1.64629620e-11,\n       1.23031807e-11, 9.17518367e-12, 6.82801967e-12, 5.07051319e-12,\n       3.75734064e-12, 2.77827276e-12, 2.04988179e-12, 1.50916302e-12,\n       1.10863979e-12, 8.12615505e-13, 5.94310268e-13, 4.33678389e-13,\n       3.15748613e-13, 2.29364773e-13, 1.66232451e-13, 1.20198959e-13,\n       8.67107893e-14, 6.24057437e-14, 4.48070306e-14, 3.20943690e-14,\n       2.29331231e-14, 1.63470560e-14, 1.16237930e-14, 8.24475622e-15,\n       5.83335921e-15, 4.11679785e-15, 2.89793663e-15, 2.03467463e-15,\n       1.42483845e-15, 9.95149362e-16, 6.93186168e-16, 4.81545165e-16,\n       3.33607469e-16, 2.30479180e-16, 1.58785164e-16, 1.09082478e-16,\n       7.47224217e-17, 5.10365361e-17, 3.47559041e-17, 2.35980083e-17,\n       1.59736079e-17, 1.07793472e-17, 7.25143259e-18, 4.86268857e-18,\n       3.25034133e-18, 2.16550454e-18, 1.43794974e-18, 9.51609415e-19,\n       6.27594502e-19, 4.12457153e-19, 2.70103806e-19, 1.76240788e-19,\n       1.14571474e-19, 7.42010644e-20, 4.78712973e-20, 3.07636676e-20,\n       1.96908192e-20, 1.25520748e-20, 7.96810225e-21, 5.03664910e-21,\n       3.16981374e-21, 1.98603465e-21, 1.23866684e-21, 7.68932209e-22,\n       4.75046575e-22, 2.92041786e-22, 1.78631351e-22, 1.08696212e-22,\n       6.57888137e-23, 3.96008023e-23, 2.37028077e-23, 1.41047378e-23,\n       8.34297312e-24, 4.90437599e-24, 2.86460795e-24, 1.66215350e-24,\n       9.57859186e-25, 5.48088338e-25, 3.11318344e-25, 1.75486464e-25,\n       9.81383687e-26, 5.44318732e-26, 2.99323382e-26, 1.63134064e-26,\n       8.80842695e-27, 4.71002611e-27, 2.49303748e-27, 1.30560244e-27,\n       6.76163586e-28, 3.46113248e-28, 1.75009273e-28, 8.73602202e-29,\n       4.30220352e-29, 2.08875431e-29, 9.99023495e-30, 4.70332461e-30,\n       2.17769994e-30, 9.90716031e-31, 4.42405823e-31, 1.93704585e-31,\n       8.30602893e-32, 3.48356071e-32, 1.42698785e-32, 5.70053613e-33,\n       2.21703812e-33, 8.37870540e-34, 3.07056575e-34, 1.08862767e-34,\n       3.72401149e-35, 1.22548416e-35, 3.86610475e-36, 1.16460832e-36,\n       3.33433071e-37, 9.02358339e-38, 2.29322604e-38, 5.42958479e-39,\n       1.18602916e-39, 2.36105349e-40, 4.21647181e-41, 6.61537149e-42,\n       8.85983133e-43, 9.71368199e-44, 8.16044046e-45, 4.65902701e-46,\n       1.35182008e-47]), 21: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       4.44055737e-38, 1.41768050e-36, 2.38907027e-35, 2.88565701e-34,\n       2.81732320e-33, 2.35658731e-32, 1.74616117e-31, 1.17163380e-30,\n       7.22914218e-30, 4.14796307e-29, 2.23225412e-28, 1.13428841e-27,\n       5.47150371e-27, 2.51652598e-26, 1.10763171e-25, 4.67979175e-25,\n       1.90298718e-24, 7.46460107e-24, 2.83004429e-23, 1.03882913e-22,\n       3.69759423e-22, 1.27792149e-21, 4.29359608e-21, 1.40390742e-20,\n       4.47175021e-20, 1.38873501e-19, 4.20832881e-19, 1.24526850e-18,\n       3.60053191e-18, 1.01784983e-17, 2.81485260e-17, 7.61912080e-17,\n       2.01946574e-16, 5.24373035e-16, 1.33441967e-15, 3.32932600e-15,\n       8.14675045e-15, 1.95577575e-14, 4.60779929e-14, 1.06569537e-13,\n       2.42022370e-13, 5.39848895e-13, 1.18301094e-12, 2.54744943e-12,\n       5.39161113e-12, 1.12181107e-11, 2.29507913e-11, 4.61783230e-11,\n       9.13954600e-11, 1.77966641e-10, 3.41004592e-10, 6.43085360e-10,\n       1.19382961e-09, 2.18202516e-09, 3.92734789e-09, 6.96209971e-09,\n       1.21580018e-08, 2.09192559e-08, 3.54710985e-08, 5.92831564e-08,\n       9.76791639e-08, 1.58698950e-07, 2.54294676e-07, 4.01960390e-07,\n       6.26910903e-07, 9.64941231e-07, 1.46610927e-06, 2.19938963e-06,\n       3.25844304e-06, 4.76863050e-06, 6.89537270e-06, 9.85391035e-06,\n       1.39204597e-05, 1.94446806e-05, 2.68632800e-05, 3.67144737e-05,\n       4.96529128e-05, 6.64645739e-05, 8.80810043e-05, 1.15592220e-04,\n       1.50257480e-04, 1.93513131e-04, 2.46976669e-04, 3.12446247e-04,\n       3.91894872e-04, 4.87458671e-04, 6.01418745e-04, 7.36176320e-04,\n       8.94221082e-04, 1.07809287e-03, 1.29033709e-03, 1.53345446e-03,\n       1.80984608e-03, 2.12175469e-03, 2.47120375e-03, 2.85993547e-03,\n       3.28934966e-03, 3.76044489e-03, 4.27376371e-03, 4.82934367e-03,\n       5.42667558e-03, 6.06467049e-03, 6.74163671e-03, 7.45526780e-03,\n       8.20264221e-03, 8.98023517e-03, 9.78394280e-03, 1.06091183e-02,\n       1.14506199e-02, 1.23028689e-02, 1.31599185e-02, 1.40155299e-02,\n       1.48632553e-02, 1.56965267e-02, 1.65087471e-02, 1.72933829e-02,\n       1.80440569e-02, 1.87546371e-02, 1.94193228e-02, 2.00327240e-02,\n       2.05899334e-02, 2.10865900e-02, 2.15189332e-02, 2.18838456e-02,\n       2.21788856e-02, 2.24023082e-02, 2.25530744e-02, 2.26308494e-02,\n       2.26359903e-02, 2.25695232e-02, 2.24331117e-02, 2.22290160e-02,\n       2.19600460e-02, 2.16295072e-02, 2.12411427e-02, 2.07990708e-02,\n       2.03077207e-02, 1.97717674e-02, 1.91960659e-02, 1.85855868e-02,\n       1.79453549e-02, 1.72803893e-02, 1.65956486e-02, 1.58959797e-02,\n       1.51860721e-02, 1.44704168e-02, 1.37532717e-02, 1.30386314e-02,\n       1.23302039e-02, 1.16313925e-02, 1.09452822e-02, 1.02746328e-02,\n       9.62187584e-03, 8.98911581e-03, 8.37813608e-03, 7.79040788e-03,\n       7.22710252e-03, 6.68910621e-03, 6.17703697e-03, 5.69126329e-03,\n       5.23192396e-03, 4.79894878e-03, 4.39207963e-03, 4.01089173e-03,\n       3.65481458e-03, 3.32315248e-03, 3.01510427e-03, 2.72978220e-03,\n       2.46622966e-03, 2.22343774e-03, 2.00036051e-03, 1.79592895e-03,\n       1.60906347e-03, 1.43868513e-03, 1.28372539e-03, 1.14313469e-03,\n       1.01588959e-03, 9.00998868e-04, 7.97508392e-04, 7.04504983e-04,\n       6.21119324e-04, 5.46527997e-04, 4.79954753e-04, 4.20671090e-04,\n       3.67996234e-04, 3.21296615e-04, 2.79984893e-04, 2.43518640e-04,\n       2.11398721e-04, 1.83167447e-04, 1.58406561e-04, 1.36735100e-04,\n       1.17807178e-04, 1.01309743e-04, 8.69603151e-05, 7.45047632e-05,\n       6.37151229e-05, 5.43874847e-05, 4.63399643e-05, 3.94107684e-05,\n       3.34563618e-05, 2.83497444e-05, 2.39788382e-05, 2.02449877e-05,\n       1.70615715e-05, 1.43527239e-05, 1.20521627e-05, 1.01021187e-05,\n       8.45236352e-06, 7.05932833e-06, 5.88530977e-06, 4.89775584e-06,\n       4.06862663e-06, 3.37382385e-06, 2.79268342e-06, 2.30752564e-06,\n       1.90325772e-06, 1.56702355e-06, 1.28789616e-06, 1.05660835e-06,\n       8.65317463e-07, 7.07400621e-07, 5.77276873e-07, 4.70253209e-07,\n       3.82391576e-07, 3.10394327e-07, 2.51505816e-07, 2.03428079e-07,\n       1.64248758e-07, 1.32379662e-07, 1.06504505e-07, 8.55345762e-08,\n       6.85712161e-08, 5.48741394e-08, 4.38347517e-08, 3.49537264e-08,\n       2.78222071e-08, 2.21060841e-08, 1.75328730e-08, 1.38807903e-08,\n       1.09696773e-08, 8.65347796e-09, 6.81401768e-09, 5.35586960e-09,\n       4.20212790e-09, 3.29093530e-09, 2.57263634e-09, 2.00744899e-09,\n       1.56356409e-09, 1.21559750e-09, 9.43332170e-10, 7.30698008e-10,\n       5.64946377e-10, 4.35983498e-10, 3.35833320e-10, 2.58205631e-10,\n       1.98149511e-10, 1.51775874e-10, 1.16035767e-10, 8.85436157e-11,\n       6.74365902e-11, 5.12629436e-11, 3.88935476e-11, 2.94519483e-11,\n       2.22591821e-11, 1.67903286e-11, 1.26403763e-11, 9.49746021e-12,\n       7.12192435e-12, 5.32997545e-12, 3.98094779e-12, 2.96740259e-12,\n       2.20744722e-12, 1.63878901e-12, 1.21414193e-12, 8.97685574e-13,\n       6.62341433e-13, 4.87682118e-13, 3.58329975e-13, 2.62733129e-13,\n       1.92232021e-13, 1.40349038e-13, 1.02249074e-13, 7.43307958e-14,\n       5.39176125e-14, 3.90245404e-14, 2.81827129e-14, 2.03075722e-14,\n       1.46000906e-14, 1.04729084e-14, 7.49522901e-15, 5.35179816e-15,\n       3.81243869e-15, 2.70947511e-15, 1.92104334e-15, 1.35877990e-15,\n       9.58762316e-16, 6.74857875e-16, 4.73851764e-16, 3.31887164e-16,\n       2.31870120e-16, 1.61582277e-16, 1.12311730e-16, 7.78621555e-17,\n       5.38374740e-17, 3.71267115e-17, 2.55339502e-17, 1.75131770e-17,\n       1.19787769e-17, 8.17043769e-18, 5.55709266e-18, 3.76879952e-18,\n       2.54855814e-18, 1.71832217e-18, 1.15508773e-18, 7.74117358e-19,\n       5.17202403e-19, 3.44473533e-19, 2.28702927e-19, 1.51351337e-19,\n       9.98336096e-20, 6.56326091e-20, 4.30021754e-20, 2.80778303e-20,\n       1.82689038e-20, 1.18443065e-20, 7.65114122e-21, 4.92416104e-21,\n       3.15715907e-21, 2.01644437e-21, 1.28282538e-21, 8.12839483e-22,\n       5.12933201e-22, 3.22327027e-22, 2.01684180e-22, 1.25644513e-22,\n       7.79232658e-23, 4.81056236e-23, 2.95583699e-23, 1.80746298e-23,\n       1.09978648e-23, 6.65794638e-24, 4.00963717e-24, 2.40181424e-24,\n       1.43079220e-24, 8.47512449e-25, 4.99083936e-25, 2.92132887e-25,\n       1.69935254e-25, 9.82187999e-26, 5.63923962e-26, 3.21560203e-26,\n       1.82060121e-26, 1.02321429e-26, 5.70688390e-27, 3.15781054e-27,\n       1.73297995e-27, 9.42928227e-28, 5.08498046e-28, 2.71683649e-28,\n       1.43756895e-28, 7.53010288e-29, 3.90287066e-29, 2.00064244e-29,\n       1.01375754e-29, 5.07505144e-30, 2.50862132e-30, 1.22362290e-30,\n       5.88557675e-31, 2.78965569e-31, 1.30197262e-31, 5.97844994e-32,\n       2.69855094e-32, 1.19624159e-32, 5.20250323e-33, 2.21734910e-33,\n       9.25053228e-34, 3.77265600e-34, 1.50196640e-34, 5.82814726e-35,\n       2.20046071e-35, 8.06834571e-36, 2.86697422e-36, 9.84919624e-37,\n       3.26251408e-37, 1.03885909e-37, 3.16883210e-38, 9.22211409e-39,\n       2.54864554e-39, 6.65165425e-40, 1.62861878e-40, 3.71111060e-41,\n       7.79309411e-42, 1.48963754e-42, 2.55117602e-43, 3.83352119e-44,\n       4.91076342e-45, 5.14310568e-46, 4.12239382e-47, 2.24324120e-48,\n       6.19883875e-50]), 22: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n       0.00000000e+00, 6.52766502e-40, 2.18801325e-38, 3.86153259e-37,\n       4.86487333e-36, 4.93607282e-35, 4.28030703e-34, 3.28244029e-33,\n       2.27656805e-32, 1.45056144e-31, 8.58877239e-31, 4.76700481e-30,\n       2.49715410e-29, 1.24138844e-28, 5.88270452e-28, 2.66729256e-27,\n       1.16078440e-26, 4.86163220e-26, 1.96410102e-25, 7.66950415e-25,\n       2.89971338e-24, 1.06316296e-23, 3.78528451e-23, 1.31033941e-22,\n       4.41502647e-22, 1.44936332e-21, 4.63985839e-21, 1.44966888e-20,\n       4.42375567e-20, 1.31936655e-19, 3.84822966e-19, 1.09830998e-18,\n       3.06891611e-18, 8.39946154e-18, 2.25277960e-17, 5.92334659e-17,\n       1.52744073e-16, 3.86426109e-16, 9.59442857e-16, 2.33861429e-15,\n       5.59773949e-15, 1.31613802e-14, 3.04045080e-14, 6.90286189e-14,\n       1.54055174e-13, 3.38045766e-13, 7.29488662e-13, 1.54843573e-12,\n       3.23358061e-12, 6.64463819e-12, 1.34380052e-11, 2.67516529e-11,\n       5.24316522e-11, 1.01189849e-10, 1.92332730e-10, 3.60092406e-10,\n       6.64187319e-10, 1.20713082e-09, 2.16210503e-09, 3.81706887e-09,\n       6.64334503e-09, 1.14004259e-08, 1.92933592e-08, 3.22050199e-08,\n       5.30330015e-08, 8.61698589e-08, 1.38175950e-07, 2.18705952e-07,\n       3.41762817e-07, 5.27365723e-07, 8.03730548e-07, 1.21007105e-06,\n       1.80013489e-06, 2.64658891e-06, 3.84636092e-06, 5.52702898e-06,\n       7.85432202e-06, 1.10407568e-05, 1.53553854e-05, 2.11345656e-05,\n       2.87935923e-05, 3.88389510e-05, 5.18808663e-05, 6.86457377e-05,\n       8.99879733e-05, 1.16900664e-04, 1.50524485e-04, 1.92154182e-04,\n       2.43241981e-04, 3.05397296e-04, 3.80382124e-04, 4.70101642e-04,\n       5.76589573e-04, 7.01988068e-04, 8.48521979e-04, 1.01846758e-03,\n       1.21411602e-03, 1.43773182e-03, 1.69150732e-03, 1.97751352e-03,\n       2.29764870e-03, 2.65358557e-03, 3.04671855e-03, 3.47811225e-03,\n       3.94845263e-03, 4.45800224e-03, 5.00656080e-03, 5.59343241e-03,\n       6.21740051e-03, 6.87671145e-03, 7.56906762e-03, 8.29163049e-03,\n       9.04103392e-03, 9.81340780e-03, 1.06044118e-02, 1.14092787e-02,\n       1.22228666e-02, 1.30397193e-02, 1.38541334e-02, 1.46602306e-02,\n       1.54520351e-02, 1.62235522e-02, 1.69688496e-02, 1.76821365e-02,\n       1.83578421e-02, 1.89906893e-02, 1.95757646e-02, 2.01085807e-02,\n       2.05851328e-02, 2.10019463e-02, 2.13561156e-02, 2.16453335e-02,\n       2.18679116e-02, 2.20227896e-02, 2.21095370e-02, 2.21283433e-02,\n       2.20800012e-02, 2.19658806e-02, 2.17878958e-02, 2.15484657e-02,\n       2.12504687e-02, 2.08971929e-02, 2.04922836e-02, 2.00396867e-02,\n       1.95435927e-02, 1.90083785e-02, 1.84385513e-02, 1.78386924e-02,\n       1.72134049e-02, 1.65672626e-02, 1.59047635e-02, 1.52302872e-02,\n       1.45480562e-02, 1.38621021e-02, 1.31762365e-02, 1.24940271e-02,\n       1.18187785e-02, 1.11535171e-02, 1.05009821e-02, 9.86361884e-03,\n       9.24357838e-03, 8.64271900e-03, 8.06261205e-03, 7.50455052e-03,\n       6.96956017e-03, 6.45841294e-03, 5.97164200e-03, 5.50955835e-03,\n       5.07226838e-03, 4.65969211e-03, 4.27158177e-03, 3.90754053e-03,\n       3.56704097e-03, 3.24944308e-03, 2.95401177e-03, 2.67993342e-03,\n       2.42633168e-03, 2.19228208e-03, 1.97682562e-03, 1.77898121e-03,\n       1.59775687e-03, 1.43215979e-03, 1.28120514e-03, 1.14392387e-03,\n       1.01936922e-03, 9.06622353e-04, 8.04796859e-04, 7.13042432e-04,\n       6.30547649e-04, 5.56541999e-04, 4.90297202e-04, 4.31127923e-04,\n       3.78391932e-04, 3.31489794e-04, 2.89864163e-04, 2.52998731e-04,\n       2.20416901e-04, 1.91680242e-04, 1.66386768e-04, 1.44169097e-04,\n       1.24692519e-04, 1.07653023e-04, 9.27752967e-05, 7.98107438e-05,\n       6.85355256e-05, 5.87486550e-05, 5.02701544e-05, 4.29392894e-05,\n       3.66128868e-05, 3.11637447e-05, 2.64791369e-05, 2.24594141e-05,\n       1.90167038e-05, 1.60737057e-05, 1.35625820e-05, 1.14239397e-05,\n       9.60590049e-06, 8.06325373e-06, 6.75668955e-06, 5.65210545e-06,\n       4.71998242e-06, 3.93482520e-06, 3.27466197e-06, 2.72059836e-06,\n       2.25642133e-06, 1.86824821e-06, 1.54421691e-06, 1.27421305e-06,\n       1.04963039e-06, 8.63161112e-07, 7.08612658e-07, 5.80748223e-07,\n       4.75148236e-07, 3.88090340e-07, 3.16445690e-07, 2.57589566e-07,\n       2.09324517e-07, 1.69814443e-07, 1.37528189e-07, 1.11191401e-07,\n       8.97455219e-08, 7.23129612e-08, 5.81675628e-08, 4.67096344e-08,\n       3.74448759e-08, 2.99666380e-08, 2.39410198e-08, 1.90943772e-08,\n       1.52028751e-08, 1.20837690e-08, 9.58814434e-09, 7.59488327e-09,\n       6.00566201e-09, 4.74081153e-09, 3.73589974e-09, 2.93891534e-09,\n       2.30795227e-09, 1.80930972e-09, 1.41593637e-09, 1.10615909e-09,\n       8.62646165e-10, 6.71563659e-10, 5.21890169e-10, 4.04861472e-10,\n       3.13521314e-10, 2.42358785e-10, 1.87016207e-10, 1.44054264e-10,\n       1.10763559e-10, 8.50137221e-11, 6.51328128e-11, 4.98111477e-11,\n       3.80247453e-11, 2.89745144e-11, 2.20380439e-11, 1.67314577e-11,\n       1.26792949e-11, 9.59077339e-12, 7.24112214e-12, 5.45692809e-12,\n       4.10465808e-12, 3.08168543e-12, 2.30928873e-12, 1.72720030e-12,\n       1.28936985e-12, 9.60679065e-13, 7.14398765e-13, 5.30224784e-13,\n       3.92763918e-13, 2.90369171e-13, 2.14245532e-13, 1.57764843e-13,\n       1.15941939e-13, 8.50349177e-14, 6.22407485e-14, 4.54639643e-14,\n       3.31412449e-14, 2.41086683e-14, 1.75014568e-14, 1.26784234e-14,\n       9.16515248e-15, 6.61135755e-15, 4.75894867e-15, 3.41816902e-15,\n       2.44980029e-15, 1.75192190e-15, 1.25007988e-15, 8.90003193e-16,\n       6.32219253e-16, 4.48082047e-16, 3.16848831e-16, 2.23533289e-16,\n       1.57332470e-16, 1.10476726e-16, 7.73908207e-17, 5.40833960e-17,\n       3.77036684e-17, 2.62202838e-17, 1.81892138e-17, 1.25863992e-17,\n       8.68736394e-18, 5.98082348e-18, 4.10683758e-18, 2.81264127e-18,\n       1.92117844e-18, 1.30874013e-18, 8.89112745e-19, 6.02369266e-19,\n       4.06963696e-19, 2.74169560e-19, 1.84177575e-19, 1.23364693e-19,\n       8.23879476e-20, 5.48575715e-20, 3.64158384e-20, 2.40993285e-20,\n       1.58986330e-20, 1.04552253e-20, 6.85335955e-21, 4.47761813e-21,\n       2.91568104e-21, 1.89215834e-21, 1.22369599e-21, 7.88608135e-22,\n       5.06398717e-22, 3.23995061e-22, 2.06522912e-22, 1.31144620e-22,\n       8.29568175e-23, 5.22683274e-23, 3.28000176e-23, 2.04984463e-23,\n       1.27567471e-23, 7.90478437e-24, 4.87672455e-24, 2.99508776e-24,\n       1.83099376e-24, 1.11406552e-24, 6.74573518e-25, 4.06432163e-25,\n       2.43629485e-25, 1.45276192e-25, 8.61625497e-26, 5.08200922e-26,\n       2.98040230e-26, 1.73765177e-26, 1.00697989e-26, 5.79917766e-27,\n       3.31827420e-27, 1.88610556e-27, 1.06470628e-27, 5.96760657e-28,\n       3.32022376e-28, 1.83322158e-28, 1.00419848e-28, 5.45569547e-29,\n       2.93878313e-29, 1.56900406e-29, 8.29970690e-30, 4.34827332e-30,\n       2.25532465e-30, 1.15758013e-30, 5.87682184e-31, 2.94964982e-31,\n       1.46287859e-31, 7.16497798e-32, 3.46364531e-32, 1.65154463e-32,\n       7.76235860e-33, 3.59361796e-33, 1.63746349e-33, 7.33763047e-34,\n       3.23073511e-34, 1.39635537e-34, 5.91827421e-35, 2.45707185e-35,\n       9.98027390e-36, 3.96096153e-36, 1.53380821e-36, 5.78590907e-37,\n       2.12251017e-37, 7.55738154e-38, 2.60619183e-38, 8.68384609e-39,\n       2.78812198e-39, 8.59939586e-40, 2.53892010e-40, 7.14638104e-41,\n       1.90861005e-41, 4.80964198e-42, 1.13599514e-42, 2.49463966e-43,\n       5.04321743e-44, 9.27031092e-45, 1.52500211e-45, 2.19851465e-46,\n       2.69875076e-47, 2.70529566e-48, 2.07321187e-49, 1.07763281e-50,\n       2.84250858e-52])}\n\n\n\n\n6.4.3 Experimental Design\nWe will use the trained XGBoost Regressor model to guide a local search algorithm to find the best schedule. The local search algorithm will start with an initial schedule and iteratively explore the neighborhood of the current schedule to find a better one. As an initial schedule, we will use the schedule with the lowest objective value from the training dataset that was used to train the XGBoost Regressor model.\n\n\n6.4.4 Variables\n\nIndependent Variables:\n\nThe trained XGBoost Regressor model.\n\nDependent Variables:\n\nSpeed, accuracy, and convergence of the local search algorithm.\n\n\n\n\n6.4.5 Data Collection\nWe will use the training dataset to initialize the local search algorithm.\n\n\n6.4.6 Sample Size and Selection\n\n\n6.4.7 Experimental Procedure\n\n\n\n\n\n\nFigure 6.1: Local search algorithm",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html#results",
    "href": "local-search-regressor-large.html#results",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "6.5 Results",
    "text": "6.5 Results\n\n6.5.1 Load the initial best schedule.\nStart with the best solution found so far \\(\\{x^*, C(x^*)\\}\\) from the training set.\n\n# Load the best solution from the training dataset\nfile_path_schedules = f\"datasets/neighbors_and_objectives_{N}_{T}_{l}.pkl\"\n# Load the data from the pickle file\nwith open(file_path_schedules, 'rb') as f:\n    data_sch = pickle.load(f)\n    \nprint(f\"The data has following keys: {[key for key in data_sch.keys()]}\")\n\n# Step 1: Flatten the objectives into a 1D array\nflattened_data = [value for sublist in data_sch['objectives'] for value in sublist]\n\n# Step 2: Find the index of the minimum value\nmin_index = np.argmin(flattened_data)\n\n# Step 3: Convert that index back to the original 2D structure\nrow_index = min_index // 2  # Assuming each inner list has 2 values\ncol_index = min_index % 2\n\nprint(f\"The minimum objective value is at index [{row_index}][{col_index}].\\nThis is schedule: {data_sch['neighbors_list'][row_index][col_index]} with objective value {data_sch['objectives'][row_index][col_index]}.\")\n\n# Set the initial schedule to the best solution from the training dataset\ninitial_schedule = data_sch['neighbors_list'][row_index][col_index]\nN = sum(initial_schedule)\nT = len(initial_schedule)\n\nThe data has following keys: ['neighbors_list', 'objectives', 'rankings']\nThe minimum objective value is at index [4876][0].\nThis is schedule: [2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 4] with objective value 59.11487789997525.\n\n\n\n\n6.5.2 Generate the neighborhood of \\(x^*\\).\n\n6.5.2.1 Set T\nSet \\(T\\) to the length of the vector \\(x^*\\).\n\nT = len(initial_schedule)\n\n\n\n6.5.2.2 Define \\(V^*\\).\nDefine the vectors \\(V^*\\) as follows:\n\\[\n\\left\\{\n\\begin{array}{c}\n\\vec{v_1}, \\\\\n\\vec{v_2}, \\\\\n\\vec{v_3}, \\\\\n\\vdots \\\\\n\\vec{v_{T-1}}, \\\\\n\\vec{v_T} \\\\\n\\end{array}\n\\right\\} =\n\\left\\{\n\\begin{array}{c}\n(-1, 0,...., 0, 1), \\\\\n(1, -1, 0,...., 0), \\\\\n(0, 1, -1,...., 0), \\\\\n\\vdots \\\\\n(0,...., 1, -1, 0), \\\\\n(0,...., 0, 1, -1) \\\\\n\\end{array}\n\\right\\}\n\\]\n\ndef get_v_star(t):\n    # Create an initial vector 'u' of zeros with length 't'\n    u = np.zeros(t, dtype=int)\n    # Set the first element of vector 'u' to -1\n    u[0] = -1\n    # Set the last element of vector 'u' to 1\n    u[-1] = 1\n    # Initialize the list 'v_star' with the initial vector 'u'\n    v_star = [u]\n    # Loop over the length of 'u' minus one times\n    for i in range(len(u) - 1):\n        # Append the last element of 'u' to the front of 'u'\n        u = np.append(u[-1], u)\n        # Remove the last element of 'u' to maintain the same length\n        u = np.delete(u, -1)\n        # Append the updated vector 'u' to the list 'v_star'\n        v_star.append(u)\n    # Convert the list of vectors 'v_star' into a NumPy array and return it\n    return(np.array(v_star))\n\n# Example of function call:\n# This will create a 4x4 matrix where each row is a cyclically shifted version of the first row\nget_v_star(4)\n\narray([[-1,  0,  0,  1],\n       [ 1, -1,  0,  0],\n       [ 0,  1, -1,  0],\n       [ 0,  0,  1, -1]])\n\n\n\n\n6.5.2.3 Define \\(U_t\\).\nDefine \\(U_t\\) as the set of all possible subsets of \\(V^*\\) such that each subset contains exactly \\(t\\) elements, i.e.,\n\\[\nU_t = \\{ S \\subsetneq V^* \\mid |S| = t \\}, \\quad t \\in \\{1, 2, \\dots, T\\}.\n\\]\n\ndef powerset(iterable, size=1):\n    \"powerset([1,2,3], 2) --&gt; (1,2) (1,3) (2,3)\"\n    return [[i for i in item] for item in combinations(iterable, size)]\n  \nx = initial_schedule\n\n# Generate a matrix 'v_star' using the 'get_v_star' function\nv_star = get_v_star(T)\n\n# Generate all possible non-empty subsets (powerset) of the set {0, 1, 2, ..., t-1}\n# 'ids' will be a list of tuples, where each tuple is a subset of indices\nsize = 2\nids = powerset(range(T), size)\nlen(ids)\nids[:T]\n\n[[0, 1],\n [0, 2],\n [0, 3],\n [0, 4],\n [0, 5],\n [0, 6],\n [0, 7],\n [0, 8],\n [0, 9],\n [0, 10],\n [0, 11],\n [0, 12],\n [0, 13],\n [0, 14],\n [0, 15],\n [0, 16],\n [0, 17],\n [0, 18],\n [0, 19],\n [1, 2]]\n\n\n\n\n6.5.2.4 Define the neighborhood of \\(x\\)\nDefine the neighborhood of \\(x\\) as all vectors of the form \\(x + u_{tk}\\) with \\(\\forall \\, u_{tk} \\in U_t\\).\n\nv_star = get_v_star(T)\n\ndef get_neighborhood(x, v_star, ids, verbose=False):\n    x = np.array(x)\n    p = 50\n    if verbose:\n        print(f\"Printing every {p}th result\")\n    # Initialize the list 'neighborhood' to store the vectors in the neighborhood of 'x'\n    neighborhood = []\n    # Loop over all possible non-empty subsets of indices\n    for i in range(len(ids)):\n        # Initialize the vector 'neighbor' to store the sum of vectors in 'v_star' corresponding to the indices in 'ids[i]'\n        neighbor = np.zeros(len(x), dtype=int)\n        # Loop over all indices in 'ids[i]'\n        for j in range(len(ids[i])):\n            if verbose:\n                print(f\"v_star{[ids[i][j]]}: {v_star[ids[i][j]]}\")\n            # Add the vector in 'v_star' corresponding to the index 'ids[i][j]' to 'neighbor'\n            neighbor += v_star[ids[i][j]]\n        # Append the vector 'x' plus 'neighbor' to the list 'neighborhood'\n        x_n = x + neighbor\n        if i%p==0:\n            if verbose:\n                print(f\"x, x', delta:\\n{x},\\n{x_n},\\n{neighbor}\\n----------------- \")\n        neighborhood.append(x_n)\n    \n    # Convert the list 'neighborhood' into a NumPy array\n    neighborhood = np.array(neighborhood)\n    if verbose:\n        print(f\"Size of raw neighborhood: {len(neighborhood)}\")\n    # Create a mask for rows with negative values\n    mask = ~np.any(neighborhood &lt; 0, axis=1)\n    # Filter out rows with negative values using the mask\n    if verbose:\n        print(f\"filtered out: {len(neighborhood)-mask.sum()} schedules with negative values.\")\n    filtered_neighborhood = neighborhood[mask]\n    if verbose:\n        print(f\"Size of filtered neighborhood: {len(filtered_neighborhood)}\")\n    return filtered_neighborhood\n\n# Example of function call:\n# This will generate the neighborhood of the vector 'x' using the vectors in 'v_star' and the indices in 'ids'\ntest_nh = get_neighborhood(x, v_star, ids)\nprint(f\"All neighborhoods with {size} patients switched:\\n x = {np.array(x)}: \\n {test_nh}\")\n\nAll neighborhoods with 2 patients switched:\n x = [2 1 0 1 1 1 1 1 1 1 1 0 1 2 0 1 1 1 1 4]: \n [[2 0 0 ... 1 1 5]\n [1 1 1 ... 1 1 5]\n [1 1 0 ... 1 1 5]\n ...\n [2 1 0 ... 1 0 4]\n [2 1 0 ... 0 2 3]\n [2 1 0 ... 2 1 3]]\n\n\n\n\n\n6.5.3 Local search algorithm\n\nGenerate the neighborhood of \\(x^*\\).\nFor each vector \\(y\\) in the neighborhood of \\(x^*\\):\n\nPredict \\(C(y)\\).\nIf \\(C(y) &lt; C(x^*)\\), set \\(x^* = y\\) and go to 1\n\nReturn \\(x^*\\).\n\n\nfrom functions import calculate_objective_serv_time_lookup\n\ndef local_search_predicted(x, d, convolutions, w, v_star, regressor, size=2):\n    # Ensure x_star is a 1D numpy array\n    x_star = np.array(x).flatten()\n    c_star = regressor.predict(x_star.reshape(1, -1))[0]\n\n    solutions_list = []\n    predictions_list = []\n    objectives_list = []\n\n    # Set T as the length of x_star\n    T = len(x_star)\n\n    # Outer loop for t (number of patients switched)\n    t = 1\n    while t &lt; size:\n        print(f'Running local search {t}')\n        \n        # Generate neighborhood and use a generator to reduce memory usage\n        ids_gen = powerset(range(T), t)\n        neighborhood = get_neighborhood(x_star, v_star, ids_gen)\n        \n        # Collect neighbors\n        neighbors = []\n        for neighbor in neighborhood:\n            neighbors.append(neighbor)\n\n        neighbors_array = np.array(neighbors)\n        predicted_costs = regressor.predict(neighbors_array)\n\n        # Flag to track if we find a better solution\n        found_better_solution = False\n        \n        # Evaluate neighbors and update x_star and c_star\n        for i, (neighbor, cost) in enumerate(zip(neighbors, predicted_costs)):\n            if cost &lt; c_star:\n                x_star = neighbor\n                c_star = cost\n                objectives = calculate_objective_serv_time_lookup(x_star, d, convolutions)\n                objective_value = w * objectives[0] + (1 - w) * objectives[1]\n                print(f\"Found better solution: {x_star}, pred_cost: {c_star}, real_cost: {objective_value}\")\n                \n                # Update lists with the new best solution\n                solutions_list.append(x_star)\n                predictions_list.append(c_star)\n                objectives_list.append(objective_value)\n                \n                # Increase n_estimators\n                regressor.n_estimators += 5\n                # Fit with previous model\n                print(f\"Retraining on {len(solutions_list)} new schedules\")\n                regressor.fit(\n                    np.array(solutions_list),\n                    np.array(objectives_list),\n                    verbose=False\n                )\n\n                # Set flag to True and break out of inner loop\n                found_better_solution = True\n                break\n\n        # If we found a better solution, restart outer loop from t = 1\n        if found_better_solution:\n            t = 1  # Restart search with t = 1\n        else:\n            t += 1  # Move to next t value if no better solution was found\n\n    # Return the best solution found\n    return x_star, c_star, objective_value, solutions_list, predictions_list, objectives_list\n\n\ndef local_search(x, d, convolutions, w, v_star, size=2):\n    # Initialize the best solution found so far 'x_star' to the input vector 'x'\n    x_star = np.array(x).flatten()  # Keep as 1D array\n\n    # Calculate initial objectives and cost\n    objectives_star = calculate_objective_serv_time_lookup(x_star, d, convolutions)\n    c_star = w * objectives_star[0] + (1 - w) * objectives_star[1]\n\n    # Set the value of 'T' to the length of the input vector 'x'\n    T = len(x_star)\n\n    # Outer loop for the number of patients to switch\n    t = 1\n    while t &lt; size:\n        print(f'Running local search {t}')\n\n        # Generate the neighborhood of the current best solution 'x_star' with 't' patients switched\n        ids_gen = powerset(range(T), t)\n        neighborhood = get_neighborhood(x_star, v_star, ids_gen)\n        print(f\"Switching {t} patient(s). Size of neighborhood: {len(list(ids_gen))}\")\n\n        # Flag to track if a better solution is found\n        found_better_solution = False\n\n        for neighbor in neighborhood:\n            # Calculate objectives for the neighbor\n            objectives = calculate_objective_serv_time_lookup(neighbor, d, convolutions)\n            cost = w * objectives[0] + (1 - w) * objectives[1]\n\n            # Compare scalar costs\n            if cost &lt; c_star:\n                x_star = neighbor\n                c_star = cost\n                print(f\"Found better solution: {x_star}, cost: {c_star}\")\n\n                # Set the flag to restart the outer loop\n                found_better_solution = True\n                break  # Break out of the inner loop\n\n        # If a better solution was found, restart the search from t = 1\n        if found_better_solution:\n            t = 1  # Restart search with t = 1\n        else:\n            t += 1  # Move to the next neighborhood size if no better solution was found\n\n    # Return the best solution found 'x_star' and its cost\n    return x_star, c_star\n\n\n\n6.5.4 Run the local search algorithm\n\n# Example of using the local search algorithm with a regressor model\n# Load regressor model\n# Load parameters\nwith open('models/regressor_params.json', 'r') as f:\n    params = json.load(f)\nregressor = xgb.XGBRegressor(**params)\nregressor.load_model(\"models/regressor_large_instance.json\")\n# Check parameters\nprint(regressor.get_params())\n\ntest = local_search_predicted(initial_schedule, d, convolutions, w, v_star , regressor, T)\nprint(test[:3])\nprint(f\"Best solution found: {test[0]}, with predicted cost: {test[1]} and real cost: {test[2]}\")\n\n{'objective': 'reg:squarederror', 'base_score': '7.818584E1', 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'rmsle', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.15, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 7, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 900, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\nRunning local search 1\nFound better solution: [2 1 0 1 2 0 1 1 1 1 1 0 1 2 0 1 1 1 1 4], pred_cost: 59.150535583496094, real_cost: 59.35650821743148\nRetraining on 1 new schedules\nRunning local search 1\nRunning local search 2\nRunning local search 3\nRunning local search 4\nRunning local search 5\nRunning local search 6\nRunning local search 7\nRunning local search 8\nRunning local search 9\nRunning local search 10\nRunning local search 11\nRunning local search 12\nRunning local search 13\nRunning local search 14\nRunning local search 15\nRunning local search 16\nRunning local search 17\nRunning local search 18\nRunning local search 19\n(array([2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 4]), 59.150536, 59.35650821743148)\nBest solution found: [2 1 0 1 2 0 1 1 1 1 1 0 1 2 0 1 1 1 1 4], with predicted cost: 59.150535583496094 and real cost: 59.35650821743148\n\n\n\nimport plotly.graph_objects as go\n\n# Data for plotting\nsteps = list(range(len(test[4])))  # Convert range to list\npredicted_values = test[4]\nobjective_values = test[5]\n\n# Create the figure\nfig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(\n    x=steps, \n    y=predicted_values,\n    mode='lines',\n    name='Predicted Objective Value',\n))\n\nfig.add_trace(go.Scatter(\n    x=steps, \n    y=objective_values,\n    mode='lines',\n    name='True Objective Value',\n    marker=dict(size=6, symbol='circle')\n))\n\n# Add titles and labels\nfig.update_layout(\n    title='Cost of Best Solution at Each Iteration',\n    xaxis_title='Iteration',\n    yaxis_title='Cost',\n    legend_title='Cost Type',\n    plot_bgcolor='rgba(0,0,0,0)',  # Transparent background\n    xaxis=dict(showgrid=True, gridwidth=1, gridcolor='lightgray'),\n    yaxis=dict(showgrid=True, gridwidth=1, gridcolor='lightgray'),\n)\n\n# Show the plot\nfig.show()\nfig.write_html(\"images/objectives-large-comparison.html\")\n\n                                                \n\n\n\n# Computing optimal solution with real cost\nprint(f\"Initial schedule: {test[0]}\")\ntest_x = local_search(test[0], d, convolutions, w, v_star, T)\ntest_x_pred = np.array(test_x[0]).flatten()  # Keep as 1D array\ntest_c_star_pred = regressor.predict(test_x_pred.reshape(1, -1))[0]\nprint(f\"Best solution found: {test_x [0]}, with true cost: {test_x [1]}, and predicted cost: {test_c_star_pred}\")\n\nInitial schedule: [2 1 0 1 2 0 1 1 1 1 1 0 1 2 0 1 1 1 1 4]\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 0 2 0 1 1 1 1 1 0 1 2 0 1 1 1 1 4], cost: 59.10512529471494\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 1 1 0 1 1 1 1 1 0 1 2 0 1 1 1 1 4], cost: 58.723392522826074\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 1 1 0 1 1 1 1 1 1 0 2 0 1 1 1 1 4], cost: 58.7196462066003\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 4], cost: 58.61919862472588\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 4], cost: 58.600845129827505\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nRunning local search 2\nSwitching 2 patient(s). Size of neighborhood: 190\nRunning local search 3\nSwitching 3 patient(s). Size of neighborhood: 1140\nRunning local search 4\nSwitching 4 patient(s). Size of neighborhood: 4845\nRunning local search 5\nSwitching 5 patient(s). Size of neighborhood: 15504\nRunning local search 6\nSwitching 6 patient(s). Size of neighborhood: 38760\nRunning local search 7\nSwitching 7 patient(s). Size of neighborhood: 77520\nRunning local search 8\nSwitching 8 patient(s). Size of neighborhood: 125970\nRunning local search 9\nSwitching 9 patient(s). Size of neighborhood: 167960\nRunning local search 10\nSwitching 10 patient(s). Size of neighborhood: 184756\nRunning local search 11\nSwitching 11 patient(s). Size of neighborhood: 167960\nRunning local search 12\nSwitching 12 patient(s). Size of neighborhood: 125970\nRunning local search 13\nSwitching 13 patient(s). Size of neighborhood: 77520\nFound better solution: [2 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 4], cost: 58.55115322846101\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 4], cost: 58.46526491320927\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 4], cost: 58.440262127807806\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nFound better solution: [2 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 4], cost: 58.40282774316313\nRunning local search 1\nSwitching 1 patient(s). Size of neighborhood: 20\nRunning local search 2\nSwitching 2 patient(s). Size of neighborhood: 190\nRunning local search 3\nSwitching 3 patient(s). Size of neighborhood: 1140\nRunning local search 4\nSwitching 4 patient(s). Size of neighborhood: 4845\nRunning local search 5\nSwitching 5 patient(s). Size of neighborhood: 15504\nRunning local search 6\nSwitching 6 patient(s). Size of neighborhood: 38760\nRunning local search 7\nSwitching 7 patient(s). Size of neighborhood: 77520\nRunning local search 8\nSwitching 8 patient(s). Size of neighborhood: 125970\nRunning local search 9\nSwitching 9 patient(s). Size of neighborhood: 167960\nRunning local search 10\nSwitching 10 patient(s). Size of neighborhood: 184756\nRunning local search 11\nSwitching 11 patient(s). Size of neighborhood: 167960\nRunning local search 12\nSwitching 12 patient(s). Size of neighborhood: 125970\nRunning local search 13\nSwitching 13 patient(s). Size of neighborhood: 77520\nRunning local search 14\nSwitching 14 patient(s). Size of neighborhood: 38760\nRunning local search 15\nSwitching 15 patient(s). Size of neighborhood: 15504\nRunning local search 16\nSwitching 16 patient(s). Size of neighborhood: 4845\nRunning local search 17\nSwitching 17 patient(s). Size of neighborhood: 1140\nRunning local search 18\nSwitching 18 patient(s). Size of neighborhood: 190\nRunning local search 19\nSwitching 19 patient(s). Size of neighborhood: 20\nBest solution found: [2 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 4], with true cost: 58.40282774316313, and predicted cost: 59.356529235839844",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html#discussion",
    "href": "local-search-regressor-large.html#discussion",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "6.6 Discussion",
    "text": "6.6 Discussion\nAnalyze your results in this section. Discuss whether your hypothesis was supported, what the results mean, and the implications for future work. Address any anomalies or unexpected findings, and consider the broader impact of your results.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html#timeline",
    "href": "local-search-regressor-large.html#timeline",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "6.7 Timeline",
    "text": "6.7 Timeline\nDocument the duration and key dates of the experiment. This helps in project management and reproducibility.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "local-search-regressor-large.html#references",
    "href": "local-search-regressor-large.html#references",
    "title": "6  Large instance local search with trained XGBoost regressor model",
    "section": "6.8 References",
    "text": "6.8 References\nCite all sources that informed your experiment, including research papers, datasets, and tools. This section ensures that your work is properly grounded in existing research and that others can trace the origins of your methods and data.s",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Large instance local search with trained XGBoost regressor model</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html",
    "href": "appointment-scheduling-heuristics.html",
    "title": "7  Appointment scheduling heuristics",
    "section": "",
    "text": "7.1 Objective\nIn this experiment, we will test the validity of existing appointment scheduling heuristics by evaluating several instances of scheduling systems and analyzing the results. We will examine the performance of different scheduling strategies and compare them to the heuristics proposed in the literature. The goal is to find quasi optimal schedules that form a good starting point for further optimization using for instance local search algorithms.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html#background",
    "href": "appointment-scheduling-heuristics.html#background",
    "title": "7  Appointment scheduling heuristics",
    "section": "7.2 Background",
    "text": "7.2 Background\nThe extensive body of research on appointment scheduling offers valuable heuristics for designing schedules that are likely close to optimal. In their seminal work, Welch et al. (1952)1 established the following rule: schedule two patients at the beginning of the day to minimize the risk of idle time if one patient does not show up. The remaining patients should then be scheduled at intervals equal to the mean consultation time.\n\n\n\n‘Dome’ shapes of appointment schedules. From Robinson and Chen (2003)2\n\n\nRobinson and Chen (2003)3 explored the structure of optimal schedules. In their model, the length of intervals could be adjusted to accommodate different job allowances. Their findings include the following general observations:\n\nJob allowances follow a ‘dome’ pattern, with more time allotted to patients in the middle of the day.\nThe first job allowance is consistently much lower than the subsequent ones, while the final job allowance is also somewhat lower than the others.\nIntermediate job allowances are generally uniform.\n\nKlassen and Yoogalingam (2009)4 observed a plateau form when appointment intervals are restricted to integers.\nIn our model, all interval times are fixed integers, but job allowances can be adjusted by overbooking or underbooking selected service intervals. We examined the extent to which the above rules apply to our model definition.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html#methodology",
    "href": "appointment-scheduling-heuristics.html#methodology",
    "title": "7  Appointment scheduling heuristics",
    "section": "7.3 Methodology",
    "text": "7.3 Methodology\n\n7.3.1 Tools and Materials\n\nimport itertools\nfrom joblib import Parallel, delayed\nimport networkx as nx\nimport plotly.graph_objects as go\nimport numpy as np\nfrom typing import List, Tuple\nimport plotly.subplots as sp\nfrom plotly.subplots import make_subplots\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\nimport math\nfrom functions import create_random_schedules, calculate_objective, compute_convolutions, local_search, get_v_star, powerset, get_neighborhood, build_welch_bailey_schedule, service_time_with_no_shows, create_schedule_network, create_schedule_network_var_edges, create_schedule_network_from_lists, local_search_w_intermediates, build_quasi_optimal_schedule\n\n\n\n7.3.2 Experimental Design\nWe have developed a function that uses the Bailey-Welch rule to create a initial schedule.\ndef build_welch_bailey_schedule(N, T):\n    \"\"\"\n    Build a schedule based on the Welch and Bailey (1952) heuristic.\n\n    Parameters:\n    N (int): Number of patients to be scheduled.\n    T (int): Number of time intervals in the schedule.\n\n    Returns:\n    list: A schedule of length T where each item represents the number of patients scheduled\n          at the corresponding time interval.\n    \"\"\"\n    # Initialize the schedule with zeros\n    schedule = [0] * T\n\n    # Schedule the first two patients at the beginning\n    schedule[0] = 2\n    remaining_patients = N - 2\n\n    # Distribute patients in the middle time slots with gaps\n    for t in range(1, T - 1):\n        if remaining_patients &lt;= 0:\n            break\n        if t % 2 == 1:  # Create gaps (only schedule patients at odd time slots)\n            schedule[t] = 1\n            remaining_patients -= 1\n\n    # Push any remaining patients to the last time slot\n    schedule[-1] += remaining_patients\n\n    return schedule\nWe will compare the performance of the Bailey-Welch heuristic with the performance of a schedule generated by a local search algorithm. The local search algorithm will start from the Bailey-Welch schedule and iteratively improve it by swapping patients between time slots to reduce the patients’ waiting time and physician’s overtime.\n\n\n7.3.3 Variables\n\nIndependent Variables:\n\nDifferent schedule designs with increasingly large instances (lengths and number of patients).\n\nDependent Variables:\n\nObjective function value (weighted sum of average waiting time and physician’s overtime) for each schedule.\nComputation times\n\n\n\n\n7.3.4 Samples\nWe will generate several schedules with different lengths (\\(T\\)), numbers of patients (\\(N\\)) and weights for patients’ waiting time (\\(w\\)) relatively to overtime.\n\\[\nN \\in \\{16, \\dots , 22\\}\n\\] \\[\nT \\in \\{15, \\dots , 20\\}\n\\] \\[\nw \\in \\{0.1, 0,9\\}\n\\] This means that the total solution space varies between 13 mln and 244 bln schedules. The challenge is to find the optimal schedules within these vast solution spaces.\n\n\n# Graph representation of an appointment schedule\n\n# Define parameters\nN = 4  # Number of patients\nT = 3  # Number of time intervals\ns = [0.3, 0.2, 0.1, 0.05, 0.15, 0.2]  # Example service time probability distribution\nd = 2  # Duration threshold\nq = 0.1  # No-show probability\nw = 0.5  # Weight for waiting time in the objective\n\n# Create and visualize the network\nfig = create_schedule_network(N=N, T=T, s=s, d=d, q=q, w=w, echo=True)\nfig.show()\n\nSchedule: (0, 0, 4), Objective: 4.36, Expected mean waiting time: 11.61, Expected spillover time: 5.81\nSchedule: (0, 1, 3), Objective: 3.43, Expected mean waiting time: 8.37, Expected spillover time: 4.77\nSchedule: (0, 2, 2), Objective: 3.21, Expected mean waiting time: 8.42, Expected spillover time: 4.31\nSchedule: (0, 3, 1), Objective: 3.28, Expected mean waiting time: 9.79, Expected spillover time: 4.12\nSchedule: (0, 4, 0), Objective: 3.48, Expected mean waiting time: 11.61, Expected spillover time: 4.06\nSchedule: (1, 0, 3), Objective: 2.86, Expected mean waiting time: 6.35, Expected spillover time: 4.14\nSchedule: (1, 1, 2), Objective: 2.44, Expected mean waiting time: 5.58, Expected spillover time: 3.48\nSchedule: (1, 2, 1), Objective: 2.43, Expected mean waiting time: 6.64, Expected spillover time: 3.21\nSchedule: (1, 3, 0), Objective: 2.60, Expected mean waiting time: 8.37, Expected spillover time: 3.11\nSchedule: (2, 0, 2), Objective: 2.36, Expected mean waiting time: 6.03, Expected spillover time: 3.20\nSchedule: (2, 1, 1), Objective: 2.27, Expected mean waiting time: 6.79, Expected spillover time: 2.85\nSchedule: (2, 2, 0), Objective: 2.41, Expected mean waiting time: 8.42, Expected spillover time: 2.72\nSchedule: (3, 0, 1), Objective: 2.40, Expected mean waiting time: 8.24, Expected spillover time: 2.75\nSchedule: (3, 1, 0), Objective: 2.52, Expected mean waiting time: 9.79, Expected spillover time: 2.59\nSchedule: (4, 0, 0), Objective: 2.74, Expected mean waiting time: 11.61, Expected spillover time: 2.57\n\n\n                                                \n\n\n\n\n\n7.3.5 Experimental Procedure\nWe will evaluate multiple schedules using the Bailey-Welch heuristic and a local search algorithm, complemented by visualizations to compare their structures. Additionally, we will analyze computation times to assess the practical feasibility of the local search algorithm for large-scale instances.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html#results",
    "href": "appointment-scheduling-heuristics.html#results",
    "title": "7  Appointment scheduling heuristics",
    "section": "7.4 Results",
    "text": "7.4 Results\nWe began with a set of relatively small instances, keeping the number of intervals fixed while varying the number of patients. For each instance, we applied the local search algorithm and compared the resulting optimized schedules to the initial ones. The initial schedules, generated using the Bailey-Welch heuristic, are depicted as blue dotted lines, while the optimized schedules obtained through local search are shown as red solid lines.\n\nfrom functions import create_random_schedules, calculate_objective, compute_convolutions, local_search, get_v_star, powerset, get_neighborhood, build_welch_bailey_schedule\n\n# Assuming the necessary functions are defined elsewhere:\n# get_v_star, build_welch_bailey_schedule, compute_convolutions, local_search\n\n# Parameters\nN = range(16, 20)\nT = 15\ns = [0.3, 0.2, 0.1, 0.05, 0.15, 0.2]  # Example service time probability distribution\nd = 2  # Duration threshold\nq = 0.1  # No-show probability\nw = 0.1  # Weight for waiting time in the objective\nv_star = get_v_star(T)\n\n# Lists to store results\nx_stars = []\nx_initials = []  # To store initial schedules\nobj_vals = []\nschedules_list, objectives_list = [], []\n\n# Iterate over each n in N\nstart = time.time()\nfor n in N:\n    print(f'Running local search for schedule with N={n}')\n    x = build_welch_bailey_schedule(n, T)\n    x_initials.append(x)  # Store the initial schedule\n    convolutions = compute_convolutions(s, n, q)\n    schedules, objectives = local_search_w_intermediates(x, d, convolutions, w, v_star, T)\n    #x_star, obj = local_search(x, d, q, convolutions, w, v_star, T)\n    obj_vals.append(objectives[-1])\n    x_stars.append(schedules[-1])\n    schedules_list.append(schedules)\n    objectives_list.append(objectives)\nend = time.time()\nprint(\"Optimized schedules:\", x_stars)\nprint(\"Objective values:\", obj_vals)\nprint(f\"Search time: {end - start:.2f} seconds\")\n\nRunning local search for schedule with N=16\nTotal evaluations: 36913\nRunning local search for schedule with N=17\nTotal evaluations: 33123\nRunning local search for schedule with N=18\nTotal evaluations: 33123\nRunning local search for schedule with N=19\nTotal evaluations: 33123\nOptimized schedules: [[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3], [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]]\nObjective values: [10.209161916511897, 12.537501602843756, 15.121828179211807, 17.927771231270906]\nSearch time: 57.26 seconds\n\n\n\n# Number of subplots needed\nnum_subplots = len(x_stars)\n\n# Create a subplot figure with one chart per subplot\nfig = sp.make_subplots(\n    rows=num_subplots, \n    cols=1, \n    shared_xaxes=True, \n    subplot_titles=[f'n = {n}' for n in N]\n)\n\n# Add each initial and optimized schedule to its respective subplot\nfor idx, (x_initial, x_star) in enumerate(zip(x_initials, x_stars)):\n    # Add initial schedule as a dotted line\n    fig.add_trace(\n        go.Scatter(\n            x=list(range(T)), \n            y=x_initial, \n            mode='lines', \n            name='Initial schedule' if idx == 0 else None,  # Show legend only once\n            line=dict(dash='dot', color='blue')\n        ), \n        row=idx + 1, \n        col=1\n    )\n    \n    # Add optimized schedule as a solid line with markers\n    fig.add_trace(\n        go.Scatter(\n            x=list(range(T)), \n            y=x_star, \n            mode='lines+markers', \n            name='Optimized schedule' if idx == 0 else None,  # Show legend only once\n            line=dict(color='red')\n        ), \n        row=idx + 1, \n        col=1\n    )\n\n# Update layout properties\nfig.update_layout(\n    height=600 * num_subplots,  # Adjust height based on the number of subplots\n    title=dict(\n        text=f\"Optimal schedules across different values of N\\n(T={T}, w={w})\",\n        x=0.5,  # Center the title horizontally\n        # y=0.95,  # Adjust the vertical position (closer to the top)\n        font=dict(size=20),  # Optional: Adjust title font size\n        pad=dict(b=50)  # Add padding at the top of the title\n    ),\n    xaxis_title=\"Time slot (x)\",\n    yaxis_title=\"# of patients (y)\",\n    template=\"plotly_white\",\n    showlegend=False  # Enable legend to distinguish between initial and optimized schedules\n)\n\n# Set consistent y-axis ticks for each subplot\nfor i in range(1, num_subplots + 1):\n    fig.update_yaxes(tickmode='linear', tick0=0, dtick=1, row=i, col=1)\n\n# Optionally, adjust the legend position\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.02,\n    xanchor=\"right\",\n    x=1\n))\n\n# Show the Plotly figure\nfig.show()\n\n                                                \n\n\nSubsequently we’ve analyzed the number of steps required for the local search algorithm to transition from the initial schedule to the optimal schedule, as well as the characteristics of the search paths. To accomplish this, we’ve recorded and visualized the search paths using graph representations for multiple instances starting at the initial schedule and ending at the optimized schedule. Each node in the graph represents an improved schedule. The length of the edges corresponds to the improvement in the objective function value.\n\n\nfor idx, (n, schedules, objectives) in enumerate(zip(N, schedules_list, objectives_list), start=1):\n    print(f'Processing N={n}, number of schedules: {len(schedules)}')\n    \n    # Create individual network graph\n    individual_fig = create_schedule_network_from_lists(\n        schedules=schedules,\n        objective_values=objectives,\n        echo=False\n    )\n    \n    individual_fig.update_layout(\n        autosize=False,\n        width=1500,\n        height=1800,\n        margin=dict(\n            l=50,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\n    \n    # Show the individual network graph\n    individual_fig.show()\n\nProcessing N=16, number of schedules: 39\nProcessing N=17, number of schedules: 43\nProcessing N=18, number of schedules: 43\nProcessing N=19, number of schedules: 43\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n\nNext we’ve repeated the experiment for similar instances but with a higher weight for the waiting time in the objective function. In this case we also implemented parallel processing to speed up the computation.\n\n# Function to process a single N\ndef process_schedule(n, T, s, d, q, w, v_star):\n    print(f'Running local search for schedule with N={n}')\n    x = build_welch_bailey_schedule(n, T)\n    convolutions = compute_convolutions(s, n, q)\n    schedules, objectives = local_search_w_intermediates(x, d, convolutions, w, v_star, T)\n    return {\n        'n': n,\n        'x_initial': x,\n        'schedules': schedules,\n        'objectives': objectives,\n        'x_star': schedules[-1],\n        'obj_val': objectives[-1],\n    }\n\n# Parameters\nN = range(16, 20)\nT = 15\ns = [0.3, 0.2, 0.1, 0.05, 0.15, 0.2]  # Example service time probability distribution\nd = 2  # Duration threshold\nq = 0.1  # No-show probability\nw = 0.9  # Weight for waiting time in the objective\nv_star = get_v_star(T)\n\n# Lists to store results\nresults = []\n\nstart = time.time()\n\n# Parallelize the process_schedule function using Joblib\nresults = Parallel(n_jobs=-1)(delayed(process_schedule)(n, T, s, d, q, w, v_star) for n in N)\n\nend = time.time()\n\n# Extract results\nx_initials = [result['x_initial'] for result in results]\nschedules_list = [result['schedules'] for result in results]\nobjectives_list = [result['objectives'] for result in results]\nx_stars = [result['x_star'] for result in results]\nobj_vals = [result['obj_val'] for result in results]\n\nprint(\"Optimized schedules:\", x_stars)\nprint(\"Objective values:\", obj_vals)\nprint(f\"Search time: {end - start:.2f} seconds\")\n\nOptimized schedules: [[2, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 4], [2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 4], [2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 5], [2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 6]]\nObjective values: [39.1854102224129, 48.66396904640554, 58.95723399701313, 70.90032316773812]\nSearch time: 16.10 seconds\n\n\n\n# Number of subplots needed\nnum_subplots = len(x_stars)\n\n# Create a subplot figure with one chart per subplot\nfig = sp.make_subplots(\n    rows=num_subplots, \n    cols=1, \n    shared_xaxes=True, \n    subplot_titles=[f'n = {n}' for n in N]\n)\n\n# Add each initial and optimized schedule to its respective subplot\nfor idx, (x_initial, x_star) in enumerate(zip(x_initials, x_stars)):\n    # Add initial schedule as a dotted line\n    fig.add_trace(\n        go.Scatter(\n            x=list(range(T)), \n            y=x_initial, \n            mode='lines', \n            name='Initial schedule' if idx == 0 else None,  # Show legend only once\n            line=dict(dash='dot', color='blue')\n        ), \n        row=idx + 1, \n        col=1\n    )\n    \n    # Add optimized schedule as a solid line with markers\n    fig.add_trace(\n        go.Scatter(\n            x=list(range(T)), \n            y=x_star, \n            mode='lines+markers', \n            name='Optimized schedule' if idx == 0 else None,  # Show legend only once\n            line=dict(color='red')\n        ), \n        row=idx + 1, \n        col=1\n    )\n\n# Update layout properties\nfig.update_layout(\n    height=600 * num_subplots,  # Adjust height based on the number of subplots\n    title=dict(\n        text=f\"Optimal schedules across different values of N\\n(T={T}, w={w})\",\n        x=0.5,  # Center the title horizontally\n        # y=0.95,  # Adjust the vertical position (closer to the top)\n        font=dict(size=20),  # Optional: Adjust title font size\n        pad=dict(b=50)  # Add padding at the top of the title\n    ),\n    xaxis_title=\"Time slot (x)\",\n    yaxis_title=\"# of patients (y)\",\n    template=\"plotly_white\",\n    showlegend=False  # Enable legend to distinguish between initial and optimized schedules\n)\n\n# Set consistent y-axis ticks for each subplot\nfor i in range(1, num_subplots + 1):\n    fig.update_yaxes(tickmode='linear', tick0=0, dtick=1, row=i, col=1)\n\n# Optionally, adjust the legend position\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.02,\n    xanchor=\"right\",\n    x=1\n))\n\n# Show the Plotly figure\nfig.show()\n\n                                                \n\n\n\n\nfor idx, (n, schedules, objectives) in enumerate(zip(N, schedules_list, objectives_list), start=1):\n    print(f'Processing N={n}, number of schedules: {len(schedules)}')\n    \n    # Create individual network graph\n    individual_fig = create_schedule_network_from_lists(\n        schedules=schedules,\n        objective_values=objectives,\n        echo=False\n    )\n    \n    individual_fig.update_layout(\n        autosize=False,\n        width=1500,\n        height=1800,\n        margin=dict(\n            l=50,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\n    \n    # Show the individual network graph\n    individual_fig.show()\n\nProcessing N=16, number of schedules: 20\nProcessing N=17, number of schedules: 21\nProcessing N=18, number of schedules: 26\nProcessing N=19, number of schedules: 27\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\n\nFinally we’ve expanded the experiment to include larger instances. We’ve increased the number of intervals and patients, while keeping the weight for the waiting time in the objective function at 0.9.\n\n# Function to process a single N\ndef process_schedule(n, T, s, d, w, v_star):\n    print(f'Running local search for schedule with N={n}')\n    x = build_quasi_optimal_schedule(n, T)\n    convolutions = compute_convolutions(s, n, q)\n    schedules, objectives = local_search_w_intermediates(x, d, convolutions, w, v_star, T)\n    return {\n        'n': n,\n        'x_initial': x,\n        'schedules': schedules,\n        'objectives': objectives,\n        'x_star': schedules[-1],\n        'obj_val': objectives[-1],\n    }\n\n# Parameters\nN = range(21, 24)\nT = 20\ns = [0.3, 0.2, 0.1, 0.05, 0.15, 0.2]  # Example service time probability distribution\nd = 2  # Duration threshold\nq = 0.1  # No-show probability\nw = 0.5  # Weight for waiting time in the objective\nv_star = get_v_star(T)\n\n# Lists to store results\nresults = []\n\nstart = time.time()\n\n# Parallelize the process_schedule function using Joblib\nresults = Parallel(n_jobs=-1)(delayed(process_schedule)(n, T, s, d, w, v_star) for n in N)\n\nend = time.time()\n\n# Extract results\nx_initials = [result['x_initial'] for result in results]\nschedules_list = [result['schedules'] for result in results]\nobjectives_list = [result['objectives'] for result in results]\nx_stars = [result['x_star'] for result in results]\nobj_vals = [result['obj_val'] for result in results]\n\nprint(\"Optimized schedules:\", x_stars)\nprint(\"Objective values:\", obj_vals)\nprint(f\"Search time: {end - start:.2f} seconds\")\n\nRunning local search for schedule with N=18\nTotal evaluations: 18625\nRunning local search for schedule with N=17\nTotal evaluations: 19548\nRunning local search for schedule with N=19\nTotal evaluations: 18633\nOptimized schedules: [[2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 4], [2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 5], [2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 5]]\nObjective values: [36.303606121519586, 42.87410729585329, 50.14956668757205]\nSearch time: 338.51 seconds\n\n\n\n# Number of subplots needed\nnum_subplots = len(x_stars)\n\n# Create a subplot figure with one chart per subplot\nfig = sp.make_subplots(\n    rows=num_subplots, \n    cols=1, \n    shared_xaxes=True, \n    subplot_titles=[f'n = {n}' for n in N]\n)\n\n# Add each initial and optimized schedule to its respective subplot\nfor idx, (x_initial, x_star) in enumerate(zip(x_initials, x_stars)):\n    # Add initial schedule as a dotted line\n    fig.add_trace(\n        go.Scatter(\n            x=list(range(T)), \n            y=x_initial, \n            mode='lines', \n            name='Initial schedule' if idx == 0 else None,  # Show legend only once\n            line=dict(dash='dot', color='blue')\n        ), \n        row=idx + 1, \n        col=1\n    )\n    \n    # Add optimized schedule as a solid line with markers\n    fig.add_trace(\n        go.Scatter(\n            x=list(range(T)), \n            y=x_star, \n            mode='lines+markers', \n            name='Optimized schedule' if idx == 0 else None,  # Show legend only once\n            line=dict(color='red')\n        ), \n        row=idx + 1, \n        col=1\n    )\n\n# Update layout properties\nfig.update_layout(\n    height=600 * num_subplots,  # Adjust height based on the number of subplots\n    title=dict(\n        text=f\"Optimal schedules across different values of N\\n(T={T}, w={w})\",\n        x=0.5,  # Center the title horizontally\n        y=0.95,  # Adjust the vertical position (closer to the top)\n        font=dict(size=20),  # Optional: Adjust title font size\n        pad=dict(t=50)  # Add padding at the top of the title\n    ),\n    xaxis_title=\"Time slot (x)\",\n    yaxis_title=\"# of patients (y)\",\n    template=\"plotly_white\",\n    showlegend=False  # Enable legend to distinguish between initial and optimized schedules\n)\n\n# Set consistent y-axis ticks for each subplot\nfor i in range(1, num_subplots + 1):\n    fig.update_yaxes(tickmode='linear', tick0=0, dtick=1, row=i, col=1)\n\n# Optionally, adjust the legend position\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.02,\n    xanchor=\"right\",\n    x=1\n))\n\n# Show the Plotly figure\nfig.show()\n\n                                                \n\n\n\n\nfor idx, (n, schedules, objectives) in enumerate(zip(N, schedules_list, objectives_list), start=1):\n    print(f'Processing N={n}, number of schedules: {len(schedules)}')\n    \n    # Create individual network graph\n    individual_fig = create_schedule_network_from_lists(\n        schedules=schedules,\n        objective_values=objectives,\n        echo=False\n    )\n    \n    individual_fig.update_layout(\n        autosize=False,\n        width=1500,\n        height=1800,\n        margin=dict(\n            l=50,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\n    \n    # Show the individual network graph\n    individual_fig.show()\n\nProcessing N=21, number of schedules: 2\nProcessing N=22, number of schedules: 2\nProcessing N=23, number of schedules: 8",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html#discussion",
    "href": "appointment-scheduling-heuristics.html#discussion",
    "title": "7  Appointment scheduling heuristics",
    "section": "7.5 Discussion",
    "text": "7.5 Discussion\nThe results of the experiments appear to confirm that optimal schedules adhere to the Bailey-Welch rule of scheduling two patients at the start of the day. The remaining patients are then allocated as evenly as possible across the remaining time intervals. When patients’ time is valued higher than the physician’s, empty intervals are inserted into the schedule to absorb potential spillover times. This adjustment, however, pushes some patients out of the schedule, thereby increasing the total overtime.\nThe local search algorithm required on average 22 and 42 steps for both types of small instances (\\(w = 0.1\\) and \\(w = 0.9\\), respectively) to compute the global optimum. Interestingly the number of steps required to reach the optimal schedule did not increase significantly for the larger instance (\\(T=20\\), \\(N=\\{21, 22\\}\\), \\(w = 0.9\\)), despite the larger solution space. This suggests that the local search algorithm is effective in finding the optimal schedule within a reasonable number of steps.\nIn each instance, the most significant reductions in the objective value occurred each time a patient was moved from the last time interval to an earlier one. This adjustment minimized overtime, which apparently has a substantial impact on the objective value.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html#timeline",
    "href": "appointment-scheduling-heuristics.html#timeline",
    "title": "7  Appointment scheduling heuristics",
    "section": "7.6 Timeline",
    "text": "7.6 Timeline\nThis experiment was started at 18-11-2024 and is expected to be completed by 31-12-2024.",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html#references",
    "href": "appointment-scheduling-heuristics.html#references",
    "title": "7  Appointment scheduling heuristics",
    "section": "7.7 References",
    "text": "7.7 References",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  },
  {
    "objectID": "appointment-scheduling-heuristics.html#footnotes",
    "href": "appointment-scheduling-heuristics.html#footnotes",
    "title": "7  Appointment scheduling heuristics",
    "section": "",
    "text": "Welch, J. D., & Bailey, N. T. J. (1952). Appointment systems in hospital outpatient departments. The Lancet, 259(6718), 1105-1108.↩︎\nRobinson, L. W., & Chen, R. R. (2003). Scheduling doctors’ appointments: optimal and empirically-based heuristic policies. IIE Transactions, 35(3), 295-307.↩︎\nRobinson, L. W., & Chen, R. R. (2003). Scheduling doctors’ appointments: optimal and empirically-based heuristic policies. IIE Transactions, 35(3), 295-307.↩︎\nKlassen, K. J., & Yoogalingam, R. (2009). Improving performance in outpatient appointment services with a simulation optimization approach. Production and Operations Management, 18(4), 447-458.↩︎",
    "crumbs": [
      "Surrogate models for schedule evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appointment scheduling heuristics</span>"
    ]
  }
]