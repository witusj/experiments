[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experiments",
    "section": "",
    "text": "Preface\nThis book contains all experiment protocols for my research on appointment scheduling.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html",
    "href": "xgboost-pairwise-ranking.html",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "",
    "text": "2.1 Objective\nObjective: Testing the performance of an XGBoost model trained for ranking pairwise schedules.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#background",
    "href": "xgboost-pairwise-ranking.html#background",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.2 Background",
    "text": "2.2 Background\nTo find optimal solutions for appointment scheduling problems one approach is to create local search neighborhoods and evaluate the schedules in that set. A better search method either (1) - creates smaller search neighborhoods or (2) - evaluates faster.\nOne approach for speeding up evaluation is to create surrogate models, or metamodels. These are simplified representations of complex systems that are often created using machine learning techniques.\nIn this experiment we develop a Machine Learning model using XGBoost that can evaluate two neighboring schedules and rank them according to preference. This ranking model can be applied to quickly guide the search process towards a `good enough’ solution.\nThe choice of using an ordinal model instead of a cardinal model is based on the following considerations (Ho et al. 2000):\n\nAccuracy: The convergence of ‘order’ occurs at an exponential rate, while ‘value’ converges at a rate of \\(1/t^{1/2}\\). In simpler terms, it is significantly easier to determine whether alternative A is superior to B than to quantify the exact difference between A and B. This makes intuitive sense when considering the scenario of holding two identical-looking packages and deciding which one is heavier, as opposed to estimating the precise weight difference between them.\nEfficiency: When evaluating a complex system is computationally expensive, it’s more efficient to use a method that quickly identifies a subset of solutions with a high likelihood of containing the optimal or near-optimal solution. By focusing computational resources on refining the search within this promising subset, rather than across the entire solution space, we can significantly reduce the overall computational burden.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#hypothesis",
    "href": "xgboost-pairwise-ranking.html#hypothesis",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.3 Hypothesis",
    "text": "2.3 Hypothesis\nAn XGBoost ranking model achieves superior computational efficiency compared to evaluating each element of a pair individually, leading to faster overall performance in ranking tasks.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#methodology",
    "href": "xgboost-pairwise-ranking.html#methodology",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.4 Methodology",
    "text": "2.4 Methodology\n\n2.4.1 Tools and Materials\nWe use packages from Scikit-learn to prepare training data and evaluate the model and the XGBClassifier interface from the XGBoost library.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.base import clone\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\nimport functions\n\n\n\n2.4.2 Experimental Design\nTo compare an XGBoost Machine Learning model with a simple evaluation of each individual element of the pair, we will use a pairwise ranking approach. The objective is to rank two neighboring schedules according to preference.\nWe will create a random set of pairs of neighboring schedules with \\(N = 12\\) patients and \\(\\ T = 18\\) intervals of length \\(d = 5\\).\nA neighborhood consists of all schedules that differ by one patient only. Eg: ([2,1,1], [1,1,2]) are neighbors and ([2,1,1], [1,0,3]) are not.\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.20\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. The model will be trained to predict which of the two neighboring schedules has the lowest objective value. The prediction time will be recorded. Then the same schedules will be evaluated by computing the objective value and then ranked.\n\nN = 12 # Number of patients\nT = 18 # Number of intervals\nd = 5 # Length of each interval\ns = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1] # Service times distribution\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.8 # Weight for the waiting time in objective function\nnum_schedules = 20000 # Number of schedules to sample\n\n\n\n2.4.3 Variables\n\nIndependent Variables: A list of tuples with pairs of neighboring schedules.\nDependent Variables: A list with rankings for each tuple of pairwise schedules. Eg: If the rank for ([2,1,1], [1,1,2]) is 1 this means that the schedule with index 1 ([1,1,2]) has the lowest objective value.\n\n\n\n2.4.4 Data Collection\nThe data set will be generated using simulation in which random samples will be drawn from the population of all possible schedules. For each sample a random neighboring schedule will be created.\n\n\n2.4.5 Sample Size and Selection\nSample Size: The total population size equals \\({{N + T -1}\\choose{N}} \\approx\\) 52.0 mln. For this experiment we will be using a relatively small sample of 20000 schedules.\nSample Selection: The samples will be drawn from a lexicographic order of possible schedules in order to accurately reflect the combinatorial nature of the problem and to ensure unbiased sampling from the entire combinatorial space.\n\n\n2.4.6 Experimental Procedure\nThe experiment involves multiple steps, beginning with data preparation and concluding with model evaluation. Each step offers several design options. The diagram below illustrates the sequence of steps and the available choices. We are adhering to the steps highlighted in red.\n\n\n\n\n\ngraph TD\n    A[\"Create features\"]:::path --&gt;|\"option 1\"| B[\"from population\"]\n    A --&gt;|\"option 2\"| C[\"random subset\"]:::path\n    B --&gt; D[\"Create pairs\"]:::path\n    C --&gt; D\n    D --&gt;|\"option 1\"| E[\"random\"]\n    D --&gt;|\"option 2\"| F[\"neighbors\"]:::path\n    E --&gt; G[\"Create labels\"]:::path\n    F --&gt; G\n    G --&gt;|\"option 1\"| H[\"objective\"]\n    G --&gt;|\"option 2\"| I[\"ranking\"]:::path\n    H --&gt; J[\"Split dataset\"]:::path\n    I --&gt; J\n    J --&gt; K[\"Train XGBoost\"]:::path\n    K --&gt; L[\"Evaluate model\"]:::path\n    \n    classDef path stroke:#f00\n\n\n\n\n\n\nStep 1: Randomly select a subset of schedules.\n\nfrom functions import random_combination_with_replacement\n\nstart = time.time()\nschedules = random_combination_with_replacement(T, N, num_schedules)\nprint(f\"Sampled: {len(schedules)} schedules\\n\")\nfor schedule in schedules[:5]:\n    print(f\"Schedule: {schedule}\")\nend = time.time()\ndata_prep_time = end - start\n\nprint(f\"\\nProcessing time: {data_prep_time} seconds\\n\")\n\nTotal number of combinations: 51895935\nSampled: 20000 schedules\n\nSchedule: [5, 2, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [5, 2, 1, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [4, 3, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [4, 3, 2, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSchedule: [6, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\nProcessing time: 0.22069811820983887 seconds\n\n\n\nStep 2: Create pairs of neighboring schedules.\n\nfrom functions import create_neighbors_list\n\nstart = time.time()\nneighbors_list = create_neighbors_list(schedules)\nfor neighbor in neighbors_list[:5]:\n    print(f\"Neighbor: {neighbor[1]}\")\nend = time.time() \ntraining_set_feat_time = end - start\nprint(f\"\\nProcessing time: {training_set_feat_time} seconds\\n\")\n\nNeighbor: [5, 2, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\nNeighbor: [5, 2, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\nNeighbor: [4, 3, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\nNeighbor: [3, 3, 2, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nNeighbor: [6, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n\nProcessing time: 0.11100196838378906 seconds\n\n\n\nStep 3: For each schedule in each pair calculate the objective. For each pair save the index of the schedule that has the lowest objective value.\n\nfrom functions import calculate_objective\n\nobjectives_schedule_1 = [w * calculate_objective(neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(neighbor[0], s, d, q)[1] for neighbor in neighbors_list]\nstart = time.time()\nobjectives_schedule_2 = [w * calculate_objective(neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(neighbor[1], s, d, q)[1] for neighbor in neighbors_list]\nend = time.time()\ntraining_set_lab_time = end - start\nobjectives = [[obj, objectives_schedule_2[i]] for i, obj in enumerate(objectives_schedule_1)]\nrankings = np.argmin(objectives, axis=1).tolist()\nfor i in range(5):\n    print(f\"Objectives: {objectives[i]}, Ranking: {rankings[i]}\")\n\nprint(f\"\\nProcessing time: {training_set_lab_time} seconds\\n\")\n\n# Saving neighbors_list and objectives to a pickle file\nfile_path = 'neighbors_and_objectives.pkl'\nwith open(file_path, 'wb') as f:\n    pickle.dump({'neighbors_list': neighbors_list, 'objectives': objectives, 'rankings': rankings}, f)\n    print(f\"Data saved successfully to '{file_path}'\")\n\nObjectives: [33.14262247150417, 29.513652258155812], Ranking: 1\nObjectives: [40.31329726070515, 33.9918899368676], Ranking: 1\nObjectives: [28.26829606395503, 28.13988665387279], Ranking: 1\nObjectives: [36.3496594221498, 28.076426535166036], Ranking: 1\nObjectives: [36.391030344723525, 36.39070437488561], Ranking: 1\n\nProcessing time: 22.04170322418213 seconds\n\nData saved successfully to 'neighbors_and_objectives.pkl'\n\n\nStep 4: Create training and test sets.\n\n# Prepare the dataset\nX = []\nfor neighbors in neighbors_list:\n    X.append(neighbors[0] + neighbors[1])\n\nX = np.array(X)\ny = np.array(rankings)\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nStep 5: Train the XGBoost model.\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B[Initialize StratifiedKFold]\n    B --&gt; C[Initialize XGBClassifier]\n    C --&gt; D[Set results as empty list]\n    D --&gt; E[Loop through each split of cv split]\n    E --&gt; F[Get train and test indices]\n    F --&gt; G[Split X and y into X_train, X_test, y_train, y_test]\n    G --&gt; H[Clone the classifier]\n    H --&gt; I[Call fit_and_score function]\n    I --&gt; J[Fit the estimator]\n    J --&gt; K[Score on training set]\n    J --&gt; L[Score on test set]\n    K --&gt; M[Return estimator, train_score, test_score]\n    L --&gt; M\n    M --&gt; N[Append the results]\n    N --&gt; E\n    E --&gt; O[Loop ends]\n    O --&gt; P[Print results]\n    P --&gt; Q[End]\n\n\n\n\n\n\n\nclass CustomCallback(TrainingCallback):\n    def __init__(self, period=10):\n        self.period = period\n\n    def after_iteration(self, model, epoch, evals_log):\n        if (epoch + 1) % self.period == 0:\n            print(f\"Epoch {epoch}, Evaluation log: {evals_log['validation_0']['logloss'][epoch]}\")\n        return False\n    \ndef fit_and_score(estimator, X_train, X_test, y_train, y_test):\n    \"\"\"Fit the estimator on the train set and score it on both sets\"\"\"\n    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0\n    )\n\n    train_score = estimator.score(X_train, y_train)\n    test_score = estimator.score(X_test, y_test)\n\n    return estimator, train_score, test_score\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)\n\n# Initialize the XGBClassifier without early stopping here\n# Load the best trial parameters from a JSON file.\nwith open(\"model_params.json\", \"r\") as f:\n    model_params = json.load(f)\n    \n# Initialize the EarlyStopping callback with validation dataset\nearly_stop = xgb.callback.EarlyStopping(\n    rounds=10, metric_name='logloss', data_name='validation_0', save_best=True\n)\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n    early_stopping_rounds=9,\n    #callbacks=[CustomCallback(period=50), early_stop],\n    callbacks=[CustomCallback(period=50)],\n)\nprint(\"Params: \")\nfor key, value in model_params.items():\n    print(f\" {key}: {value}\")\n\nstart = time.time()\nresults = []\n\nfor train_idx, test_idx in cv.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    \n    est, train_score, test_score = fit_and_score(\n        clone(clf), X_train, X_test, y_train, y_test\n    )\n    results.append((est, train_score, test_score))\nend = time.time()\ntraining_time = end - start\nprint(f\"\\nTraining time: {training_time} seconds\\n\")\n\nParams: \n max_depth: 6\n min_child_weight: 1\n gamma: 0.1\n subsample: 0.8\n colsample_bytree: 0.8\n learning_rate: 0.1\n n_estimators: 100\nEpoch 49, Evaluation log: 0.3014085651938804\nEpoch 99, Evaluation log: 0.20852809651440476\nEpoch 49, Evaluation log: 0.2990140776964836\nEpoch 99, Evaluation log: 0.21020062281913124\nEpoch 49, Evaluation log: 0.2931870718174614\nEpoch 99, Evaluation log: 0.20591436560149304\nEpoch 49, Evaluation log: 0.2928910930305719\nEpoch 99, Evaluation log: 0.2065044123098487\nEpoch 49, Evaluation log: 0.3091742426874116\nEpoch 99, Evaluation log: 0.22745722064038273\n\nTraining time: 1.11879301071167 seconds\n\n\n\nStep 6: To evaluate the performance of the XGBoost ranking model, we will use Stratified K-Fold Cross-Validation with 5 splits, ensuring each fold maintains the same class distribution as the original dataset. Using StratifiedKFold(n_splits=5, shuffle=True, random_state=94), the dataset will be divided into five folds. In each iteration, the model will be trained on four folds and evaluated on the remaining fold. A custom callback, CustomCallback(period=10), will print the evaluation log every 10 epochs.\nThe fit_and_score function will fit the model and score it on both the training and test sets, storing the results for each fold. This provides insight into the model’s performance across different subsets of the data, helps in understanding how well the model generalizes to unseen data and identifies potential overfitting or underfitting issues. The overall processing time for the cross-validation will also be recorded.\n\n# Print results\nfor i, (est, train_score, test_score) in enumerate(results):\n    print(f\"Fold {i+1} - Train Score: {train_score:.4f}, Test Score: {test_score:.4f}\")\n\nFold 1 - Train Score: 0.9543, Test Score: 0.9467\nFold 2 - Train Score: 0.9559, Test Score: 0.9393\nFold 3 - Train Score: 0.9513, Test Score: 0.9465\nFold 4 - Train Score: 0.9556, Test Score: 0.9443\nFold 5 - Train Score: 0.9534, Test Score: 0.9267\n\n\nTraining the model on the entire dataset provides a final model that has learned from all available data. Recording the training time helps in understanding the computational efficiency and scalability of the model with the given hyperparameters.\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=model_params[\"max_depth\"],\n    min_child_weight=model_params[\"min_child_weight\"],\n    gamma=model_params[\"gamma\"],\n    subsample=model_params[\"subsample\"],\n    colsample_bytree=model_params[\"colsample_bytree\"],\n    learning_rate=model_params[\"learning_rate\"],\n    n_estimators=model_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\\n\")\n\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\nTraining accuracy: 95.27%\n\n\nTraining time: 0.11682415008544922 seconds\n\n\n\nGenerating test schedules and calculating their objectives and rankings allows us to create a new dataset for evaluating the model’s performance on unseen data.\n\nnum_test_schedules = 1000\n\ntest_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_neighbors = create_neighbors_list(test_schedules)\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\ntest_objectives_schedule_1 = [w * calculate_objective(test_neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[0], s, d, q)[1] for test_neighbor in test_neighbors]\n# Start time measeurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_2 = [w * calculate_objective(test_neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[1], s, d, q)[1] for test_neighbor in test_neighbors]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\nend = time.time()\nevaluation_time = end - start\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\nprint(f\"\\nEvaluation time: {evaluation_time} seconds\\n\")\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nTotal number of combinations: 51895935\nSampled: 1000 schedules\n\n\nEvaluation time: 0.8738951683044434 seconds\n\nNeighbors: ([6, 2, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 2, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [40.53530337855781, 42.68185374861516], Ranking: 0\n\nNeighbors: ([7, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [67.34407770186385, 50.147569386795865], Ranking: 1\n\nNeighbors: ([8, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [9, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [55.176078736623644, 59.17432402702707], Ranking: 0\n\nNeighbors: ([6, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [6, 1, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [43.57140360256858, 43.697489890370804], Ranking: 0\n\nNeighbors: ([6, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0], [6, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]),\nObjectives: [52.973289533627785, 52.973289577461145], Ranking: 0\n\nNeighbors: ([5, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [5, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\nObjectives: [49.54787442106589, 49.54787442106589], Ranking: 1\n\n\n\nMaking predictions on new data and comparing them to the actual rankings provides an evaluation of the model’s performance in practical applications. Recording the prediction time helps in understanding the model’s efficiency during inference.\n\ninput_X = test_neighbors\nX_new = []\nfor test_neighbor in input_X:\n    X_new.append(test_neighbor[0] + test_neighbor[1])\n    \n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.006372213363647461 seconds\n\ntest_rankings = [0 1 0 0 0 1], \ny_pred = [0 1 1 0 0 0], \ny_pred_proba = \n[[0.5200364  0.4799636 ]\n [0.02138072 0.9786193 ]\n [0.450876   0.549124  ]\n [0.7691541  0.23084596]\n [0.71183014 0.28816983]\n [0.8532454  0.14675465]]\n\n\nCalculating the ambiguousness of the predicted probabilities helps in understanding the model’s confidence in its predictions. High ambiguousness indicates uncertain predictions, while low ambiguousness indicates confident predictions.\nCalculating cumulative error rate and cumulative accuracy helps in understanding how the model’s performance evolves over the dataset.\nVisualizing the relationship between ambiguousness and error provides insights into how uncertainty in the model’s predictions correlates with its accuracy. This can help in identifying patterns and understanding the conditions under which the model performs well or poorly.\n\nfrom functions import calculate_ambiguousness\n\nerrors = np.abs(y_pred - np.array(test_rankings))\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9)))\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#hyperparameter-optimization",
    "href": "xgboost-pairwise-ranking.html#hyperparameter-optimization",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.5 Hyperparameter Optimization",
    "text": "2.5 Hyperparameter Optimization\nIn the initial model the choice of hyperparameters was based on default values, examples from demo’s or trial and error. To improve the model’s performance, we applied a hyperparameter optimization technique to find the best set of hyperparameters. We used a grid search with cross-validation to find the optimal hyperparameters for the XGBoost model. The grid search was performed over a predefined set of hyperparameters, and the best hyperparameters were selected based on the model’s performance on the validation set. The best hyperparameters were then used to train the final model.\n\nfrom functions import compare_json\n\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n    \ndifferences = compare_json(model_params, best_trial_params)\n\nparams_tbl = pd.DataFrame(differences)\nparams_tbl.rename(index={'json1_value': 'base parameters', 'json2_value': 'optimized parameters'}, inplace=True)\nprint(params_tbl)\n\n                      max_depth     gamma  subsample  colsample_bytree  \\\nbase parameters               6  0.100000   0.800000          0.800000   \noptimized parameters          5  0.304548   0.781029          0.922528   \n\n                      learning_rate  n_estimators  \nbase parameters            0.100000           100  \noptimized parameters       0.239488           490  \n\n\n\n# Fit the model on the entire dataset\n# Initialize the XGBClassifier without early stopping here\n\n# Load the best trial parameters from a JSON file.\nwith open(\"best_trial_params.json\", \"r\") as f:\n    best_trial_params = json.load(f)\n\nstart = time.time()\n\nclf = xgb.XGBClassifier(\n    tree_method=\"hist\",\n    max_depth=best_trial_params[\"max_depth\"],\n    min_child_weight=best_trial_params[\"min_child_weight\"],\n    gamma=best_trial_params[\"gamma\"],\n    subsample=best_trial_params[\"subsample\"],\n    colsample_bytree=best_trial_params[\"colsample_bytree\"],\n    learning_rate=best_trial_params[\"learning_rate\"],\n    n_estimators=best_trial_params[\"n_estimators\"],\n)\n\nclf.fit(X, y)\nend= time.time()\nmodeling_time = end - start\nprint(f\"\\nTraining time: {modeling_time} seconds\\n\")\n\n# Calculate and print the training accuracy\ntraining_accuracy = clf.score(X, y)\nprint(f\"Training accuracy: {training_accuracy * 100:.2f}%\")\n\n\nTraining time: 0.32810282707214355 seconds\n\nTraining accuracy: 99.95%\n\n\n\n# Predict the target for new data\ny_pred = clf.predict(X_new)\n\n# Probability estimates\nstart = time.time()\ny_pred_proba = clf.predict_proba(X_new)\nend = time.time()\nprediction_time = end - start\nprint(f\"\\nPrediction time: {prediction_time} seconds\\n\")\n\nprint(f\"test_rankings = {np.array(test_rankings)[:6]}, \\ny_pred = {y_pred[:6]}, \\ny_pred_proba = \\n{y_pred_proba[:6]}\")\n\n\nPrediction time: 0.004456758499145508 seconds\n\ntest_rankings = [0 1 0 0 0 1], \ny_pred = [0 1 1 0 0 0], \ny_pred_proba = \n[[9.7754252e-01 2.2457462e-02]\n [9.5367432e-07 9.9999905e-01]\n [4.7697216e-01 5.2302784e-01]\n [9.9707091e-01 2.9291052e-03]\n [9.9411666e-01 5.8833323e-03]\n [9.9418437e-01 5.8156434e-03]]\n\n\n\nerrors = np.abs(y_pred - np.array(test_rankings))\nambiguousness: np.ndarray = calculate_ambiguousness(y_pred_proba)\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9)))\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#results",
    "href": "xgboost-pairwise-ranking.html#results",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.6 Results",
    "text": "2.6 Results\nWe wanted to test whether an XGBoost classification model could be used to assess and rank the quality of pairs of schedules. For performance benchmarking we use the conventional calculation method utilizing Lindley recursions.\nWe trained the XGBoost ranking model with a limited set of features (schedules) and labels (objectives). The total number of possible schedules is approximately 52.0 million. For training and validation, we sampled 20000 schedules. Generating the feature and label set took a total of 22.3734 seconds, with the calculation of objective values accounting for 22.0417 seconds.\nThe model demonstrates strong and consistent performance with high accuracies both for training as well as testing, good generalization and stability. Total training time for the final model was 0.3281 seconds. The evaluation of 1000 test schedules took 0.0045 seconds for the the XGBoost model and 0.8739 for the conventional method, which is an improvement of 196X.\n\ntraining_time = round(modeling_time, 4)\nconventional_time = round(evaluation_time, 4)\nxgboost_time = round(prediction_time, 4)\n\n# Define time values for plotting\ntime_values = np.linspace(0, training_time+0.1, 1000)  # 0 to 2 seconds\n\n# Calculate evaluations for method 1\nmethod1_evaluations = np.where(time_values &gt;= training_time, (time_values - training_time) / xgboost_time * 1000, 0)\n\n# Calculate evaluations for method 2\nmethod2_evaluations = time_values / conventional_time * 1000\n\n# Create line chart\nfig = go.Figure()\n\n# Add method 1 trace\nfig.add_trace(go.Scatter(x=time_values, y=method1_evaluations, mode='lines', name='Ranking model'))\n\n# Add method 2 trace\nfig.add_trace(go.Scatter(x=time_values, y=method2_evaluations, mode='lines', name='Conventional method'))\n\n# Update layout\nfig.update_layout(\n    title=\"Speed comparison between XGBoost ranking model and conventional method\",\n    xaxis_title=\"Time (seconds)\",\n    yaxis_title=\"Number of Evaluations\",\n    legend_title=\"Methods\",\n    template=\"plotly_white\"\n)\n\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#discussion",
    "href": "xgboost-pairwise-ranking.html#discussion",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.7 Discussion",
    "text": "2.7 Discussion\nIn this experiment we used total waiting time as the objective value. In conventional appointment schedule problems the objective function also includes the physician’s idle time and overtime.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#timeline",
    "href": "xgboost-pairwise-ranking.html#timeline",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.8 Timeline",
    "text": "2.8 Timeline\n*This experiment was started on 25-07-2024. The completion date was 28-08-2024.**",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-pairwise-ranking.html#references",
    "href": "xgboost-pairwise-ranking.html#references",
    "title": "2  XGBoost classification model for pairwise ranking",
    "section": "2.9 References",
    "text": "2.9 References\n\n\n\n\nHo, Y-C, C G Cassandras, C-H Chen, and L Dai. 2000. “Ordinal Optimisation and Simulation.” Journal of the Operational Research Society 51 (4): 490–500. https://doi.org/10.1057/palgrave.jors.2600906.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>XGBoost classification model for pairwise ranking</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html",
    "href": "xgboost-objective-calc.html",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "",
    "text": "3.1 Objective\nCompare the performance (speed and accuracy) of a surrogate model (XGBoost regressor) with a conventional calculation for appointment scheduling objective function and against a ranking model.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#background",
    "href": "xgboost-objective-calc.html#background",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "3.2 Background",
    "text": "3.2 Background\nTo find optimal solutions for appointment scheduling problems one approach is to create local search neighborhoods and evaluate the schedules in that set. A better search method either (1) - creates smaller search neighborhoods or (2) - evaluates faster.\nOne approach for speeding up evaluation is to create surrogate models, or metamodels. These are simplified representations of complex systems that are often created using machine learning techniques.\nIn an earlier experiment we developed a ranking model that can rank two schedules according to preference. We established that a ranking model is significantly faster at choosing the best solution from a pair while retaining high accuracy levels.\nIn this experiment we develop a Machine Learning model using XGBoost for evaluating a single schedule and let it compete with the conventional method as well as with the ranking model.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#hypothesis",
    "href": "xgboost-objective-calc.html#hypothesis",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "3.3 Hypothesis",
    "text": "3.3 Hypothesis\nWe expect a ranking model to be superior in speed compared to a XGBoost regressor model. The XGBoost regressor model will outperform the conventional model in speed.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#methodology",
    "href": "xgboost-objective-calc.html#methodology",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "3.4 Methodology",
    "text": "3.4 Methodology\n\n3.4.1 Tools and Materials\nList the software, libraries, datasets, and any other materials you will use in this experiment. Include specific versions or configurations that are crucial for reproducibility.\n\nimport time\nimport math\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.base import clone\nimport xgboost as xgb\nfrom xgboost.callback import TrainingCallback\nimport plotly.graph_objects as go\nimport pickle\n\n\n\n3.4.2 Experimental Design\nWe will create a random set of pairs of neighboring schedules with \\(N = 12\\) patients and \\(\\ T = 18\\) intervals of length \\(d = 5\\).\nA neighborhood consists of all schedules that differ by one patient only. Eg: ([2,1,1], [1,1,2]) are neighbors and ([2,1,1], [1,0,3]) are not.\nService times will have a discrete distribution. The probability of a scheduled patient not showing up will be \\(q = 0.20\\).\nThe objective function will be the weighted average of the total waiting time of all patients and overtime. The model will be trained to predict the objective value of a given schedule. The prediction time will be recorded. Then the same schedules will be evaluated by computing the objective value using the conventional method.\n\nN = 12 # Number of patients\nT = 18 # Number of intervals\nd = 5 # Length of each interval\ns = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1] # Service times distribution\nq = 0.20 # Probability of a scheduled patient not showing up\nw = 0.8 # Weight for the waiting time in objective function\nnum_schedules = 20000 # Number of schedules to sample\n\n\n\n3.4.3 Variables\n\nIndependent Variables: A list schedules.\nDependent Variables: A list with objective values for each schedules.\n\n\n\n3.4.4 Data Collection\nThe data set has been generated in an earlier experiment using simulation in which random samples were drawn from the population of all possible schedules.\n\n# Load the data from the pickle file\nwith open('neighbors_and_objectives.pkl', 'rb') as f:\n    data = pickle.load(f)\n\n# Extract the variables from the loaded data\nneighbors_list = data['neighbors_list']\nobjectives_list = data['objectives']\nrankings_list = data['rankings']\n\nprint(\"Data loaded successfully.\\n\")\nfor neigbors in neighbors_list[:2]: print(neigbors, \"\\n\")\nfor objectives in objectives_list[:2]: print(objectives, \"\\n\")\nfor rankings in rankings_list[:2]: print(rankings, \"\\n\")\n\nData loaded successfully.\n\n([5, 2, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 2, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) \n\n([5, 2, 1, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 2, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]) \n\n[33.14262247150417, 29.513652258155812] \n\n[40.31329726070515, 33.9918899368676] \n\n1 \n\n1 \n\n\n\n\n\n3.4.5 Sample Size and Selection\nSample Size: - Indicate the number of samples you will use in the experiment. Justify the size based on the needs of the experiment, such as ensuring statistical significance.\nSample Selection: - Describe how you will select your samples. Ensure that the sampling method is unbiased and representative of the population you are studying.\n\n\n3.4.6 Experimental Procedure\n\nTrain XGBoost regressor model to predict objective values from given schedules. Measure training time and get training accuracy.\n\n\nX = np.array([X[0] for X in neighbors_list])\ny = np.array([y[0] for y in objectives_list])\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n#=========================================================================\n# XGBoost regression: \n# Parameters: \n# n_estimators  \"Number of gradient boosted trees. Equivalent to number \n#                of boosting rounds.\"\n# learning_rate \"Boosting learning rate (also known as “eta”)\"\n# max_depth     \"Maximum depth of a tree. Increasing this value will make \n#                the model more complex and more likely to overfit.\" \n#=========================================================================\nregressor=xgb.XGBRegressor(eval_metric='rmsle')\n\n#=========================================================================\n# exhaustively search for the optimal hyperparameters\n#=========================================================================\nfrom sklearn.model_selection import GridSearchCV\n# set up our search grid\nparam_grid = {\"max_depth\":    [4, 5, 7],\n              \"n_estimators\": [500, 700, 900],\n              \"learning_rate\": [0.05, 0.1, 0.15]}\n\n# try out every combination of the above values\nstart = time.time()\nsearch = GridSearchCV(regressor, param_grid, cv=5, verbose=3).fit(X_train, y_train)\nend = time.time()\nhyper_search_time = end - start\nprint(f'Hyperparameter optimization time: {hyper_search_time}')\n\nprint(\"The best hyperparameters are \",search.best_params_)\n\nregressor=xgb.XGBRegressor(learning_rate = search.best_params_[\"learning_rate\"],\n                       n_estimators  = search.best_params_[\"n_estimators\"],\n                       max_depth     = search.best_params_[\"max_depth\"],\n                       eval_metric='rmsle')\n\nregressor.fit(X_train, y_train)\n\nFitting 5 folds for each of 27 candidates, totalling 135 fits\n[CV 1/5] END learning_rate=0.05, max_depth=4, n_estimators=500;, score=0.994 total time=   0.4s\n[CV 2/5] END learning_rate=0.05, max_depth=4, n_estimators=500;, score=0.993 total time=   0.3s\n[CV 3/5] END learning_rate=0.05, max_depth=4, n_estimators=500;, score=0.994 total time=   0.4s\n[CV 4/5] END learning_rate=0.05, max_depth=4, n_estimators=500;, score=0.993 total time=   0.2s\n[CV 5/5] END learning_rate=0.05, max_depth=4, n_estimators=500;, score=0.994 total time=   0.3s\n[CV 1/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=0.997 total time=   0.3s\n[CV 2/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=0.996 total time=   0.3s\n[CV 3/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=0.996 total time=   0.3s\n[CV 4/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=0.996 total time=   0.3s\n[CV 5/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=0.996 total time=   0.3s\n[CV 1/5] END learning_rate=0.05, max_depth=4, n_estimators=900;, score=0.998 total time=   0.5s\n[CV 2/5] END learning_rate=0.05, max_depth=4, n_estimators=900;, score=0.997 total time=   0.6s\n[CV 3/5] END learning_rate=0.05, max_depth=4, n_estimators=900;, score=0.997 total time=   0.4s\n[CV 4/5] END learning_rate=0.05, max_depth=4, n_estimators=900;, score=0.997 total time=   0.4s\n[CV 5/5] END learning_rate=0.05, max_depth=4, n_estimators=900;, score=0.997 total time=   0.4s\n[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.997 total time=   0.3s\n[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.996 total time=   0.3s\n[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.996 total time=   0.4s\n[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.996 total time=   0.3s\n[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=500;, score=0.996 total time=   0.6s\n[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=700;, score=0.998 total time=   0.5s\n[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=700;, score=0.997 total time=   0.4s\n[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=700;, score=0.997 total time=   0.5s\n[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=700;, score=0.997 total time=   0.5s\n[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=700;, score=0.997 total time=   0.4s\n[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=900;, score=0.998 total time=   0.5s\n[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=900;, score=0.997 total time=   0.6s\n[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=900;, score=0.998 total time=   0.5s\n[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=900;, score=0.998 total time=   0.5s\n[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=900;, score=0.997 total time=   0.7s\n[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.998 total time=   0.8s\n[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.997 total time=   0.7s\n[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.997 total time=   0.8s\n[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.996 total time=   0.8s\n[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=500;, score=0.997 total time=   0.9s\n[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=700;, score=0.998 total time=   1.0s\n[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=700;, score=0.998 total time=   0.9s\n[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=700;, score=0.997 total time=   1.0s\n[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=700;, score=0.997 total time=   1.3s\n[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=700;, score=0.997 total time=   1.0s\n[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=900;, score=0.998 total time=   1.5s\n[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=900;, score=0.998 total time=   1.3s\n[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=900;, score=0.998 total time=   1.3s\n[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=900;, score=0.997 total time=   1.3s\n[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=900;, score=0.998 total time=   1.2s\n[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=500;, score=0.997 total time=   0.2s\n[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=500;, score=0.997 total time=   0.4s\n[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=500;, score=0.997 total time=   0.3s\n[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=0.998 total time=   0.4s\n[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=0.997 total time=   0.4s\n[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=0.998 total time=   0.5s\n[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=0.998 total time=   0.3s\n[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=0.998 total time=   0.3s\n[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=900;, score=0.999 total time=   0.5s\n[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=900;, score=0.998 total time=   0.4s\n[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=900;, score=0.998 total time=   0.4s\n[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=900;, score=0.998 total time=   0.5s\n[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=900;, score=0.998 total time=   0.4s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.998 total time=   0.4s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.998 total time=   0.4s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=500;, score=0.998 total time=   0.4s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=700;, score=0.999 total time=   0.5s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=700;, score=0.998 total time=   0.5s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=700;, score=0.999 total time=   0.5s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=700;, score=0.998 total time=   0.5s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=700;, score=0.998 total time=   0.5s\n[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.999 total time=   0.7s\n[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.998 total time=   0.7s\n[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.999 total time=   0.7s\n[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.999 total time=   0.6s\n[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=900;, score=0.999 total time=   0.7s\n[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.998 total time=   0.7s\n[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.998 total time=   0.7s\n[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.998 total time=   0.7s\n[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.998 total time=   0.8s\n[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=500;, score=0.998 total time=   0.9s\n[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=700;, score=0.999 total time=   1.1s\n[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=700;, score=0.998 total time=   0.9s\n[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=700;, score=0.998 total time=   1.0s\n[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=700;, score=0.998 total time=   1.1s\n[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=700;, score=0.998 total time=   1.0s\n[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.999 total time=   1.3s\n[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.999 total time=   1.2s\n[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.998 total time=   1.3s\n[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.998 total time=   1.2s\n[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=900;, score=0.998 total time=   1.5s\n[CV 1/5] END learning_rate=0.15, max_depth=4, n_estimators=500;, score=0.998 total time=   0.2s\n[CV 2/5] END learning_rate=0.15, max_depth=4, n_estimators=500;, score=0.998 total time=   0.2s\n[CV 3/5] END learning_rate=0.15, max_depth=4, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 4/5] END learning_rate=0.15, max_depth=4, n_estimators=500;, score=0.998 total time=   0.2s\n[CV 5/5] END learning_rate=0.15, max_depth=4, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 1/5] END learning_rate=0.15, max_depth=4, n_estimators=700;, score=0.999 total time=   0.4s\n[CV 2/5] END learning_rate=0.15, max_depth=4, n_estimators=700;, score=0.998 total time=   0.6s\n[CV 3/5] END learning_rate=0.15, max_depth=4, n_estimators=700;, score=0.999 total time=   0.4s\n[CV 4/5] END learning_rate=0.15, max_depth=4, n_estimators=700;, score=0.999 total time=   0.4s\n[CV 5/5] END learning_rate=0.15, max_depth=4, n_estimators=700;, score=0.998 total time=   0.6s\n[CV 1/5] END learning_rate=0.15, max_depth=4, n_estimators=900;, score=0.999 total time=   0.6s\n[CV 2/5] END learning_rate=0.15, max_depth=4, n_estimators=900;, score=0.999 total time=   0.4s\n[CV 3/5] END learning_rate=0.15, max_depth=4, n_estimators=900;, score=0.999 total time=   0.4s\n[CV 4/5] END learning_rate=0.15, max_depth=4, n_estimators=900;, score=0.999 total time=   0.6s\n[CV 5/5] END learning_rate=0.15, max_depth=4, n_estimators=900;, score=0.999 total time=   0.7s\n[CV 1/5] END learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.999 total time=   0.4s\n[CV 2/5] END learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.998 total time=   0.5s\n[CV 3/5] END learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.998 total time=   0.5s\n[CV 4/5] END learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 5/5] END learning_rate=0.15, max_depth=5, n_estimators=500;, score=0.998 total time=   0.3s\n[CV 1/5] END learning_rate=0.15, max_depth=5, n_estimators=700;, score=0.999 total time=   0.5s\n[CV 2/5] END learning_rate=0.15, max_depth=5, n_estimators=700;, score=0.999 total time=   0.5s\n[CV 3/5] END learning_rate=0.15, max_depth=5, n_estimators=700;, score=0.999 total time=   0.6s\n[CV 4/5] END learning_rate=0.15, max_depth=5, n_estimators=700;, score=0.999 total time=   0.5s\n[CV 5/5] END learning_rate=0.15, max_depth=5, n_estimators=700;, score=0.999 total time=   0.5s\n[CV 1/5] END learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.999 total time=   1.1s\n[CV 2/5] END learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.999 total time=   1.0s\n[CV 3/5] END learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.999 total time=   0.7s\n[CV 4/5] END learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.999 total time=   0.8s\n[CV 5/5] END learning_rate=0.15, max_depth=5, n_estimators=900;, score=0.999 total time=   0.6s\n[CV 1/5] END learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.999 total time=   0.7s\n[CV 2/5] END learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.998 total time=   0.7s\n[CV 3/5] END learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.998 total time=   0.6s\n[CV 4/5] END learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.998 total time=   0.8s\n[CV 5/5] END learning_rate=0.15, max_depth=7, n_estimators=500;, score=0.998 total time=   1.0s\n[CV 1/5] END learning_rate=0.15, max_depth=7, n_estimators=700;, score=0.999 total time=   0.9s\n[CV 2/5] END learning_rate=0.15, max_depth=7, n_estimators=700;, score=0.998 total time=   1.0s\n[CV 3/5] END learning_rate=0.15, max_depth=7, n_estimators=700;, score=0.999 total time=   1.0s\n[CV 4/5] END learning_rate=0.15, max_depth=7, n_estimators=700;, score=0.998 total time=   1.1s\n[CV 5/5] END learning_rate=0.15, max_depth=7, n_estimators=700;, score=0.998 total time=   0.9s\n[CV 1/5] END learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.999 total time=   1.3s\n[CV 2/5] END learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.998 total time=   1.6s\n[CV 3/5] END learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.999 total time=   1.2s\n[CV 4/5] END learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.998 total time=   1.2s\n[CV 5/5] END learning_rate=0.15, max_depth=7, n_estimators=900;, score=0.998 total time=   1.1s\nHyperparameter optimization time: 88.54528522491455\nThe best hyperparameters are  {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 900}\n\n\nXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric='rmsle', feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.15, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=900, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org. XGBRegressoriFittedXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric='rmsle', feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.15, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=5, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=900, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...) \n\n\n\npredictions = regressor.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_log_error\nRMSLE = np.sqrt( mean_squared_log_error(y_test, predictions) )\nprint(\"The score is %.5f\" % RMSLE )\n\nThe score is 0.00742\n\n\n\nimport plotly.graph_objects as go\n\n# Create the scatter plot\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=y_test, \n    y=predictions, \n    mode='markers',\n    marker=dict(color='blue'),\n    name='Predictions vs. true values'\n))\nfig.add_trace(go.Scatter(\n    x=[0, max(max(y_test), max(predictions))],\n    y=[0, max(max(y_test), max(predictions))],\n    mode='lines',\n    line=dict(color='tomato', dash='dash'),\n    name='Base line',\n))\n\n# Add axis labels and a title\nfig.update_layout(\n    title='Predictions vs. true values',\n    xaxis_title='True values',\n    yaxis_title='Predictions',\n    showlegend=True\n)\n\n# Show the plot\nfig.show()\n\n                                                \n\n\n\nCreate validation set with pairs of neighboring schedules and calculate their objectives. Measure calculation time.\n\n\nfrom functions import random_combination_with_replacement, create_neighbors_list, calculate_objective\n\nnum_test_schedules = 1000\n\ntest_schedules = random_combination_with_replacement(T, N, num_test_schedules)\ntest_neighbors = create_neighbors_list(test_schedules)\n\nprint(f\"Sampled: {len(test_schedules)} schedules\\n\")\n\ntest_objectives_schedule_1 = [w * calculate_objective(test_neighbor[0], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[0], s, d, q)[1] for test_neighbor in test_neighbors]\n# Start time measeurement for the evaluation\nstart = time.time()\ntest_objectives_schedule_2 = [w * calculate_objective(test_neighbor[1], s, d, q)[0] + (1 - w) * calculate_objective(test_neighbor[1], s, d, q)[1] for test_neighbor in test_neighbors]\ntest_rankings = [0 if test_obj &lt; test_objectives_schedule_2[i] else 1 for i, test_obj in enumerate(test_objectives_schedule_1)]\nend = time.time()\nevaluation_time = end - start\n\n# Combine the objectives for each pair for later processing\ntest_objectives = [[test_obj, test_objectives_schedule_2[i]] for i, test_obj in enumerate(test_objectives_schedule_1)]\n\nprint(f\"\\nEvaluation time: {evaluation_time} seconds\\n\")\n\nfor i in range(6):\n    print(f\"Neighbors: {test_neighbors[i]},\\nObjectives: {test_objectives[i]}, Ranking: {test_rankings[i]}\\n\")\n\nTotal number of combinations: 51895935\nSampled: 1000 schedules\n\n\nEvaluation time: 1.0750250816345215 seconds\n\nNeighbors: ([7, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [7, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\nObjectives: [55.043563835340436, 55.043563835340436], Ranking: 1\n\nNeighbors: ([5, 2, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 2, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [37.73306739107084, 26.024206087499312], Ranking: 1\n\nNeighbors: ([6, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\nObjectives: [49.42588617690052, 33.85178483030369], Ranking: 1\n\nNeighbors: ([6, 2, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [6, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]),\nObjectives: [49.46767397338491, 49.11353041602344], Ranking: 1\n\nNeighbors: ([3, 5, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 5, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\nObjectives: [45.1137194090156, 40.289706823026286], Ranking: 1\n\nNeighbors: ([5, 2, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\nObjectives: [35.20662033743255, 22.727985726985295], Ranking: 1\n\n\n\n\nPredict for each schedule in the validation set the objectives using the regressor model. Measure prediction time.\n\n\ndef predict_and_rank(neighbors):\n    neighbors_array = [np.array(neighbor) for neighbor in neighbors] # Convert schedules to a NumPy array\n    neighbors_array = np.vstack(neighbors_array)\n    predictions = regressor.predict(neighbors_array)\n    ranking = np.argmin(predictions)\n    return predictions, ranking\n\npredictions = [predict_and_rank(neighbors)[0] for neighbors in test_neighbors]\npred_rankings = [predict_and_rank(neighbors)[1] for neighbors in test_neighbors]\nprint(predictions[:10], pred_rankings[:10])\n\n[array([55.099285, 55.036415], dtype=float32), array([37.67509 , 26.061663], dtype=float32), array([49.215958, 33.878544], dtype=float32), array([49.543835, 49.20572 ], dtype=float32), array([44.91252 , 40.438553], dtype=float32), array([35.30649 , 22.991669], dtype=float32), array([27.386244, 27.103498], dtype=float32), array([57.97573, 65.45732], dtype=float32), array([27.271936, 33.643456], dtype=float32), array([32.77332 , 26.572252], dtype=float32)] [1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n\n\n\nCalculate accuracy comparing true and predicted rankings.\n\n\nerrors = np.abs(np.array(test_rankings) - pred_rankings)\naccuracy = 1 - errors.mean()\nprint(f\"Accuracy = {accuracy}\")\n\ndef calculate_ambiguousness(vector: np.array) -&gt; float:\n    # Ensure the vector is a numpy array\n    vector = np.array(vector)\n    \n    # Calculate the angle of the vector in radians\n    angle = np.arctan2(vector[1], vector[0])\n    \n    # Convert the angle to degrees\n    angle_degrees = np.degrees(angle)\n    \n    # Calculate the absolute difference from 45 degrees\n    difference_from_45 = np.abs(angle_degrees - 45)\n    \n    # Normalize the difference to a value between 0 and 1\n    ambiguousness = difference_from_45 / 45\n    \n    # Since ambiguousness must be between 0 and 1, we cap it at 1\n    ambiguousness = min(ambiguousness, 1)\n    \n    return ambiguousness\n\n# Example usage\nvector = np.array([1, 1])\nambiguousness = [calculate_ambiguousness(vector) for vector in predictions]\n\nAccuracy = 0.942\n\n\n\ndf = pd.DataFrame({\"Ambiguousness\": ambiguousness, \"Error\": errors}).sort_values(by=\"Ambiguousness\")\ndf['Cumulative error rate'] = df['Error'].expanding().mean()\n# Calculate cumulative accuracy\ndf['Cumulative accuracy'] = 1 - df['Cumulative error rate']\ndf.head()\n\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Error\"],\n                    mode=\"markers\",\n                    name=\"Error\",\n                    marker=dict(size=9)))\nfig.add_trace(go.Scatter(x=df[\"Ambiguousness\"], y=df[\"Cumulative accuracy\"],\n                    mode=\"lines\",\n                    name=\"Cum. accuracy\",\n                    line = dict(width = 3, dash = 'dash')))\nfig.update_layout(\n    title={\n        'text': f\"Error vs Ambiguousness&lt;/br&gt;&lt;/br&gt;&lt;sub&gt;n={num_test_schedules}&lt;/sub&gt;\",\n        'y': 0.95,  # Keep the title slightly higher\n        'x': 0.02,\n        'xanchor': 'left',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Ambiguousness\",\n    yaxis_title=\"Error / Accuracy\",\n    hoverlabel=dict(font=dict(color='white')),\n    margin=dict(t=70)  # Add more space at the top of the chart\n)\nfig.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#results",
    "href": "xgboost-objective-calc.html#results",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "3.5 Results",
    "text": "3.5 Results\nPresent your findings, using visual aids like charts or tables where appropriate. This section is factual; simply report what you found during the experiment.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#discussion",
    "href": "xgboost-objective-calc.html#discussion",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "3.6 Discussion",
    "text": "3.6 Discussion\nAnalyze your results in this section. Discuss whether your hypothesis was supported, what the results mean, and the implications for future work. Address any anomalies or unexpected findings, and consider the broader impact of your results.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#timeline",
    "href": "xgboost-objective-calc.html#timeline",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "3.7 Timeline",
    "text": "3.7 Timeline\nThis experiment was started on 30-08-2024. The expected completion date is 09-09-2024.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  },
  {
    "objectID": "xgboost-objective-calc.html#references",
    "href": "xgboost-objective-calc.html#references",
    "title": "3  XGBoost regression model for objective calculation",
    "section": "3.8 References",
    "text": "3.8 References\nCite all sources that informed your experiment, including research papers, datasets, and tools. This section ensures that your work is properly grounded in existing research and that others can trace the origins of your methods and data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>XGBoost regression model for objective calculation</span>"
    ]
  }
]